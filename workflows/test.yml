# ‚ö†Ô∏è EXAMPLE WORKFLOW - REQUIRES INTEGRATION
# This workflow was exported from a working project and serves as an EXAMPLE ONLY.
# You MUST adapt the following before using:
# - $GCP_PROJECT_ID ‚Üí Your Google Cloud project ID
# - $GITHUB_REPOSITORY ‚Üí Your repository (owner/repo)
# - $GITHUB_OWNER ‚Üí Your GitHub username or org
# - Service account configurations and secrets
# - Environment-specific variables and paths
#
# See workflows/README.md for integration instructions.
# ---

name: WorldArchitect Tests (Directory-Based)

# Security permissions for directory-based testing
permissions:
  contents: read
  pull-requests: read

# When to run the tests (optimized - no duplication on PR branches)
on:
  pull_request:              # Run on all PRs regardless of target branch
    paths-ignore:
      - '**/*.md'
      - 'docs/**'
      - 'roadmap/**'
      - '.github/ISSUE_TEMPLATE/**'
  push:
    branches: [ main, dev ]  # Run on pushes to main/dev for post-merge validation
    paths-ignore:
      - '**/*.md'
      - 'docs/**'
      - 'roadmap/**'
      - '.github/ISSUE_TEMPLATE/**'

jobs:
  limit-pr-runs:
    if: github.event_name == 'pull_request' && github.event.pull_request.head.repo.fork == false
    runs-on: ubuntu-latest
    permissions:
      actions: write
      contents: read
      pull-requests: read
    steps:
      - name: Checkout repository
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5  # v4.3.1 # v4.1.1
      - name: Limit PR runs
        uses: ./.github/actions/limit-pr-runs
        with:
          gh_token: ${{ secrets.GITHUB_TOKEN }}
  detect-changes:
    runs-on: ubuntu-latest
    outputs:
      test-dirs: ${{ steps.changes.outputs.test-dirs }}
      selected-groups: ${{ steps.changes.outputs.selected-groups }}
      matrix: ${{ steps.changes.outputs.matrix }}
      has-changes: ${{ steps.changes.outputs.has-changes }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5  # v4.3.1  # v4.1.1
        with:
          fetch-depth: 0  # Full history for accurate change detection

      - name: Detect directory changes
        id: changes
        run: |
          # Use shared change detection script
          chmod +x scripts/ci-detect-changes.sh

          # Run change detection and capture output
          OUTPUT=$(./scripts/ci-detect-changes.sh \
            "${{ github.event_name }}" \
            "${{ github.event.pull_request.base.sha }}" \
            "${{ github.event.pull_request.head.sha }}" \
            "include")

          # Parse and export outputs
          echo "$OUTPUT" | while IFS= read -r line; do
            if [[ "$line" =~ ^test-dirs= ]]; then
              echo "$line" >> $GITHUB_OUTPUT
            elif [[ "$line" =~ ^selected-groups= ]]; then
              echo "$line" >> $GITHUB_OUTPUT
            elif [[ "$line" =~ ^matrix= ]]; then
              echo "$line" >> $GITHUB_OUTPUT
            elif [[ "$line" =~ ^has-changes= ]]; then
              echo "$line" >> $GITHUB_OUTPUT
            fi
          done

          echo "$OUTPUT"

  # Import validation (always runs)
  import-validation:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - name: Checkout repository
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5  # v4.3.1  # v4.1.1
        with:
          fetch-depth: 0  # Full history needed for merge-base diff
      - name: Run import validation
        run: |
          if [ -f "scripts/validate_imports_delta.sh" ]; then
            ./scripts/validate_imports_delta.sh
          else
            echo "Import validation script not found, skipping"
          fi
      - name: Upload import validation results
        uses: actions/upload-artifact@5d5d22a31266ced268874388b861e4b58bb5c2f3  # v4.3.1
        if: always()
        with:
          name: import-validation-results
          path: scripts/validate_imports.log

  # Directory-based test execution
  test:
    name: Directory tests (${{ matrix.test-group }})
    needs: detect-changes
    if: needs.detect-changes.outputs.has-changes == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 15
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.detect-changes.outputs.matrix) }}

    steps:
    - name: Checkout repository
      uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5  # v4.3.1  # v4.1.1
      with:
        submodules: recursive
        fetch-depth: 0  # Full history needed for git diff in JS test step

    - name: Set up Python 3.11
      uses: actions/setup-python@0a5c61591373683505ea898e09a3ea4f39ef2b9c  # v5.0.0
      with:
        python-version: '3.11'

    - name: Set up Node.js 20
      if: matrix.test-group == 'core'
      uses: actions/setup-node@60edb5dd545a775178f52524783378180af0d1f8  # v4.0.2
      with:
        node-version: '20'

    - name: Cache pip dependencies and virtual environment
      uses: actions/cache@0400d5f644dc74513175e3cd8d07132dd4860809  # v4.2.4
      with:
        path: |
          ~/.cache/pip
          venv
        key: ${{ runner.os }}-python-3.11-${{ hashFiles('**/requirements.txt') }}-${{ matrix.test-group }}
        restore-keys: |
          ${{ runner.os }}-python-3.11-${{ hashFiles('**/requirements.txt') }}-
          ${{ runner.os }}-python-3.11-

    - name: Install dependencies
      run: |
        # Reuse cached venv when available; otherwise create it
        if [ -d venv ]; then
          echo "Reusing cached venv"
        else
          echo "Creating new venv"
          python -m venv venv
        fi
        source venv/bin/activate

        # Upgrade pip and install resolver tools with timeout
        timeout 300 python -m pip install --upgrade pip setuptools wheel

        # Install core application requirements
        timeout 600 pip install -r mvp_site/requirements.txt

        # Install additional requirements for specific directories if needed
        # NOTE: Keep the group names in sync with GROUP_CONFIG in scripts/ci-detect-changes.sh (source of truth).
        case "${{ matrix.test-group }}" in
          "core"|"claude"|"orchestration"|"automation"|"scripts"|"mcp")
            # These directories may have additional requirements
            find . -name "requirements.txt" -not -path "./venv/*" -not -path "./mvp_site/requirements.txt" | while read req_file; do
              echo "Installing $req_file (with 300s timeout)"
              timeout 300 pip install -r "$req_file" || echo "Warning: Failed to install $req_file"
            done
            # Install utility packages if testing core group (tests/ directory needs these)
            if [ "${{ matrix.test-group }}" = "core" ]; then
              if [ -f "moltbook_poster/pyproject.toml" ]; then
                echo "Installing moltbook_poster package for tests/ directory"
                timeout 300 pip install -e "./moltbook_poster" || echo "Warning: Failed to install moltbook_poster"
              fi
              if [ -f "orchestration/pyproject.toml" ]; then
                echo "Installing orchestration package for tests/ directory"
                timeout 300 pip install -e "./orchestration" || echo "Warning: Failed to install orchestration"
              fi
            fi
            # Install automation package if testing automation
            if [ "${{ matrix.test-group }}" = "automation" ] && [ -f "automation/pyproject.toml" ]; then
              echo "Installing automation package in editable mode with dev dependencies"
              timeout 300 pip install -e "./automation[dev]"
            fi
            ;;
        esac

        # Verify key dependencies
        timeout 60 python -c "import pydantic; print(f'‚úÖ Pydantic {pydantic.__version__} available')"
        chmod +x vpython
        timeout 60 ./vpython --version

    - name: Run frontend_v1 JS unit tests
      if: matrix.test-group == 'core'
      run: |
        if [ "${{ github.event_name }}" = "pull_request" ]; then
          CHANGED_FILES=$(git diff --name-only "${{ github.event.pull_request.base.sha }}" "${{ github.event.pull_request.head.sha }}")
        else
          CHANGED_FILES=$(git diff --name-only "HEAD~1..HEAD")
        fi

        if echo "$CHANGED_FILES" | grep -q '^mvp_site/frontend_v1/'; then
          node --test mvp_site/frontend_v1/tests/settings_listeners.test.js
        else
          echo "No frontend_v1 changes detected; skipping JS unit test."
        fi

    - name: Run directory-based tests - ${{ matrix.test-group }}
      timeout-minutes: 12
      run: |
        source venv/bin/activate

        # Set CI environment variables
        export TESTING=true
        export TESTING_AUTH_BYPASS=true
        export MOCK_SERVICES_MODE=true
        export FAST_TESTS=1
        # Defense-in-depth: Set fake API keys so real services can't be hit
        # even if mock mode is somehow bypassed
        # NOTE: Keys must start with "test-" or "dummy-" to trigger Gemini stub
        # (see gemini_provider._use_test_stub_client)
        export GEMINI_API_KEY="test-ci-key-only"
        export CEREBRAS_API_KEY="test-ci-key-only"
        export OPENROUTER_API_KEY="test-ci-key-only"
        export TEST_GEMINI_API_KEY="test-ci-key-only"
        export GOOGLE_APPLICATION_CREDENTIALS="/dev/null"
        # Disable semantic classifier to prevent model download stalls in CI
        export ENABLE_SEMANTIC_ROUTING=false
        export ENABLE_BROWSER_TESTS=0
        export ENABLE_BUILD_TESTS=0
        export ENABLE_NETWORK_TESTS=0
        export GITHUB_ACTIONS=true
        export PYTHONPATH="${PYTHONPATH}:${PWD}:${PWD}/mvp_site:${PWD}/automation"

        echo "üéØ Running tests for directory group: ${{ matrix.test-group }}"
        echo "üìÇ Test directories: ${{ matrix.test-dirs }}"

        # Run tests only for the specified directory/directories
        chmod +x run_tests.sh
        # CI_TEST_LIMIT removed to run all discovered tests (prevents skipping critical tests)
        # Historical note: CI_TEST_LIMIT=50 previously truncated test lists, risking test coverage gaps

        # Use directory-based test discovery with validation
        IFS=',' read -ra SELECTED_DIRS <<< "${{ matrix.test-dirs }}"
        TOTAL_TESTS=0
        for DIR in "${SELECTED_DIRS[@]}"; do
          DIR=$(echo "$DIR" | xargs)
          [ -z "$DIR" ] && continue
          COUNT=$(find "$DIR" -name "test_*.py" -type f 2>/dev/null | wc -l)
          echo "üìä Found $COUNT test files in $DIR"
          TOTAL_TESTS=$((TOTAL_TESTS + COUNT))
        done

        if [ "$TOTAL_TESTS" -eq 0 ]; then
          echo "‚ö†Ô∏è No tests found in specified directories, falling back to full test suite"
          ./run_tests.sh --ci --parallel --exclude-integration --exclude-mcp
        else
          ./run_tests.sh --test-dirs="${{ matrix.test-dirs }}" --parallel --exclude-integration --exclude-mcp
        fi

    - name: Upload test results
      uses: actions/upload-artifact@5d5d22a31266ced268874388b861e4b58bb5c2f3  # v4.3.1
      if: always()
      with:
        name: test-results-${{ matrix.test-group }}
        path: |
          mvp_site/test-results/
          /tmp/worldarchitectai/coverage/
          mvp_site/*.log
        retention-days: 30
        if-no-files-found: warn
