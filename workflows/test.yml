# âš ï¸ EXAMPLE WORKFLOW - REQUIRES INTEGRATION
# This workflow was exported from a working project and serves as an EXAMPLE ONLY.
# You MUST adapt the following before using:
# - $GCP_PROJECT_ID â†’ Your Google Cloud project ID
# - $GITHUB_REPOSITORY â†’ Your repository (owner/repo)
# - $GITHUB_OWNER â†’ Your GitHub username or org
# - Service account configurations and secrets
# - Environment-specific variables and paths
#
# See workflows/README.md for integration instructions.
# ---

name: WorldArchitect Tests (Directory-Based)

# Cancel in-progress runs when new commits are pushed to same branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

# Security permissions for directory-based testing
permissions:
  contents: read
  pull-requests: read

# When to run the tests (optimized - no duplication on PR branches)
on:
  workflow_dispatch:
  pull_request:              # Run on all PRs regardless of target branch
    paths-ignore:
      - '**/*.md'
      - 'docs/**'
      - 'roadmap/**'
      - '.github/ISSUE_TEMPLATE/**'
  push:
    branches: [ main, dev ]  # Run on pushes to main/dev for post-merge validation
    paths-ignore:
      - '**/*.md'
      - 'docs/**'
      - 'roadmap/**'
      - '.github/ISSUE_TEMPLATE/**'

jobs:
  limit-pr-runs:
    if: github.event_name == 'pull_request' && github.event.pull_request.head.repo.fork == false
    runs-on: ubuntu-latest
    permissions:
      actions: write
      contents: read
      pull-requests: read
    steps:
      - name: Checkout repository
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5  # v4.3.1 # v4.1.1
      - name: Limit PR runs
        uses: ./.github/actions/limit-pr-runs
        with:
          gh_token: ${{ secrets.GITHUB_TOKEN }}
  detect-changes:
    runs-on: ubuntu-latest
    outputs:
      test-dirs: ${{ steps.changes.outputs.test-dirs }}
      selected-groups: ${{ steps.changes.outputs.selected-groups }}
      matrix: ${{ steps.changes.outputs.matrix }}
      has-changes: ${{ steps.changes.outputs.has-changes }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5  # v4.3.1  # v4.1.1
        with:
          fetch-depth: 0  # Full history for accurate change detection

      - name: Detect directory changes
        id: changes
        run: |
          # Use shared change detection script
          chmod +x scripts/ci-detect-changes.sh

          # Run change detection and capture output
          OUTPUT=$(./scripts/ci-detect-changes.sh \
            "${{ github.event_name }}" \
            "${{ github.event.pull_request.base.sha }}" \
            "${{ github.event.pull_request.head.sha }}" \
            "include")

          # Parse and export outputs
          echo "$OUTPUT" | while IFS= read -r line; do
            if [[ "$line" =~ ^test-dirs= ]]; then
              echo "$line" >> $GITHUB_OUTPUT
            elif [[ "$line" =~ ^selected-groups= ]]; then
              echo "$line" >> $GITHUB_OUTPUT
            elif [[ "$line" =~ ^matrix= ]]; then
              echo "$line" >> $GITHUB_OUTPUT
            elif [[ "$line" =~ ^has-changes= ]]; then
              echo "$line" >> $GITHUB_OUTPUT
            fi
          done

          echo "$OUTPUT"

  # Import validation (always runs)
  import-validation:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - name: Checkout repository
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5  # v4.3.1  # v4.1.1
        with:
          fetch-depth: 0  # Full history needed for merge-base diff
      - name: Run import validation
        run: |
          if [ -f "scripts/validate_imports_delta.sh" ]; then
            ./scripts/validate_imports_delta.sh
          else
            echo "Import validation script not found, skipping"
          fi
      - name: Upload import validation results
        uses: actions/upload-artifact@5d5d22a31266ced268874388b861e4b58bb5c2f3  # v4.3.1
        if: always()
        with:
          name: import-validation-results
          path: scripts/validate_imports.log

  # Merge-commit correctness gate (REV-q4cmy)
  # The testmon test jobs checkout PR head SHA for cache stability,
  # but that skips validation against the merge commit (base+head).
  # This lightweight gate runs on the default merge commit to catch
  # integration breakages that would only appear after merging.
  merge-commit-gate:
    name: Merge commit validation
    if: github.event_name == 'pull_request'
    runs-on: ubuntu-latest
    timeout-minutes: 10
    env:
      TESTING: 'true'
      TESTING_AUTH_BYPASS: 'true'
      MOCK_SERVICES_MODE: 'true'
      FAST_TESTS: '1'
      GEMINI_API_KEY: test-ci-key-only
      CEREBRAS_API_KEY: test-ci-key-only
      OPENROUTER_API_KEY: test-ci-key-only
      GOOGLE_APPLICATION_CREDENTIALS: /dev/null
      ENABLE_SEMANTIC_ROUTING: 'false'
      PYTHONPATH: ${{ github.workspace }}:${{ github.workspace }}/mvp_site:${{ github.workspace }}/automation
    steps:
    - name: Checkout merge commit
      uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5  # v4.3.1  # v4.1.1
      with:
        # Deliberately NOT setting ref â€” uses default merge commit
        # to validate the PR integrates cleanly with the base branch.
        submodules: recursive
        fetch-depth: 1

    - name: Set up Python 3.11
      uses: actions/setup-python@0a5c61591373683505ea898e09a3ea4f39ef2b9c  # v5.0.0
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
        if [ -f mvp_site/requirements.txt ]; then pip install -r mvp_site/requirements.txt; fi

    - name: Validate merge-commit imports
      run: |
        echo "=== Merge-commit import validation ==="
        echo "Ref: ${{ github.ref }}"
        echo "SHA: $(git rev-parse HEAD)"

        # Verify all production modules can be imported on the merge commit.
        # This catches cases where PR head compiles fine in isolation but
        # conflicts with changes on main (e.g., removed imports, renamed modules).
        python -c "
        import importlib, sys, pathlib
        errors = []
        # Core production modules that must import cleanly
        for mod in [
            'mvp_site.main', 'mvp_site.world_logic', 'mvp_site.llm_service',
            'mvp_site.game_state', 'mvp_site.firestore_service',
            'mvp_site.structured_fields_utils', 'mvp_site.streaming_orchestrator',
        ]:
            try:
                importlib.import_module(mod)
                print(f'  âœ“ {mod}')
            except Exception as e:
                errors.append((mod, e))
                print(f'  âœ— {mod}: {e}')
        if errors:
            print(f'\n{len(errors)} import(s) failed on merge commit!')
            sys.exit(1)
        print('\nAll core imports validated on merge commit.')
        "

    - name: Run merge-commit smoke tests
      run: |
        # Run a focused subset of fast tests on the merge commit.
        # These are chosen to exercise cross-module integration points.
        python -m pytest \
          mvp_site/tests/test_main_state_helper.py \
          mvp_site/tests/test_game_state.py \
          -x -q --timeout=60 --no-header \
          2>&1 || {
            echo "::error::Merge-commit smoke tests failed â€” PR may have integration issues with base branch"
            exit 1
          }

  # Directory-based test execution
  test:
    name: Directory tests (${{ matrix.test-group }})
    needs: detect-changes
    if: needs.detect-changes.outputs.has-changes == 'true'
    runs-on: ubuntu-latest
    # Core group runs with coverage enabled and sequential execution, which can exceed 15m.
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.detect-changes.outputs.matrix) }}

    steps:
    - name: Repair workspace permissions for checkout
      run: |
        if [ -d "$GITHUB_WORKSPACE" ]; then
          chmod -R u+rwX "$GITHUB_WORKSPACE" || true
        fi

    - name: Checkout repository
      uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5  # v4.3.1  # v4.1.1
      with:
        # For PRs: checkout the actual head commit, not the synthetic merge commit.
        # testmon fingerprints files using the working tree state; the merge commit
        # creates a different checkout that defeats testmon's change detection.
        ref: ${{ github.event.pull_request.head.sha || github.sha }}
        submodules: recursive
        fetch-depth: 0  # Full history needed for git diff in JS test step
        clean: true  # Remove untracked files from prior runs on self-hosted runners

    - name: Set up Node.js 20
      if: matrix.test-group == 'core-mvp-1'
      uses: actions/setup-node@60edb5dd545a775178f52524783378180af0d1f8  # v4.0.2
      with:
        node-version: '20'

    - name: Prepare runner tool cache for setup actions
      run: |
        chmod +x scripts/ci/setup-runner-tool-cache.sh
        ./scripts/ci/setup-runner-tool-cache.sh

    - name: Set up Python 3.11
      uses: actions/setup-python@0a5c61591373683505ea898e09a3ea4f39ef2b9c  # v5.0.0
      with:
        python-version: '3.11'

    - name: Resolve Python version for cache keys
      id: python-version
      shell: bash
      run: |
        PYTHON=$(command -v python3.11 || command -v python3 || command -v python || true)
        if [ -z "$PYTHON" ]; then
          echo "::error::No suitable Python interpreter found (tried: python3.11, python3, python)" >&2
          exit 2
        fi
        PYTHON_VERSION=$($PYTHON -c 'import sys; print(f"{sys.version_info.major}.{sys.version_info.minor}")')
        echo "Resolved interpreter: $PYTHON"
        echo "Resolved version: $PYTHON_VERSION"
        echo "python=$PYTHON" >> "$GITHUB_OUTPUT"
        echo "python_version=$PYTHON_VERSION" >> "$GITHUB_OUTPUT"

    - name: Cache pip dependencies
      uses: actions/cache@0400d5f644dc74513175e3cd8d07132dd4860809  # v4.2.4
      with:
        path: |
          ~/.cache/pip
        key: ${{ runner.os }}-python-${{ steps.python-version.outputs.python_version }}-${{ hashFiles('**/requirements.txt') }}-${{ matrix.test-group }}
        restore-keys: |
          ${{ runner.os }}-python-${{ steps.python-version.outputs.python_version }}-${{ hashFiles('**/requirements.txt') }}-
          ${{ runner.os }}-python-${{ steps.python-version.outputs.python_version }}-

    - name: Cache testmon data
      uses: actions/cache@0400d5f644dc74513175e3cd8d07132dd4860809  # v4.2.4
      with:
        path: |
          .testmondata
          .testmondata-shm
          .testmondata-wal
          mvp_site/.testmondata
          mvp_site/.testmondata-shm
          mvp_site/.testmondata-wal
        # Rolling key: GitHub Actions cache is write-once per key, so a static
        # branch-based key can never be updated after first creation.
        # Using run_number makes each run save fresh testmon data under a new
        # key. restore-keys prefix match loads the most recent prior run's
        # baseline from the same branch.
        key: testmon-${{ matrix.test-group }}-${{ github.base_ref || github.ref_name }}-${{ github.run_number }}
        restore-keys: |
          testmon-${{ matrix.test-group }}-${{ github.base_ref || github.ref_name }}-

    - name: Runner preflight
      id: preflight
      shell: bash
      run: |
        chmod +x scripts/ci/runner_preflight.sh scripts/runner_health_score.py
        export REQUIRED_PYTHON_MINOR="${{ steps.python-version.outputs.python_version }}"
        export PRECHECK_JSON="${RUNNER_TEMP}/runner_health.json"
        PRECHECK_PYTHON="${{ steps.python-version.outputs.python }}"
        if [ -z "$PRECHECK_PYTHON" ]; then
          PRECHECK_PYTHON=$(command -v python3.11 || command -v python3 || command -v python || true)
        fi
        if [ -z "$PRECHECK_PYTHON" ]; then
          PRECHECK_PYTHON=python
        fi
        PRECHECK_CLASS=""
        PRECHECK_EXIT=0
        if scripts/ci/runner_preflight.sh "$PRECHECK_JSON"; then
          PRECHECK_EXIT=0
        else
          PRECHECK_EXIT=$?
          PRECHECK_PYTHON="${{ steps.python-version.outputs.python }}"
          if [ -z "$PRECHECK_PYTHON" ] || [ ! -x "$PRECHECK_PYTHON" ]; then
            PRECHECK_PYTHON=$(command -v python3.11 || command -v python3 || command -v python || true)
          fi
          if [ -z "$PRECHECK_PYTHON" ]; then
            PRECHECK_CLASS="preflight_parse_failed"
          else
            PRECHECK_CLASS=$("$PRECHECK_PYTHON" -c 'import json,os; path=os.environ.get("PRECHECK_JSON"); print((json.load(open(path, "r", encoding="utf-8")).get("infra_failure_class", "preflight_failed")) if path and os.path.exists(path) else "preflight_failed"') || PRECHECK_CLASS="preflight_parse_failed"
          fi
        fi
        echo "preflight_json=$PRECHECK_JSON" >> "$GITHUB_OUTPUT"
        echo "preflight_exit_code=$PRECHECK_EXIT" >> "$GITHUB_OUTPUT"
        echo "infra_failure_class=$PRECHECK_CLASS" >> "$GITHUB_OUTPUT"

    - name: Runner quarantine check
      id: runner-quarantine
      shell: bash
      run: |
        scripts/runner_health_score.py \
          --runner "${RUNNER_NAME:-unknown}" \
          --threshold 6 \
          --github-output "$GITHUB_OUTPUT" \
          check

    - name: Enforce preflight and quarantine gate
      shell: bash
      run: |
        if [ "${{ steps.preflight.outputs.preflight_exit_code }}" != "0" ]; then
          echo "::error::Runner preflight failed (class=${{ steps.preflight.outputs.infra_failure_class }})"
          exit 2
        fi
        if [ "${{ steps.runner-quarantine.outputs.quarantined }}" = "true" ]; then
          echo "::error::Runner ${RUNNER_NAME:-unknown} is quarantined (score=${{ steps.runner-quarantine.outputs.score }})"
          exit 3
        fi

    - name: Debug testmon state
      if: always()
      run: |
        echo "=== Git checkout info ==="
        echo "HEAD: $(git rev-parse HEAD)"
        echo "github.sha: ${{ github.sha }}"
        echo "PR head SHA: ${{ github.event.pull_request.head.sha }}"
        echo "Event: ${{ github.event_name }}"
        echo ""
        echo "=== Testmon data files ==="
        ls -la .testmondata mvp_site/.testmondata 2>/dev/null || echo "No .testmondata files found"
        echo ""
        if [ -f mvp_site/.testmondata ] || [ -f .testmondata ]; then
          DB_FILE="mvp_site/.testmondata"
          [ ! -f "$DB_FILE" ] && DB_FILE=".testmondata"
          echo "=== Testmon DB tables ==="
          sqlite3 "$DB_FILE" ".tables" 2>/dev/null || echo "Cannot read DB"
          echo ""
          echo "=== Testmon file fingerprints (first 20) ==="
          sqlite3 "$DB_FILE" "SELECT * FROM file LIMIT 20;" 2>/dev/null || echo "No file table"
          echo ""
          echo "=== Testmon node count ==="
          sqlite3 "$DB_FILE" "SELECT COUNT(*) FROM node;" 2>/dev/null || echo "No node table"
          echo ""
          echo "=== Testmon environment ==="
          sqlite3 "$DB_FILE" "SELECT * FROM metadata;" 2>/dev/null || echo "No metadata table"
        fi

    - name: Install dependencies
      id: install-deps
      run: |
        VENV_PY="$PWD/venv/bin/python"
        VENV_PIP="$PWD/venv/bin/pip"

        # Reuse cached venv only when interpreter and pip are both healthy.
        # A restored cache can contain venv/bin/python that exists but points
        # to a missing interpreter, or pip state that is broken across runners.
        if [ -d venv ] && [ -x "$VENV_PY" ] && [ -x "$VENV_PIP" ] \
          && timeout 30 "$VENV_PY" --version >/dev/null 2>&1 \
          && timeout 30 "$VENV_PIP" --version >/dev/null 2>&1 \
          && "$VENV_PY" -m pip --version >/dev/null 2>&1; then
          echo "Reusing cached venv"
        else
          echo "Creating new venv"
          # Remove stale/corrupt cached venv (e.g., broken symlinks from cross-runner cache restore)
          rm -rf venv
        fi
        chmod +x scripts/ci/classify_infra_failure.sh

        PYTHON="${{ steps.python-version.outputs.python }}"
        if [ -z "$PYTHON" ]; then
          # Prefer python3.11 to match project target; fall back to python3 then python.
          PYTHON=$(command -v python3.11 || command -v python3 || command -v python || true)
        fi
        if [ -z "$PYTHON" ]; then
          echo "::error::No suitable Python interpreter found (tried: python3.11, python3, python)" >&2
          exit 2
        fi
        echo "Using $PYTHON ($($PYTHON --version))"

        ATTEMPT=1
        MAX_ATTEMPTS=2
        INFRA_CLASS=""
        while [ "$ATTEMPT" -le "$MAX_ATTEMPTS" ]; do
          echo "Dependency install attempt ${ATTEMPT}/${MAX_ATTEMPTS}"

          # Reuse cached venv when healthy, otherwise recreate to avoid cross-runner drift.
          if [ -d venv ] && [ -x "$VENV_PY" ] && [ -x "$VENV_PIP" ] \
            && timeout 30 "$VENV_PY" --version >/dev/null 2>&1 \
            && timeout 30 "$VENV_PIP" --version >/dev/null 2>&1; then
            echo "Reusing cached venv"
          else
            echo "Creating new venv"
            rm -rf venv
            $PYTHON -m venv venv
          fi
          set +e
          {
            echo "Using venv python: $($VENV_PY --version)"
            timeout 60 "$VENV_PY" --version
            timeout 60 "$VENV_PIP" --version
            echo "$PWD/venv/bin" >> "$GITHUB_PATH"

            if "$VENV_PY" -c "import pydantic, pytest, xdist, pytest_cov, testmon" 2>/dev/null; then
              echo "Cached venv already has core dependencies"
            else
              # Upgrade pip and install resolver tools with timeout
              timeout 300 "$VENV_PY" -m pip install --upgrade pip setuptools wheel
              # Install core application requirements
              timeout 600 "$VENV_PIP" install -r mvp_site/requirements.txt
              # Install pytest tooling for batched worker execution
              timeout 300 "$VENV_PIP" install pytest pytest-xdist pytest-testmon pytest-cov
            fi

            case "${{ matrix.test-group }}" in
              "core-mvp-1"|"core-mvp-2"|"core-mvp-3"|"core-tests"|"claude"|"orchestration"|"automation"|"scripts"|"mcp")
                find . -name "requirements.txt" -not -path "./venv/*" -not -path "./mvp_site/requirements.txt" | while read req_file; do
                  echo "Installing $req_file (with 300s timeout)"
                  timeout 300 "$VENV_PIP" install -r "$req_file" || echo "Warning: Failed to install $req_file"
                done
                if [[ "${{ matrix.test-group }}" == core-* ]]; then
                  if [ -f "moltbook_poster/pyproject.toml" ]; then
                    echo "Installing moltbook_poster package for tests/ directory"
                    timeout 300 "$VENV_PIP" install -e "./moltbook_poster" || echo "Warning: Failed to install moltbook_poster"
                  fi
                  if [ -f "orchestration/pyproject.toml" ]; then
                    echo "Installing orchestration package for tests/ directory"
                    timeout 300 "$VENV_PIP" install -e "./orchestration" || echo "Warning: Failed to install orchestration"
                  fi
                fi
                if [ "${{ matrix.test-group }}" = "automation" ] && [ -f "automation/pyproject.toml" ]; then
                  echo "Installing automation package in editable mode with dev dependencies"
                  timeout 300 "$VENV_PIP" install -e "./automation[dev]"
                fi
                ;;
            esac

            if [[ "${{ matrix.test-group }}" == core-* ]]; then
              "$VENV_PIP" install coverage
            fi

            timeout 60 "$VENV_PY" -c "import pydantic; print(f'âœ… Pydantic {pydantic.__version__} available')"
            chmod +x vpython
            timeout 60 ./vpython --version
          } 2>&1 | tee "${RUNNER_TEMP}/install-deps.log"
          INSTALL_EXIT=${PIPESTATUS[0]}
          set -e

          if [ "$INSTALL_EXIT" -eq 0 ]; then
            echo "infra_failure_class=" >> "$GITHUB_OUTPUT"
            break
          fi

          INFRA_CLASS="$(scripts/ci/classify_infra_failure.sh "${RUNNER_TEMP}/install-deps.log" || true)"
          echo "Install attempt ${ATTEMPT} failed (infra_class=${INFRA_CLASS:-none})"
          if [ "$ATTEMPT" -lt "$MAX_ATTEMPTS" ] && [ -n "$INFRA_CLASS" ]; then
            echo "Retrying install due to infra-classified failure..."
            ATTEMPT=$((ATTEMPT + 1))
            sleep 5
            continue
          fi

          echo "infra_failure_class=${INFRA_CLASS}" >> "$GITHUB_OUTPUT"
          exit "$INSTALL_EXIT"
        done

        echo "install_attempts=${ATTEMPT}" >> "$GITHUB_OUTPUT"

    - name: Run frontend_v1 JS unit tests
      if: matrix.test-group == 'core-mvp-1'
      run: |
        if [ "${{ github.event_name }}" = "pull_request" ]; then
          CHANGED_FILES=$(git diff --name-only "${{ github.event.pull_request.base.sha }}" "${{ github.event.pull_request.head.sha }}")
        else
          CHANGED_FILES=$(git diff --name-only "HEAD~1..HEAD")
        fi

        if echo "$CHANGED_FILES" | grep -q '^mvp_site/frontend_v1/'; then
          node --test mvp_site/frontend_v1/tests/settings_listeners.test.js
        else
          echo "No frontend_v1 changes detected; skipping JS unit test."
        fi

    - name: Create coverage config
      if: startsWith(matrix.test-group, 'core-')
      run: |
        # Must exist BEFORE test execution so coverage stores relative paths.
        # Without this, the coverage-report job can't resolve source files.
        cat > .coveragerc << 'COVEOF'
        [run]
        relative_files = true
        source = mvp_site
        omit =
            */tests/*
            */testing_framework/*
            */venv/*
            */__pycache__/*

        [report]
        exclude_lines =
            pragma: no cover
            def __repr__
            raise NotImplementedError
        COVEOF

    - name: Run directory-based tests - ${{ matrix.test-group }}
      id: run-tests
      # Keep per-step timeout aligned with the expanded suite timeout budget.
      timeout-minutes: 25
      run: |
        chmod +x scripts/ci/classify_infra_failure.sh
        # VIRTUAL_ENV set so run_tests.sh/ensure_venv skips sourcing activate.
        export VIRTUAL_ENV="$PWD/venv"
        # Set CI environment variables
        export TESTING=true
        export TESTING_AUTH_BYPASS=true
        export MOCK_SERVICES_MODE=true
        export FAST_TESTS=1
        export GEMINI_API_KEY="test-ci-key-only"
        export CEREBRAS_API_KEY="test-ci-key-only"
        export OPENROUTER_API_KEY="test-ci-key-only"
        export TEST_GEMINI_API_KEY="test-ci-key-only"
        export GOOGLE_APPLICATION_CREDENTIALS="/dev/null"
        export ENABLE_SEMANTIC_ROUTING=false
        export ENABLE_BROWSER_TESTS=0
        export ENABLE_BUILD_TESTS=0
        export ENABLE_NETWORK_TESTS=0
        export GITHUB_ACTIONS=true
        export PYTHONPATH="${PYTHONPATH}:${PWD}:${PWD}/mvp_site:${PWD}/automation"
        export TEST_SHARD_INDEX="${{ matrix.shard-index }}"
        export TEST_SHARD_TOTAL="${{ matrix.shard-total }}"

        echo "ðŸŽ¯ Running tests for directory group: ${{ matrix.test-group }}"
        echo "ðŸ“‚ Test directories: ${{ matrix.test-dirs }}"
        echo "ðŸ§© Shard: ${TEST_SHARD_INDEX}/${TEST_SHARD_TOTAL}"

        if [ "${{ matrix.test-group }}" = "automation" ]; then
          echo "ðŸ§ª Running automation shell regression tests"
          bash automation/tests/test_install_cron_entries.sh
          bash automation/tests/test_crontab_restore_safety.sh
        fi

        chmod +x run_tests.sh
        IFS=',' read -ra SELECTED_DIRS <<< "${{ matrix.test-dirs }}"
        TOTAL_TESTS=0
        for DIR in "${SELECTED_DIRS[@]}"; do
          DIR=$(echo "$DIR" | xargs)
          [ -z "$DIR" ] && continue
          COUNT=$(find "$DIR" -name "test_*.py" -type f 2>/dev/null | wc -l)
          echo "ðŸ“Š Found $COUNT test files in $DIR"
          TOTAL_TESTS=$((TOTAL_TESTS + COUNT))
        done

        if [ "$TOTAL_TESTS" -eq 0 ]; then
          TEST_CMD="./run_tests.sh --ci --parallel --exclude-integration --exclude-mcp"
        elif [[ "${{ matrix.test-group }}" == core-mvp-* ]] && [ "${{ github.event_name }}" = "pull_request" ]; then
          export TEST_SUITE_TIMEOUT=1080  # 18 min (vs default 15 min)
          export TEST_MAX_WORKERS=2
          TEST_CMD="./run_tests.sh --test-dirs=\"${{ matrix.test-dirs }}\" --coverage --exclude-integration --exclude-mcp --testmon"
        elif [ "${{ github.event_name }}" = "push" ]; then
          export TEST_MAX_WORKERS=2
          TEST_CMD="./run_tests.sh --test-dirs=\"${{ matrix.test-dirs }}\" --parallel --exclude-integration --exclude-mcp --testmon"
        else
          export TEST_MAX_WORKERS=2
          TEST_CMD="./run_tests.sh --test-dirs=\"${{ matrix.test-dirs }}\" --parallel --exclude-integration --exclude-mcp --testmon"
        fi

        ATTEMPT=1
        MAX_ATTEMPTS=2
        TEST_INFRA_CLASS=""
        while [ "$ATTEMPT" -le "$MAX_ATTEMPTS" ]; do
          echo "Test execution attempt ${ATTEMPT}/${MAX_ATTEMPTS}: ${TEST_CMD}"
          set +e
          bash -o pipefail -c "${TEST_CMD}" 2>&1 | tee "${RUNNER_TEMP}/run-tests.log"
          TEST_EXIT=${PIPESTATUS[0]}
          set -e

          if [ "$TEST_EXIT" -eq 0 ]; then
            echo "infra_failure_class=" >> "$GITHUB_OUTPUT"
            break
          fi

          TEST_INFRA_CLASS="$(scripts/ci/classify_infra_failure.sh "${RUNNER_TEMP}/run-tests.log" || true)"
          echo "Test attempt ${ATTEMPT} failed (infra_class=${TEST_INFRA_CLASS:-none})"
          if [ "$ATTEMPT" -lt "$MAX_ATTEMPTS" ] && [ -n "$TEST_INFRA_CLASS" ]; then
            echo "Retrying tests due to infra-classified failure..."
            ATTEMPT=$((ATTEMPT + 1))
            sleep 5
            continue
          fi

          echo "infra_failure_class=${TEST_INFRA_CLASS}" >> "$GITHUB_OUTPUT"
          exit "$TEST_EXIT"
        done

        echo "test_attempts=${ATTEMPT}" >> "$GITHUB_OUTPUT"

    - name: Update runner health score
      if: always()
      id: runner-health-update
      shell: bash
      run: |
        chmod +x scripts/runner_health_score.py

        DELTA=-1
        REASON="success"

        if [ "${{ steps.preflight.outputs.preflight_exit_code }}" != "0" ]; then
          DELTA=4
          REASON="preflight:${{ steps.preflight.outputs.infra_failure_class }}"
        elif [ "${{ steps.runner-quarantine.outputs.quarantined }}" = "true" ]; then
          DELTA=0
          REASON="quarantine:skipped"
        elif [ "${{ steps.install-deps.outcome }}" = "skipped" ] && [ "${{ steps.run-tests.outcome }}" = "skipped" ]; then
          DELTA=0
          REASON="gated:skipped"
        elif [ "${{ steps.install-deps.outcome }}" != "success" ]; then
          if [ -n "${{ steps.install-deps.outputs.infra_failure_class }}" ]; then
            DELTA=3
            REASON="install:${{ steps.install-deps.outputs.infra_failure_class }}"
          else
            DELTA=1
            REASON="install:unknown"
          fi
        elif [ "${{ steps.run-tests.outcome }}" != "success" ]; then
          if [ -n "${{ steps.run-tests.outputs.infra_failure_class }}" ]; then
            DELTA=2
            REASON="tests:${{ steps.run-tests.outputs.infra_failure_class }}"
          else
            DELTA=1
            REASON="tests:product-failure"
          fi
        fi

        scripts/runner_health_score.py \
          --runner "${RUNNER_NAME:-unknown}" \
          --threshold 6 \
          --github-output "$GITHUB_OUTPUT" \
          update \
          --delta "$DELTA" \
          --reason "$REASON"

    - name: Persist runner health state snapshot
      if: always()
      shell: bash
      run: |
        mkdir -p "${RUNNER_TEMP}/runner-health"
        cp "${{ steps.preflight.outputs.preflight_json }}" "${RUNNER_TEMP}/runner-health/runner_health.json" 2>/dev/null || true
        cp "${HOME}/.cache/worldarchitect-ci/runner-health-score.json" "${RUNNER_TEMP}/runner-health/runner_health_score.json" 2>/dev/null || true

    - name: Upload runner health artifacts
      if: always()
      uses: actions/upload-artifact@5d5d22a31266ced268874388b861e4b58bb5c2f3  # v4.3.1
      with:
        name: runner-health-${{ matrix.test-group }}
        path: |
          ${{ runner.temp }}/runner-health/
        if-no-files-found: warn
        retention-days: 30

    - name: Runner health summary
      if: always()
      shell: bash
      run: |
        echo "### Runner Health" >> "$GITHUB_STEP_SUMMARY"
        echo "- Runner: ${RUNNER_NAME:-unknown}" >> "$GITHUB_STEP_SUMMARY"
        echo "- Quarantine score before run: ${{ steps.runner-quarantine.outputs.score }}" >> "$GITHUB_STEP_SUMMARY"
        echo "- Quarantined before run: ${{ steps.runner-quarantine.outputs.quarantined }}" >> "$GITHUB_STEP_SUMMARY"
        echo "- Preflight exit: ${{ steps.preflight.outputs.preflight_exit_code }}" >> "$GITHUB_STEP_SUMMARY"
        echo "- Install attempts: ${{ steps.install-deps.outputs.install_attempts }}" >> "$GITHUB_STEP_SUMMARY"
        echo "- Test attempts: ${{ steps.run-tests.outputs.test_attempts }}" >> "$GITHUB_STEP_SUMMARY"
        echo "- Health score delta: ${{ steps.runner-health-update.outputs.delta }}" >> "$GITHUB_STEP_SUMMARY"
        echo "- Health score now: ${{ steps.runner-health-update.outputs.score }}" >> "$GITHUB_STEP_SUMMARY"
        echo "- Quarantined now: ${{ steps.runner-health-update.outputs.quarantined }}" >> "$GITHUB_STEP_SUMMARY"

    - name: Checkpoint testmon WAL
      if: always()
      run: |
        # SQLite WAL mode keeps data in -wal files. Checkpoint flushes
        # all data to the main .testmondata so the cache step captures it.
        for db in .testmondata mvp_site/.testmondata; do
          if [ -f "$db" ]; then
            echo "Checkpointing $db"
            sqlite3 "$db" "PRAGMA wal_checkpoint(TRUNCATE);" 2>/dev/null || true
            ls -la "${db}"* 2>/dev/null
          fi
        done

    - name: Upload test results
      uses: actions/upload-artifact@5d5d22a31266ced268874388b861e4b58bb5c2f3  # v4.3.1
      if: always()
      with:
        name: test-results-${{ matrix.test-group }}
        path: |
          mvp_site/test-results/
          mvp_site/*.log
        retention-days: 30
        if-no-files-found: warn

    - name: Prepare coverage data
      if: always() && startsWith(matrix.test-group, 'core-mvp-') && github.event_name == 'pull_request'
      run: |
        # Copy coverage data from run_tests.sh output location to workspace
        if [ -f /tmp/worldarchitectai/coverage/.coverage ]; then
          cp /tmp/worldarchitectai/coverage/.coverage ".coverage.${{ matrix.test-group }}"
          echo "âœ… Coverage data copied to workspace"
        elif compgen -G "/tmp/worldarchitectai/coverage/.coverage.*" > /dev/null; then
          "$PWD/venv/bin/python" -m coverage combine /tmp/worldarchitectai/coverage || true
          if [ -f .coverage ]; then
            cp .coverage ".coverage.${{ matrix.test-group }}"
            echo "âœ… Coverage data combined and copied from shard files"
          elif [ -f /tmp/worldarchitectai/coverage/.coverage ]; then
            cp /tmp/worldarchitectai/coverage/.coverage ".coverage.${{ matrix.test-group }}"
            echo "âœ… Coverage data combined and copied from coverage dir"
          else
            echo "::warning::Coverage combine did not produce .coverage output"
          fi
        elif [ -f .coverage ]; then
          cp .coverage ".coverage.${{ matrix.test-group }}"
          echo "âœ… Coverage data copied from workspace"
        else
          echo "::warning::No coverage data found"
        fi

    - name: Upload coverage data
      if: always() && startsWith(matrix.test-group, 'core-mvp-') && github.event_name == 'pull_request'
      uses: actions/upload-artifact@5d5d22a31266ced268874388b861e4b58bb5c2f3  # v4.3.1
      with:
        name: coverage-data-${{ matrix.test-group }}
        path: .coverage.${{ matrix.test-group }}
        if-no-files-found: warn

  # Coverage reporting - processes data from core test group, no duplicate test execution
  coverage-report:
    name: PR Coverage Report
    needs: [test]
    if: always() && github.event_name == 'pull_request' && needs.test.result != 'cancelled'
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write
    timeout-minutes: 5

    steps:
      - name: Checkout repository
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5  # v4.3.1  # v4.1.1
        with:
          fetch-depth: 0  # Full history needed for git diff (delta coverage)

      - name: Set up Python 3.11
        uses: actions/setup-python@0a5c61591373683505ea898e09a3ea4f39ef2b9c  # v5.0.0
        with:
          python-version: '3.11'

      - name: Download coverage data
        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16  # v4.1.8
        with:
          pattern: coverage-data-*
          merge-multiple: true
          path: coverage-data
        continue-on-error: true

      - name: Identify changed Python files
        id: changed_files
        run: |
          # Delta coverage: enforce threshold only on files the PR actually changed.
          # This is compatible with testmon's selective execution â€” even when
          # testmon deselects unchanged tests, coverage data for the changed
          # files comes from the tests that DID run.
          BASE_SHA=${{ github.event.pull_request.base.sha }}
          HEAD_SHA=${{ github.event.pull_request.head.sha }}
          echo "Base: $BASE_SHA"
          echo "Head: $HEAD_SHA"

          CHANGED_PY=$(git diff --name-only --diff-filter=ACMR "$BASE_SHA"..."$HEAD_SHA" -- '*.py' \
            | grep -v '__pycache__' \
            | grep -v '/tests/' \
            | grep -v '/testing_framework/' \
            | grep -v '/venv/' \
            || true)

          if [ -z "$CHANGED_PY" ]; then
            echo "has_changed_py=false" >> $GITHUB_OUTPUT
            echo "::notice::No production Python files changed â€” coverage threshold not applicable"
          else
            echo "has_changed_py=true" >> $GITHUB_OUTPUT
            FILE_COUNT=$(echo "$CHANGED_PY" | wc -l | tr -d ' ')
            echo "changed_count=$FILE_COUNT" >> $GITHUB_OUTPUT
            echo "::notice::$FILE_COUNT production Python file(s) changed â€” delta coverage will be checked"
            echo ""
            echo "Changed production files:"
            echo "$CHANGED_PY" | sed 's/^/  /'

            # Build comma-separated include pattern for coverage CLI
            INCLUDE_PATTERN=$(echo "$CHANGED_PY" | paste -sd ',' -)
            echo "include_pattern=$INCLUDE_PATTERN" >> $GITHUB_OUTPUT
          fi

      - name: Generate coverage report
        id: coverage_check
        run: |
          pip install coverage

          # Create .coveragerc matching the coverage.yml baseline config
          cat > .coveragerc << 'COVEOF'
          [run]
          relative_files = true
          source = mvp_site
          omit =
              */tests/*
              */testing_framework/*
              */venv/*
              */__pycache__/*

          [report]
          exclude_lines =
              pragma: no cover
              def __repr__
              raise NotImplementedError
          COVEOF

          if compgen -G "coverage-data/.coverage*" > /dev/null; then
            echo "has_coverage=true" >> $GITHUB_OUTPUT
            coverage combine coverage-data || echo "Coverage combine skipped"
            coverage report --format=markdown > coverage_report.md || echo "Coverage report generation failed"
            coverage xml -o coverage.xml || echo "Coverage XML generation failed"
            coverage json -o coverage.json || echo "Coverage JSON generation failed"
          else
            echo "has_coverage=false" >> $GITHUB_OUTPUT
            echo "::warning::No coverage data available from test run"
          fi

      - name: Coverage comment (PR)
        if: steps.coverage_check.outputs.has_coverage == 'true'
        uses: py-cov-action/python-coverage-comment-action@fb02115d6115e7b3325dc3295fe1dcfb1919248a  # v3.32
        with:
          GITHUB_TOKEN: ${{ github.token }}
          MINIMUM_GREEN: 80
          MINIMUM_ORANGE: 60
          ANNOTATE_MISSING_LINES: true
          MAX_FILES_IN_COMMENT: 50

      - name: Report delta coverage (per-file, non-blocking)
        if: steps.coverage_check.outputs.has_coverage == 'true' && steps.changed_files.outputs.has_changed_py == 'true'
        run: |
          # Per-file delta coverage: evaluate each changed file independently.
          # This prevents well-tested files from masking under-tested ones
          # in multi-file PRs (and vice versa).

          # --- Exception list: known low-coverage legacy files ---
          # These get a reduced threshold until test coverage improves.
          # Standard files: 60% minimum, 80% recommended
          # Exception files: 30% minimum (still enforces SOME coverage)
          LOW_COVERAGE_FILES="mvp_site/main.py mvp_site/start_flask.py mvp_site/llm_providers/openclaw_provider.py mvp_site/streaming_chunk_logger.py mvp_site/firestore_service.py mvp_site/llm_providers/provider_utils.py mvp_site/llm_service.py mvp_site/settings_validation.py mvp_site/world_logic.py"
          STANDARD_MIN=60
          STANDARD_REC=80
          REDUCED_MIN=30

          echo "=== Per-file delta coverage check ==="
          echo "Standard threshold: ${STANDARD_MIN}% min / ${STANDARD_REC}% recommended"
          echo "Reduced threshold (legacy files): ${REDUCED_MIN}% min"
          echo "Legacy exception list: $LOW_COVERAGE_FILES"
          echo ""

          FAILED=0
          WARNED=0
          PASSED=0
          SKIPPED=0
          SUMMARY=""

          IFS=',' read -ra FILES <<< "${{ steps.changed_files.outputs.include_pattern }}"
          for FILE in "${FILES[@]}"; do
            # Get coverage for this single file
            FILE_REPORT=$(coverage report --include="$FILE" 2>/dev/null || true)

            if [ -z "$FILE_REPORT" ]; then
              SKIPPED=$((SKIPPED + 1))
              SUMMARY="${SUMMARY}âšª ${FILE}: no coverage data (skipped)\n"
              continue
            fi

            # Parse coverage percentage
            COV=$(echo "$FILE_REPORT" | grep -v "^Name\|^-" | grep "$FILE" | awk '{print $NF}' | tr -d '%')
            if ! [[ "$COV" =~ ^[0-9]+$ ]]; then
              COV=$(echo "$FILE_REPORT" | tail -1 | awk '{print $NF}' | tr -d '%')
            fi

            if ! [[ "$COV" =~ ^[0-9]+$ ]]; then
              SKIPPED=$((SKIPPED + 1))
              SUMMARY="${SUMMARY}âšª ${FILE}: coverage parse failed (skipped)\n"
              continue
            fi

            # Determine threshold for this file
            IS_EXCEPTION=false
            for EX in $LOW_COVERAGE_FILES; do
              if [ "$FILE" = "$EX" ]; then
                IS_EXCEPTION=true
                break
              fi
            done

            if [ "$IS_EXCEPTION" = true ]; then
              MIN_THRESH=$REDUCED_MIN
              THRESH_LABEL="reduced"
            else
              MIN_THRESH=$STANDARD_MIN
              THRESH_LABEL="standard"
            fi

            # Evaluate
            if [ "$COV" -lt "$MIN_THRESH" ]; then
              FAILED=$((FAILED + 1))
              SUMMARY="${SUMMARY}âŒ ${FILE}: ${COV}% (${THRESH_LABEL} min: ${MIN_THRESH}%)\n"
              echo "::warning::${FILE} coverage ${COV}% is below ${THRESH_LABEL} minimum of ${MIN_THRESH}% (report-only)"
            elif [ "$IS_EXCEPTION" = false ] && [ "$COV" -lt "$STANDARD_REC" ]; then
              WARNED=$((WARNED + 1))
              SUMMARY="${SUMMARY}âš ï¸  ${FILE}: ${COV}% (below recommended ${STANDARD_REC}%)\n"
              echo "::warning::${FILE} coverage ${COV}% is below recommended ${STANDARD_REC}%"
            else
              PASSED=$((PASSED + 1))
              if [ "$IS_EXCEPTION" = true ]; then
                SUMMARY="${SUMMARY}âœ… ${FILE}: ${COV}% (legacy file, reduced threshold)\n"
              else
                SUMMARY="${SUMMARY}âœ… ${FILE}: ${COV}%\n"
              fi
            fi
          done

          echo ""
          echo "=== Per-file results ==="
          echo -e "$SUMMARY"
          echo "Totals: $PASSED passed, $WARNED warned, $FAILED failed, $SKIPPED skipped"

          # Show overall project coverage for context
          TOTAL_COV=$(coverage report 2>/dev/null | grep "^TOTAL" | awk '{print $NF}' | tr -d '%' || echo "?")
          echo "Overall project coverage: ${TOTAL_COV}%"

          if [ "$FAILED" -gt 0 ]; then
            echo ""
            echo "::warning::$FAILED file(s) are below coverage threshold (report-only mode; not failing CI)"
          fi

      - name: Post coverage summary
        if: always()
        run: |
          echo "## Coverage Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ -f coverage_report.md ]; then
            cat coverage_report.md >> $GITHUB_STEP_SUMMARY
          else
            echo "No coverage data available for this PR." >> $GITHUB_STEP_SUMMARY
          fi
