#!/usr/bin/env python3
"""
Command Output Trimmer Hook - OPTIMIZED VERSION
Reduces slash command token consumption by 50-70% with <5ms overhead.
"""

import sys
import re
import json
import os
import time
import threading
from collections import deque
from typing import List, Dict, Optional, Pattern, Any
from dataclasses import dataclass

@dataclass
class CompressionStats:
    """Statistics about output compression performance."""
    original_size: int = 0
    compressed_size: int = 0
    bytes_saved: int = 0
    compression_ratio: float = 0.0
    original_lines: int = 0
    compressed_lines: int = 0
    lines_saved: int = 0
    processing_time_ms: float = 0.0
    command_type: str = 'unknown'

    def __post_init__(self):
        """Calculate derived metrics."""
        self.bytes_saved = max(0, self.original_size - self.compressed_size)
        self.lines_saved = max(0, self.original_lines - self.compressed_lines)
        if self.original_size > 0:
            self.compression_ratio = min(1.0, self.bytes_saved / self.original_size)

    @classmethod
    def from_compression(cls, original_output: str, compressed_output: str,
                        processing_time_ms: float = 0.0, command_type: str = 'unknown') -> 'CompressionStats':
        """Create CompressionStats from original and compressed output."""
        original_size = len(original_output.encode('utf-8'))
        compressed_size = len(compressed_output.encode('utf-8'))
        original_lines = len(original_output.splitlines())
        compressed_lines = len(compressed_output.splitlines())

        return cls(
            original_size=original_size,
            compressed_size=compressed_size,
            original_lines=original_lines,
            compressed_lines=compressed_lines,
            processing_time_ms=processing_time_ms,
            command_type=command_type
        )

# Configuration constants to replace magic numbers
class Config:
    # Sample size for command detection (chars)
    DETECTION_SAMPLE_SIZE = 500
    # Threshold for aggressive trimming (lines)
    AGGRESSIVE_TRIM_THRESHOLD = 100
    # Default max lines for fast trim
    FAST_TRIM_MAX_LINES = 50
    # First N lines to keep in fast trim
    FAST_TRIM_KEEP_FIRST = 25
    # Last N lines to keep in fast trim
    FAST_TRIM_KEEP_LAST = 25
    # Maximum input size to prevent DoS (10MB)
    MAX_INPUT_SIZE = 10 * 1024 * 1024
    # Performance warning threshold in ms
    PERFORMANCE_WARNING_THRESHOLD = 10
    # Maximum stats entries to keep
    MAX_STATS_ENTRIES = 1000
    # Stats reset threshold
    STATS_RESET_THRESHOLD = 10000
    # Argument length limit to prevent DoS
    ARG_LENGTH_LIMIT = 1000

class OptimizedCommandOutputTrimmer:
    # Pre-compiled regex patterns for performance
    COMMAND_PATTERNS: Dict[str, Pattern] = {
        'test': re.compile(r'(Running tests|PASSED|FAILED|test_\w+|pytest|unittest)', re.IGNORECASE),
        'pushl': re.compile(r'(git push|PR #\d+|Labels applied|Pushing to|origin/)', re.IGNORECASE),
        'copilot': re.compile(r'(Phase \d+|COPILOT|Comment coverage|‚è±Ô∏è EXECUTION TIMING)', re.IGNORECASE),
        'coverage': re.compile(r'(Coverage report|TOTAL.*\d+%|\.py\s+\d+\s+\d+\s+\d+%)', re.IGNORECASE),
        'execute': re.compile(r'(TODO:|‚úÖ COMPLETED|üîÑ IN PROGRESS|TodoWrite tool)', re.IGNORECASE),
        'cerebras': re.compile(r'(Cerebras|üöÄ SPEED|Token generation)', re.IGNORECASE),
        'orchestrate': re.compile(r'(orchestration|tmux|task-agent-|Redis coordination)', re.IGNORECASE)
    }

    # Thread-safe singleton pattern
    _instance = None
    _config = None
    _lock = threading.Lock()

    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:  # Double-check pattern
                    cls._instance = super().__new__(cls)
                    cls._instance._initialize()
        return cls._instance

    @classmethod
    def _reset_singleton_for_testing(cls):
        """Reset singleton for testing purposes only"""
        with cls._lock:
            cls._instance = None
            cls._config = None

    def _initialize(self):
        """One-time initialization with bounded statistics"""
        self.config = self._load_config_once()
        # Use bounded collections to prevent memory leaks
        self.recent_stats = deque(maxlen=Config.MAX_STATS_ENTRIES)
        self.stats_summary = {'total_saved': 0, 'count': 0, 'total_original': 0, 'total_trimmed': 0}
        self.perf_stats = deque(maxlen=Config.MAX_STATS_ENTRIES)

    def _load_config_once(self) -> dict:
        """Load configuration once and cache it"""
        if OptimizedCommandOutputTrimmer._config is None:
            settings_path = os.path.expanduser('~/.claude/settings.json')
            default_config = {
                'enabled': True,
                'compression_threshold': 0.2,
                'log_statistics': False,  # Disabled by default for performance
                'preserve_errors': True,
                'max_output_lines': 100,
                'performance_mode': True,  # New flag for aggressive optimization
                'passthrough_markers': [
                    '[claude:show-full-output]',
                    '[claude:full-output]',
                    '[claude:no-trim]'
                ],
                'passthrough_requests': [
                    'show full output',
                    'show the full output',
                    'show output',
                    'display full output',
                    'need the full output',
                    'full command output'
                ],
                'custom_rules': {
                    'test': {'max_passed_tests': 3, 'preserve_failures': True},
                    'pushl': {'max_git_lines': 5, 'preserve_pr_links': True},
                    'copilot': {'max_timing_lines': 2, 'preserve_phases': True},
                    'coverage': {'max_file_lines': 10, 'preserve_summary': True},
                    'execute': {'max_explanation_lines': 5, 'preserve_todos': True}
                }
            }

            try:
                if os.path.exists(settings_path):
                    with open(settings_path, 'r') as f:
                        settings = json.load(f)
                        if 'output_trimmer' in settings:
                            user_config = settings['output_trimmer']
                            # Validate config for solo dev debugging efficiency
                            validated_config = self._validate_config(user_config, settings_path)
                            default_config.update(validated_config)
            except FileNotFoundError:
                # Settings file doesn't exist - use defaults (normal case)
                pass
            except json.JSONDecodeError as e:
                # Malformed JSON - help solo dev debug quickly
                sys.stderr.write(f"‚ö†Ô∏è CONFIG ERROR: {settings_path} has invalid JSON at line {e.lineno}: {e.msg}\n")
                sys.stderr.write("Using default configuration. Fix JSON syntax to customize output trimmer.\n")
            except Exception as e:
                # Other errors - provide helpful context for debugging
                sys.stderr.write(f"‚ö†Ô∏è CONFIG WARNING: Error loading {settings_path}: {e}\n")
                sys.stderr.write("Using default configuration. Check file permissions and format.\n")

            OptimizedCommandOutputTrimmer._config = default_config

        return OptimizedCommandOutputTrimmer._config

    def _validate_config(self, user_config: dict, settings_path: str) -> dict:
        """Validate user configuration with helpful error messages for solo dev debugging"""
        validated = {}

        # Define expected types for key config values
        expected_types = {
            'enabled': bool,
            'compression_threshold': (int, float),
            'log_statistics': bool,
            'preserve_errors': bool,
            'max_output_lines': int,
            'performance_mode': bool
        }

        for key, value in user_config.items():
            if key in expected_types:
                expected_type = expected_types[key]
                # Handle both single type and tuple of types
                if isinstance(expected_type, tuple):
                    if not isinstance(value, expected_type):
                        sys.stderr.write(f"‚ö†Ô∏è CONFIG: {settings_path} - '{key}' should be {' or '.join(t.__name__ for t in expected_type)}, got {type(value).__name__}. Using default.\n")
                        continue
                else:
                    if not isinstance(value, expected_type):
                        sys.stderr.write(f"‚ö†Ô∏è CONFIG: {settings_path} - '{key}' should be {expected_type.__name__}, got {type(value).__name__}. Using default.\n")
                        continue

                # Additional validation for specific keys
                if key == 'compression_threshold' and not (0.0 <= value <= 1.0):
                    sys.stderr.write(f"‚ö†Ô∏è CONFIG: {settings_path} - 'compression_threshold' should be between 0.0 and 1.0, got {value}. Using default.\n")
                    continue
                elif key == 'max_output_lines' and value < 1:
                    sys.stderr.write(f"‚ö†Ô∏è CONFIG: {settings_path} - 'max_output_lines' should be positive, got {value}. Using default.\n")
                    continue

            # Accept the validated value
            validated[key] = value

        return validated

    def detect_command_type(self, output: str) -> str:
        """Detect command type using pre-compiled patterns"""
        # Quick check on first N chars for performance
        sample = output[:Config.DETECTION_SAMPLE_SIZE] if len(output) > Config.DETECTION_SAMPLE_SIZE else output

        for cmd_type, pattern in self.COMMAND_PATTERNS.items():
            if pattern.search(sample):
                return cmd_type
        return 'generic'

    def fast_trim(self, lines: List[str], max_lines: int = None) -> List[str]:
        """Ultra-fast generic trimming with intelligent middle summarization"""
        if max_lines is None:
            max_lines = Config.FAST_TRIM_MAX_LINES

        if len(lines) <= max_lines:
            return lines

        # Keep first N and last M lines based on config
        keep_total = Config.FAST_TRIM_KEEP_FIRST + Config.FAST_TRIM_KEEP_LAST
        trimmed = lines[:Config.FAST_TRIM_KEEP_FIRST]

        # Summarize the middle section instead of just excluding it
        middle_lines = lines[Config.FAST_TRIM_KEEP_FIRST:-Config.FAST_TRIM_KEEP_LAST]
        summary = self._summarize_middle_content(middle_lines)
        trimmed.extend(summary)

        trimmed.extend(lines[-Config.FAST_TRIM_KEEP_LAST:])
        return trimmed

    def _summarize_middle_content(self, middle_lines: List[str], max_summary_lines: int = 25) -> List[str]:
        """
        Create an intelligent summary of middle content with bounded memory usage.
        Extracts key patterns, errors, URLs, and important information.

        Args:
            middle_lines: Lines to summarize
            max_summary_lines: Maximum lines in summary to prevent unbounded growth
        """
        if not middle_lines:
            return []

        summary_lines = []
        summary_lines.append(f"\n... [SUMMARY of {len(middle_lines)} middle lines] ...")

        # Extract important patterns from middle content with collection limits
        MAX_COLLECTED_ITEMS = 10  # Prevent memory exhaustion
        errors = []
        urls = []
        important_info = []
        status_updates = []

        for line in middle_lines:
            line_stripped = line.strip()
            if not line_stripped:
                continue

            # Limit line length to prevent individual long lines from causing issues
            if len(line_stripped) > 200:
                line_stripped = line_stripped[:200] + "..."

            # Collect errors and warnings (with limit)
            if len(errors) < MAX_COLLECTED_ITEMS and any(pattern in line.upper() for pattern in ['ERROR', 'FAILED', 'EXCEPTION', 'WARNING']):
                errors.append(line_stripped)

            # Collect URLs (with limit)
            if len(urls) < MAX_COLLECTED_ITEMS and 'http' in line and ('://' in line):
                urls.append(line_stripped)

            # Collect status indicators (with limit)
            if len(status_updates) < MAX_COLLECTED_ITEMS and any(pattern in line for pattern in ['‚úÖ', '‚ùå', 'üîÑ', 'PASSED', 'SUCCESS', 'COMPLETED']):
                status_updates.append(line_stripped)

            # Collect PR/commit references (with limit)
            if len(important_info) < MAX_COLLECTED_ITEMS and any(pattern in line for pattern in ['PR #', 'commit', 'merge', 'branch']):
                important_info.append(line_stripped)

        # Add collected information to summary (limit each category)
        if errors:
            summary_lines.append("  Errors/Warnings found:")
            for error in errors[:3]:  # Limit to first 3 errors
                summary_lines.append(f"    ‚Ä¢ {error}")
            if len(errors) > 3:
                summary_lines.append(f"    ... and {len(errors) - 3} more errors")

        if urls:
            summary_lines.append("  URLs found:")
            for url in urls[:2]:  # Limit to first 2 URLs
                summary_lines.append(f"    ‚Ä¢ {url}")
            if len(urls) > 2:
                summary_lines.append(f"    ... and {len(urls) - 2} more URLs")

        if status_updates:
            summary_lines.append("  Status updates:")
            for status in status_updates[:5]:  # Limit to first 5 status updates
                summary_lines.append(f"    ‚Ä¢ {status}")
            if len(status_updates) > 5:
                summary_lines.append(f"    ... and {len(status_updates) - 5} more status updates")

        if important_info:
            summary_lines.append("  Important references:")
            for info in important_info[:3]:  # Limit to first 3 references
                summary_lines.append(f"    ‚Ä¢ {info}")
            if len(important_info) > 3:
                summary_lines.append(f"    ... and {len(important_info) - 3} more references")

        # If no important patterns found, show basic stats
        if not (errors or urls or status_updates or important_info):
            # Count unique line patterns
            unique_patterns = set()
            for line in middle_lines[:20]:  # Sample first 20 lines
                # Extract first few words as pattern
                words = line.strip().split()[:3]
                if words:
                    pattern = ' '.join(words)
                    unique_patterns.add(pattern)

            summary_lines.append(f"  Content types found: {len(unique_patterns)} different patterns")
            if unique_patterns:
                summary_lines.append("  Sample patterns:")
                for pattern in list(unique_patterns)[:3]:
                    summary_lines.append(f"    ‚Ä¢ {pattern}...")

        summary_lines.append("... [END SUMMARY] ...\n")

        # Cap summary length to prevent unbounded growth
        if max_summary_lines > 0 and len(summary_lines) > max_summary_lines:
            summary_lines = summary_lines[:max_summary_lines - 1]
            summary_lines.append("... [SUMMARY TRUNCATED] ...\n")

        return summary_lines

    def _should_bypass(self, output: str) -> bool:
        """Determine if trimming should be skipped entirely."""
        # Respect global enable flag first
        if not self.config.get('enabled', True):
            return True

        # Allow interactive overrides via environment variables
        env_toggle = os.environ.get('CLAUDE_TRIMMER_DISABLE', '')
        if env_toggle.lower() in {'1', 'true', 'yes', 'on'}:
            return True

        env_mode = os.environ.get('CLAUDE_TRIMMER_MODE', '').strip().lower()
        if env_mode in {'off', 'disable', 'disabled', 'passthrough', 'raw', 'full'}:
            return True

        # Normalize different output views lazily so we only compute them once
        lowered_output: Optional[str] = None
        collapsed_output: Optional[str] = None
        collapsed_lowered_output: Optional[str] = None

        def get_lowered_output() -> str:
            nonlocal lowered_output
            if lowered_output is None:
                lowered_output = output.lower()
            return lowered_output

        def get_collapsed_output() -> str:
            nonlocal collapsed_output
            if collapsed_output is None:
                # Collapse all whitespace to single spaces to make natural-language
                # matching resilient to formatting differences.
                collapsed_output = re.sub(r'\s+', ' ', output)
            return collapsed_output

        def get_collapsed_lowered_output() -> str:
            nonlocal collapsed_lowered_output
            if collapsed_lowered_output is None:
                collapsed_lowered_output = get_collapsed_output().lower()
            return collapsed_lowered_output

        # Allow configurable magic markers inside the output
        markers = self.config.get('passthrough_markers', [])
        if markers:
            lowered_markers_view = get_lowered_output()
            for marker in markers:
                if marker and marker.lower() in lowered_markers_view:
                    return True

        # Detect natural language requests for full output
        requests = self.config.get('passthrough_requests', [])
        if requests:
            for request in requests:
                if not request:
                    continue
                if isinstance(request, dict) and 'regex' in request:
                    pattern = request.get('regex')
                    if not isinstance(pattern, str):
                        continue
                    try:
                        compiled = re.compile(pattern, re.IGNORECASE)
                    except re.error:
                        continue

                    # Check both the original output and the collapsed view while
                    # reusing the cached normalization to avoid redundant work.
                    if compiled.search(output) or compiled.search(get_collapsed_output()):
                        return True
                elif isinstance(request, str):
                    if request.lower() in get_collapsed_lowered_output():
                        return True

        return False

    def process_output(self, output: str) -> str:
        """Main processing with performance tracking"""
        if self._should_bypass(output):
            return output

        # Performance tracking
        start_time = time.perf_counter() if self.config.get('performance_mode') else 0

        lines = output.split('\n')
        original_count = len(lines)

        # Quick exit for small outputs
        if original_count < 20:
            return output

        # Performance mode: aggressive trimming
        if self.config.get('performance_mode') and original_count > Config.AGGRESSIVE_TRIM_THRESHOLD:
            trimmed_lines = self.fast_trim(lines, Config.FAST_TRIM_MAX_LINES)
        else:
            # Standard mode: smart trimming
            cmd_type = self.detect_command_type(output)

            if cmd_type == 'test':
                trimmed_lines = self.trim_test_output(lines)
            elif cmd_type == 'pushl':
                trimmed_lines = self.trim_pushl_output(lines)
            elif cmd_type == 'copilot':
                trimmed_lines = self.trim_copilot_output(lines)
            else:
                trimmed_lines = self.fast_trim(lines)

        # Calculate compression
        trimmed_count = len(trimmed_lines)
        compression_ratio = 1 - (trimmed_count / original_count) if original_count > 0 else 0

        # Track performance with bounded collection
        if self.config.get('performance_mode'):
            elapsed = (time.perf_counter() - start_time) * 1000  # Convert to ms
            # Store in bounded deque to prevent memory leak
            self.perf_stats.append({
                'time': elapsed,
                'lines': original_count,
                'compression': compression_ratio
            })

            # Add performance footer only if very slow
            if elapsed > Config.PERFORMANCE_WARNING_THRESHOLD:
                trimmed_lines.append(f"[Trimmer: {elapsed:.1f}ms]")

        if compression_ratio >= self.config['compression_threshold']:
            # Update bounded statistics to prevent memory leak
            self._update_stats(original_count, trimmed_count)

            # Store recent stat for analysis
            self.recent_stats.append({
                'original': original_count,
                'trimmed': trimmed_count,
                'ratio': compression_ratio
            })

            return '\n'.join(trimmed_lines)
        else:
            return output

    def _update_stats(self, original_count: int, trimmed_count: int):
        """Update statistics with automatic reset to prevent memory leaks"""
        self.stats_summary['total_original'] += original_count
        self.stats_summary['total_trimmed'] += trimmed_count
        self.stats_summary['count'] += 1

        # Calculate and update saved lines
        lines_saved = original_count - trimmed_count
        if lines_saved > 0:
            self.stats_summary['total_saved'] += lines_saved

        # Reset summary periodically to prevent unbounded growth
        if self.stats_summary['count'] > Config.STATS_RESET_THRESHOLD:
            self.stats_summary = {
                'total_original': 0,
                'total_trimmed': 0,
                'count': 0,
                'total_saved': 0
            }

    def trim_test_output(self, lines: List[str]) -> List[str]:
        """Optimized test output compression"""
        config = self.config['custom_rules']['test']
        trimmed = []
        passed_count = 0
        total_passed = sum(1 for line in lines if 'PASSED' in line.upper())

        for line in lines:
            # Fast check for important lines
            line_upper = line.upper()
            if 'FAILED' in line_upper or 'ERROR' in line_upper:
                trimmed.append(line)
            elif 'PASSED' in line_upper:
                if passed_count < config['max_passed_tests']:
                    trimmed.append(line)
                    passed_count += 1
            elif len(trimmed) < 20:  # Keep early context
                trimmed.append(line)

        # Add compression indicator if we limited passed tests
        if total_passed > config['max_passed_tests']:
            suppressed = total_passed - config['max_passed_tests']
            trimmed.append(f"... [{suppressed} more passed tests compressed] ...")

        return trimmed

    def trim_pushl_output(self, lines: List[str]) -> List[str]:
        """Optimized pushl output compression"""
        config = self.config['custom_rules']['pushl']
        trimmed = []
        git_lines = 0

        for line in lines:
            # Fast check for PR links
            if 'PR #' in line or 'github.com' in line:
                trimmed.append(line)
            elif 'git' in line.lower() and git_lines < config['max_git_lines']:
                trimmed.append(line)
                git_lines += 1
            elif len(trimmed) < 10:
                trimmed.append(line)

        return trimmed

    def trim_copilot_output(self, lines: List[str]) -> List[str]:
        """Optimized copilot output compression"""
        trimmed = []

        for line in lines:
            # Keep only phase markers and status
            if 'Phase' in line or '‚úÖ' in line or '‚ùå' in line or 'WARNING' in line:
                trimmed.append(line)
            elif len(trimmed) < 5:  # Keep minimal context
                trimmed.append(line)

        return trimmed

    def get_performance_report(self):
        """Get performance statistics from bounded collection"""
        if len(self.perf_stats) > 0:
            recent_times = [stat['time'] for stat in self.perf_stats if 'time' in stat]
            if recent_times:
                avg_time = sum(recent_times) / len(recent_times)
                return f"Avg: {avg_time:.2f}ms over last {len(recent_times)} calls"
        return "No performance data"

    def compress_output(self, output: str) -> tuple[str, 'CompressionStats']:
        """
        Compress the output and return both the compressed output and statistics.

        Args:
            output: The output string to compress

        Returns:
            A tuple containing the compressed output string and CompressionStats object
        """
        compressed_output = self.process_output(output)

        stats = CompressionStats.from_compression(
            original_output=output,
            compressed_output=compressed_output
        )

        return compressed_output, stats

    def trim_args(self, args: Any) -> Any:
        """
        Trim argument length to prevent DoS attacks with proper type preservation and recursion.
        Implements simple length-only trimming without security filtering.

        Args:
            args: Arguments to sanitize (can be list, string, or other types)

        Returns:
            Sanitized arguments with length limits applied and types preserved
        """
        # Defensive programming: validate input types and handle edge cases
        if args is None:
            return None

        if isinstance(args, list):
            trimmed_list = []
            for arg in args:
                # Recurse into nested structures
                if isinstance(arg, (list, dict)):
                    trimmed_list.append(self.trim_args(arg))
                else:
                    arg_str = str(arg)
                    if len(arg_str) > Config.ARG_LENGTH_LIMIT:
                        # Only convert to string if it exceeds the limit
                        trimmed_list.append(arg_str[:Config.ARG_LENGTH_LIMIT])
                    else:
                        # Preserve original type and value if under limit
                        trimmed_list.append(arg)
            return trimmed_list
        elif isinstance(args, str):
            if len(args) > Config.ARG_LENGTH_LIMIT:
                return args[:Config.ARG_LENGTH_LIMIT]
            return args
        elif isinstance(args, dict):
            trimmed_dict = {}
            collision_counter = {}

            for key, value in args.items():
                # Handle nested structures in values
                if isinstance(value, (list, dict)):
                    final_value = self.trim_args(value)
                else:
                    value_str = str(value)
                    final_value = value_str[:Config.ARG_LENGTH_LIMIT] if len(value_str) > Config.ARG_LENGTH_LIMIT else value

                # Handle keys with collision protection and length validation
                key_str = str(key)
                if len(key_str) > Config.ARG_LENGTH_LIMIT:
                    base_key = key_str[:Config.ARG_LENGTH_LIMIT]

                    # Check for key collisions and handle them with length validation
                    if base_key in trimmed_dict or base_key in collision_counter:
                        collision_counter[base_key] = collision_counter.get(base_key, 0) + 1
                        # Create collision suffix and ensure total length doesn't exceed limit
                        suffix = f"__dup{collision_counter[base_key]}"
                        if len(base_key) + len(suffix) > Config.ARG_LENGTH_LIMIT:
                            # Truncate base_key to fit suffix within limit
                            max_base_length = Config.ARG_LENGTH_LIMIT - len(suffix)
                            final_key = base_key[:max_base_length] + suffix
                        else:
                            final_key = base_key + suffix
                    else:
                        final_key = base_key
                        collision_counter[base_key] = 0
                else:
                    final_key = key

                trimmed_dict[final_key] = final_value
            return trimmed_dict
        else:
            # For other types (int, float, bool, etc.), preserve type unless string representation is too long
            arg_str = str(args)
            if len(arg_str) > Config.ARG_LENGTH_LIMIT:
                return arg_str[:Config.ARG_LENGTH_LIMIT]
            return args

    def process_command_output(self, output: str) -> str:
        """
        Alias for process_output method.

        Args:
            output: The output string to process

        Returns:
            The processed output string
        """
        return self.process_output(output)

    def compress_test_output(self, lines: list[str]) -> list[str]:
        """
        Compress test output lines.

        Args:
            lines: List of output lines to compress

        Returns:
            List of compressed output lines
        """
        return self.trim_test_output(lines)

    def compress_pushl_output(self, lines: list[str]) -> list[str]:
        """
        Compress pushl output lines.

        Args:
            lines: List of output lines to compress

        Returns:
            List of compressed output lines
        """
        return self.trim_pushl_output(lines)

    def compress_copilot_output(self, lines: list[str]) -> list[str]:
        """
        Compress copilot output lines.

        Args:
            lines: List of output lines to compress

        Returns:
            List of compressed output lines
        """
        return self.trim_copilot_output(lines)

    def compress_coverage_output(self, lines: list[str]) -> list[str]:
        """
        Compress coverage output lines.

        Args:
            lines: List of output lines to compress

        Returns:
            List of compressed output lines
        """
        # Coverage compression logic - preserve totals and percentages
        trimmed = []
        for line in lines:
            if 'TOTAL' in line or '%' in line or len(trimmed) < 5:
                trimmed.append(line)
        return trimmed

    def compress_execute_output(self, lines: list[str]) -> list[str]:
        """
        Compress execute output lines.

        Args:
            lines: List of output lines to compress

        Returns:
            List of compressed output lines
        """
        # Execute compression logic - preserve TODO states and checklists
        trimmed = []
        for line in lines:
            if '‚úÖ' in line or 'üîÑ' in line or '‚ùå' in line or 'TODO:' in line or '- [' in line:
                trimmed.append(line)
            elif len(trimmed) < 10:  # Keep some early context
                trimmed.append(line)
        return trimmed

    def compress_generic_output(self, lines: list[str]) -> list[str]:
        """
        Compress generic output lines.

        Args:
            lines: List of output lines to compress

        Returns:
            List of compressed output lines
        """
        if len(lines) <= Config.FAST_TRIM_MAX_LINES:
            return lines

        # Preserve important patterns and first/last lines
        trimmed = []

        # Keep first few lines
        trimmed.extend(lines[:Config.FAST_TRIM_KEEP_FIRST])

        # Summarize middle content instead of just excluding it
        middle_lines = lines[Config.FAST_TRIM_KEEP_FIRST:-Config.FAST_TRIM_KEEP_LAST]
        summary = self._summarize_middle_content(middle_lines)
        trimmed.extend(summary)

        # Keep last few lines
        trimmed.extend(lines[-Config.FAST_TRIM_KEEP_LAST:])

        return trimmed


def main():
    """Hook entry point with error handling and input validation"""
    try:
        trimmer = OptimizedCommandOutputTrimmer()

        # Note: trim_args is for API function arguments, not command-line arguments
        # Command-line arguments for this hook don't need sanitization

        # Read input with size limit to prevent DoS (byte-aware)
        stdin_buffer = getattr(sys.stdin, "buffer", None)
        truncated = False

        if stdin_buffer is not None:
            raw_input = stdin_buffer.read(Config.MAX_INPUT_SIZE + 1)
            truncated = len(raw_input) > Config.MAX_INPUT_SIZE
            if truncated:
                raw_input = raw_input[:Config.MAX_INPUT_SIZE]
        else:
            byte_buffer = bytearray()
            while True:
                chunk = sys.stdin.read(1024)
                if not chunk:
                    break

                chunk_bytes = chunk.encode("utf-8")
                remaining = Config.MAX_INPUT_SIZE - len(byte_buffer)

                if remaining <= 0:
                    truncated = True
                    break

                if len(chunk_bytes) > remaining:
                    byte_buffer.extend(chunk_bytes[:remaining])
                    truncated = True
                    break

                byte_buffer.extend(chunk_bytes)

            if not truncated:
                extra_char = sys.stdin.read(1)
                if extra_char:
                    truncated = True

            raw_input = bytes(byte_buffer[:Config.MAX_INPUT_SIZE])

        if truncated:
            sys.stderr.write(f"Warning: Input exceeds {Config.MAX_INPUT_SIZE} bytes, truncating\n")

        input_data = raw_input.decode("utf-8", errors="replace")

        # Process command output directly (trim_args is for function arguments, not output)
        trimmed_output = trimmer.process_output(input_data)

        # Write output
        sys.stdout.write(trimmed_output)
        return 0

    except Exception as e:
        # On any error, pass through original output with full stack trace for debugging
        import traceback
        sys.stderr.write(f"Trimmer error: {e}\n")
        sys.stderr.write(f"Stack trace: {traceback.format_exc()}\n")
        # Attempt to write original data if available
        try:
            sys.stdout.write(input_data)
        except NameError:
            # input_data wasn't defined yet, nothing to pass through
            pass

if __name__ == '__main__':
    main()
