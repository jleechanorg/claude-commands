#!/usr/bin/env python3
"""
System Corrections FORCED E2E Test - Proves LLM Reads and Acts on Corrections

This test FORCES the correction cycle by injecting pending_system_corrections
directly into the game state, then verifying the LLM receives and acts on them.

Unlike test_system_corrections_real_e2e.py which can pass if the LLM "does the
right thing" immediately, this test REQUIRES the correction path to execute.

What this test PROVES:
1. pending_system_corrections are read from game_state by llm_service
2. system_corrections are injected into the LLM request
3. LLM receives the corrections in its input
4. LLM acts on the corrections and fixes rewards_processed

Run locally:
    BASE_URL=http://localhost:8001 python testing_mcp/test_system_corrections_forced_e2e.py

Run against preview:
    BASE_URL=https://preview-url python testing_mcp/test_system_corrections_forced_e2e.py
"""

from __future__ import annotations

import json
import os
import sys
import time
from datetime import datetime, timezone
from pathlib import Path
from typing import Any

# Add project root to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent))

from testing_mcp.dev_server import ensure_server_running, get_base_url
from testing_mcp.lib.campaign_utils import (
    create_campaign,
    process_action,
    get_campaign_state,
)
from testing_mcp.lib.evidence_utils import (
    get_evidence_dir,
    capture_provenance,
    create_evidence_bundle,
)
from testing_mcp.lib.mcp_client import MCPClient

# Configuration
BASE_URL = get_base_url()
USER_ID = f"e2e-forced-corrections-{datetime.now().strftime('%Y%m%d%H%M%S')}"
TEST_NAME = "system_corrections_forced_e2e"


def log(msg: str) -> None:
    """Log with timestamp."""
    ts = datetime.now(timezone.utc).isoformat()
    print(f"[{ts}] {msg}")


def setup_campaign(client: MCPClient) -> str:
    """Create a basic test campaign and return its ID."""
    log("Creating test campaign...")

    campaign_id = create_campaign(
        client,
        user_id=USER_ID,
        title="Forced Corrections Test",
        setting="A dungeon where goblins were just defeated",
    )

    log(f"Created campaign: {campaign_id}")
    return campaign_id


def inject_corrections_directly(client: MCPClient, campaign_id: str) -> dict[str, Any]:
    """
    Use god mode to inject BOTH the discrepancy state AND pending_system_corrections.

    This forces the correction cycle because:
    1. rewards_processed=False (the bug state)
    2. pending_system_corrections contains the error message
    3. The next LLM call MUST receive these corrections
    """
    log("Injecting pending_system_corrections directly via god mode...")

    # The correction message that would be generated by discrepancy detection
    correction_msg = (
        "REWARDS_STATE_ERROR: Combat ended (phase=ended) with summary, "
        "but rewards_processed=False. You MUST set combat_state.rewards_processed=true."
    )

    state_changes = {
        "combat_state": {
            "combat_phase": "ended",
            "in_combat": False,
            "combat_summary": {
                "xp_awarded": 100,
                "enemies_defeated": ["goblin_warrior_001"],
                "outcome": "victory",
            },
            "rewards_processed": False,
        },
        "player_character_data": {
            "experience": {"current": 600},
        },
        "custom_campaign_state": {
            # Mark character creation complete to ensure RewardsAgent is selected
            # (CharacterCreationAgent has higher priority than RewardsAgent)
            "character_creation_completed": True,
            "character_creation_in_progress": False,  # Explicitly disable to avoid contradictory state
            "character_creation_stage": "complete",
        },
        # Force the correction cycle by persisting the correction message in state.
        "pending_system_corrections": [correction_msg],
    }

    result = process_action(
        client,
        user_id=USER_ID,
        campaign_id=campaign_id,
        user_input=f"GOD_MODE_UPDATE_STATE:{json.dumps(state_changes)}",
    )

    log("God mode injection complete")
    has_error = (
        isinstance(result, dict)
        and "error" in result
        and result.get("error") is not None
    )
    return {"success": not has_error, "response": result}


def verify_corrections_in_state(client: MCPClient, campaign_id: str) -> dict[str, Any]:
    """
    Verify that pending_system_corrections was actually set in game state.
    """
    log("Verifying pending_system_corrections in game state...")

    state = get_campaign_state(client, user_id=USER_ID, campaign_id=campaign_id)
    game_state = state.get("game_state", {})

    pending_corrections = game_state.get("pending_system_corrections", [])
    rewards_processed = game_state.get("combat_state", {}).get("rewards_processed", None)

    log(f"Game state pending_system_corrections: {pending_corrections}")
    log(f"Game state rewards_processed: {rewards_processed}")

    return {
        "pending_corrections": pending_corrections,
        "has_pending_corrections": bool(pending_corrections),
        "rewards_processed": rewards_processed,
    }


def trigger_llm_with_corrections(client: MCPClient, campaign_id: str) -> dict[str, Any]:
    """
    Send a normal character mode request.

    The LLM should receive pending_system_corrections in its input and
    act on them by setting rewards_processed=True.

    Note: Using neutral "continue" to avoid InfoAgent trigger (which has
    Priority 4, higher than RewardsAgent Priority 6). InfoAgent matches
    "check my" pattern, preventing RewardsAgent from being selected.
    """
    log("Triggering LLM call that should receive system_corrections...")

    # Small delay to ensure state is fully persisted
    time.sleep(1)

    result = process_action(
        client,
        user_id=USER_ID,
        campaign_id=campaign_id,
        user_input="continue",
        mode="character",
    )

    # Extract relevant fields from response
    narrative = result.get("narrative", "") if isinstance(result, dict) else ""
    state_updates = result.get("state_updates", {}) if isinstance(result, dict) else {}
    system_corrections = result.get("system_corrections", []) if isinstance(result, dict) else []

    # CRITICAL: Extract game_state from API response - this is the PERSISTED state
    # BEFORE any subsequent reads trigger cleanup. This is the strongest proof.
    api_game_state = result.get("game_state", {}) if isinstance(result, dict) else {}
    api_combat_state = api_game_state.get("combat_state", {})
    api_rewards_processed = api_combat_state.get("rewards_processed", None)
    api_combat_summary = api_combat_state.get("combat_summary")
    api_combat_phase = api_combat_state.get("combat_phase", "")

    # Also check state_updates for what LLM explicitly returned
    state_updates_combat = state_updates.get("combat_state", {})
    llm_rewards_processed = state_updates_combat.get("rewards_processed", None)

    log(f"LLM state_updates rewards_processed: {llm_rewards_processed}")
    log(f"API game_state rewards_processed: {api_rewards_processed} (PERSISTED STATE)")
    log(f"API game_state combat_phase: {api_combat_phase}")
    log(f"API game_state combat_summary present: {api_combat_summary is not None}")
    log(f"LLM response system_corrections: {system_corrections}")
    log(f"Narrative snippet: {narrative[:200]}..." if len(narrative) > 200 else f"Narrative: {narrative}")

    return {
        "response": result,
        "rewards_processed": llm_rewards_processed,
        "api_rewards_processed": api_rewards_processed,  # The persisted state
        "api_combat_phase": api_combat_phase,
        "api_combat_summary_present": api_combat_summary is not None,
        "system_corrections": system_corrections,
        "narrative": narrative,
    }


def verify_final_state(client: MCPClient, campaign_id: str) -> dict[str, Any]:
    """
    Verify the final game state reflects completed rewards processing.

    IMPORTANT: When get_campaign_state is called and finds rewards_processed=True,
    _prepare_game_state archives the combat and resets rewards_processed=False.
    This is by design - after rewards are processed, combat state is cleaned up.

    So successful verification shows:
    - rewards_processed=False (reset after cleanup)
    - combat_summary=None (archived)
    - pending_corrections=[] (consumed)
    """
    log("Verifying final game state...")

    state = get_campaign_state(client, user_id=USER_ID, campaign_id=campaign_id)
    game_state = state.get("game_state", {})

    combat_state = game_state.get("combat_state", {})
    rewards_processed = combat_state.get("rewards_processed", False)
    combat_summary = combat_state.get("combat_summary")
    combat_phase = combat_state.get("combat_phase", "")
    pending_corrections = game_state.get("pending_system_corrections", [])

    log(f"Final rewards_processed: {rewards_processed}")
    log(f"Final combat_summary: {combat_summary}")
    log(f"Final combat_phase: {combat_phase}")
    log(f"Final pending_system_corrections: {pending_corrections}")

    # Success means cleanup happened: no combat_summary, phase=idle, no pending corrections
    cleanup_happened = (
        combat_summary is None
        and combat_phase == "idle"
        and not pending_corrections
    )

    return {
        "rewards_processed": rewards_processed,
        "combat_summary": combat_summary,
        "combat_phase": combat_phase,
        "pending_corrections": pending_corrections,
        "cleanup_happened": cleanup_happened,
        "success": cleanup_happened,  # Cleanup = proof that rewards_processed was True
    }


def run_test() -> dict[str, Any]:
    """Run the forced corrections test."""
    log("=" * 70)
    log("FORCED SYSTEM CORRECTIONS E2E TEST")
    log("=" * 70)
    log(f"BASE_URL: {BASE_URL}")
    log(f"USER_ID: {USER_ID}")

    # Ensure server is running
    ensure_server_running(BASE_URL)

    # Create MCP client
    client = MCPClient(BASE_URL)
    log("Server is healthy")

    results = {
        "test_name": TEST_NAME,
        "user_id": USER_ID,
        "base_url": BASE_URL,
        "timestamp": datetime.now(timezone.utc).isoformat(),
        "steps": {},
    }

    try:
        # Step 1: Create campaign
        log("")
        log("=" * 60)
        log("STEP 1: Creating test campaign")
        log("=" * 60)
        campaign_id = setup_campaign(client)
        results["campaign_id"] = campaign_id
        results["steps"]["create_campaign"] = {"success": True, "campaign_id": campaign_id}

        # Step 2: Inject corrections directly
        log("")
        log("=" * 60)
        log("STEP 2: Inject pending_system_corrections via god mode")
        log("=" * 60)
        inject_result = inject_corrections_directly(client, campaign_id)
        results["steps"]["inject_corrections"] = inject_result

        # Step 3: Verify corrections are in state
        log("")
        log("=" * 60)
        log("STEP 3: Verify pending_system_corrections in game state")
        log("=" * 60)
        verify_result = verify_corrections_in_state(client, campaign_id)
        results["steps"]["verify_injected"] = verify_result

        if not verify_result["has_pending_corrections"]:
            log("WARNING: pending_system_corrections not found in game state!")
            log("God mode may not have set it correctly. Continuing anyway...")

        # Step 4: Trigger LLM with corrections
        log("")
        log("=" * 60)
        log("STEP 4: Trigger LLM call that receives system_corrections")
        log("=" * 60)
        llm_result = trigger_llm_with_corrections(client, campaign_id)
        results["steps"]["llm_with_corrections"] = llm_result

        # Step 5: Verify final state
        log("")
        log("=" * 60)
        log("STEP 5: Verify final game state")
        log("=" * 60)
        final_result = verify_final_state(client, campaign_id)
        results["steps"]["final_verification"] = final_result

        # Determine overall success based on FULL CYCLE with STRONGEST PROOF:
        # 1. Corrections were injected and persisted
        # 2. LLM received corrections and responded with fix
        # 3. API response game_state shows rewards_processed=True (PERSISTED STATE)
        # 4. Subsequent read triggers cleanup (confirms persistence worked)
        llm_responded_correctly = llm_result.get("rewards_processed") is True
        api_state_correct = llm_result.get("api_rewards_processed") is True
        cleanup_happened = final_result.get("cleanup_happened", False)

        # Full cycle success = all conditions met
        results["success"] = (
            verify_result["has_pending_corrections"]
            and llm_responded_correctly
            and api_state_correct
            and cleanup_happened
        )

        # Generate summary
        log("")
        log("=" * 70)
        log("TEST SUMMARY")
        log("=" * 70)

        if verify_result["has_pending_corrections"]:
            log("✅ Step 1: pending_system_corrections was injected into game state")
        else:
            log("❌ Step 1: pending_system_corrections was NOT found in game state after injection")

        if llm_responded_correctly:
            log("✅ Step 2: LLM state_updates contains rewards_processed=True")
        else:
            log("❌ Step 2: LLM did NOT return rewards_processed=True in state_updates")

        if api_state_correct:
            log("✅ Step 3: API response game_state has rewards_processed=True (PERSISTED TO FIRESTORE)")
            log(f"   → combat_phase={llm_result.get('api_combat_phase')}")
            log(f"   → combat_summary present={llm_result.get('api_combat_summary_present')}")
        else:
            log("❌ Step 3: API response game_state does NOT have rewards_processed=True")
            log(f"   → api_rewards_processed={llm_result.get('api_rewards_processed')}")

        if cleanup_happened:
            log("✅ Step 4: Subsequent read triggered cleanup (confirms persistence)")
            log("   → combat_summary archived, phase=idle, rewards_processed reset to False")
        else:
            log("❌ Step 4: Combat state was NOT cleaned up")
            log(f"   → combat_summary={final_result.get('combat_summary')}")
            log(f"   → combat_phase={final_result.get('combat_phase')}")

        if results["success"]:
            log("")
            log("SUCCESS: FULL CORRECTION CYCLE COMPLETED WITH STRONGEST PROOF!")
            log("Chain: corrections injected → LLM received → LLM fixed → PERSISTED TRUE → cleanup triggered")
        else:
            log("")
            log("FAILED: The correction cycle did not complete successfully.")

    except Exception as e:
        log(f"ERROR: {e}")
        results["error"] = str(e)
        results["success"] = False
        raise

    finally:
        # Save evidence
        evidence_dir = get_evidence_dir(TEST_NAME)
        log(f"\nEvidence saved to: {evidence_dir}")

        # Create evidence bundle with provenance
        provenance = capture_provenance(BASE_URL)
        create_evidence_bundle(
            evidence_dir,
            test_name=TEST_NAME,
            provenance=provenance,
            results=results,
        )

    return results


if __name__ == "__main__":
    try:
        results = run_test()
        sys.exit(0 if results.get("success") else 1)
    except KeyboardInterrupt:
        log("\nTest interrupted by user")
        sys.exit(130)
    except Exception as e:
        log(f"\nTest failed with error: {e}")
        sys.exit(1)
