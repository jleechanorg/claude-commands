name: WorldArchitect Tests

# When to run the tests
on:
  push:
    branches: [ main, dev ]  # Run on pushes to these branches
  pull_request:
    branches: [ main ]       # Run on PRs targeting main

jobs:
  test:
    runs-on: ubuntu-latest
    timeout-minutes: 15  # Prevent infinite CI runs - kill job after 15 minutes
    strategy:
      fail-fast: false  # Continue other jobs even if one fails
      matrix:
        test-group: [all-tests, commands, import-validation-delta]

    steps:
    # Step 1: Get your code
    - name: Checkout repository
      uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11  # v4.1.1
      with:
        submodules: recursive

    # Step 2: Set up Python (same version as your project)
    - name: Set up Python 3.11
      uses: actions/setup-python@0a5c61591373683505ea898e09a3ea4f39ef2b9c  # v5.0.0
      with:
        python-version: '3.11'

    # Step 3: Cache dependencies (speeds up future runs)
    - name: Cache pip dependencies
      uses: actions/cache@0400d5f644dc74513175e3cd8d07132dd4860809  # v4.2.4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    # Step 4: Create virtual environment and install dependencies (required for vpython)
    - name: Install dependencies
      run: |
        # Remove any existing venv from previous runs to prevent conflicts
        rm -rf venv
        # Create virtual environment that vpython expects
        python -m venv venv
        source venv/bin/activate

        # Upgrade pip and install resolver tools with timeout
        timeout 300 python -m pip install --upgrade pip setuptools wheel

        # Install all requirements files in the project with timeouts
        # Core application requirements
        timeout 600 pip install -r mvp_site/requirements.txt

        # Install additional requirements for MCP servers and testing with individual timeouts
        find . -name "requirements.txt" -not -path "./venv/*" -not -path "./task-agent*" | while read req_file; do
          echo "Installing $req_file (with 300s timeout)"
          timeout 300 pip install -r "$req_file" || echo "Warning: Failed to install $req_file (timeout or error)"
        done

        # Verify key dependencies are available with timeout
        timeout 60 python -c "import pydantic; print(f'Pydantic {pydantic.__version__} installed')"
        timeout 60 python -c "import sys; print(f'Python path: {sys.path}')"

        # Verify vpython works with timeout
        chmod +x vpython
        timeout 60 ./vpython --version

    # Step 5: Run test group based on matrix strategy
    - name: Run test group - ${{ matrix.test-group }}
      run: |
        # Activate the virtual environment
        source venv/bin/activate

        # Verify environment is correct
        echo "Current Python: $(which python3)"
        echo "Virtual env: $VIRTUAL_ENV"
        python3 -c "import pydantic; print(f'‚úÖ Pydantic {pydantic.__version__} available')"

        # Set CI environment variables for GitHub Actions
        export TESTING=true
        export MOCK_SERVICES_MODE=true
        export FAST_TESTS=1
        export ENABLE_BROWSER_TESTS=0
        export ENABLE_BUILD_TESTS=0
        export ENABLE_NETWORK_TESTS=0
        export GITHUB_ACTIONS=true

        # Run specific test group based on matrix
        chmod +x run_tests.sh
        case "${{ matrix.test-group }}" in
          "all-tests")
            echo "üîó Running ALL tests (comprehensive, eliminates unit/integration overlap)..."
            ./run_tests.sh --integration --parallel
            ;;
          "commands")
            echo "‚öôÔ∏è  Running COMMAND utility tests..."
            export PYTHONPATH="${PYTHONPATH}:${PWD}/.claude/commands"
            # Find and run command tests
            test_count=0
            failed_count=0
            if [ -d ".claude/commands/tests" ]; then
              for test_file in $(find .claude/commands/tests -name "test_*.py" -type f | sort); do
                test_count=$((test_count + 1))
                echo "Running: $test_file"
                if TESTING=true python3 "$test_file"; then
                  echo "‚úÖ PASS: $test_file"
                else
                  echo "‚ùå FAIL: $test_file"
                  failed_count=$((failed_count + 1))
                fi
              done
              if [ $failed_count -eq 0 ]; then
                echo "‚úÖ Command tests: $test_count/$test_count passed (all tests succeeded)"
              else
                echo "‚ùå Command tests: $((test_count - failed_count))/$test_count passed ($failed_count failed)"
              fi
              [ $failed_count -eq 0 ] || exit 1
            fi
            ;;
          "import-validation-delta")
            ./scripts/validate_imports_delta.sh
            ;;
        esac

    # Step 6: Upload test results (optional)
    - name: Upload test results
      uses: actions/upload-artifact@5d5d22a31266ced268874388b861e4b58bb5c2f3  # v4.3.1
      if: always()  # Run even if tests fail
      with:
        name: test-results-${{ matrix.test-group }}
        path: |
          mvp_site/test-results/
          /tmp/worldarchitectai/coverage/
          mvp_site/*.log
        retention-days: 30
        if-no-files-found: warn
