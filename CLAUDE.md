# CLAUDE.md - Primary Rules and Operating Protocol

**Primary rules file for AI collaboration on WorldArchitect.AI**

## ğŸš¨ CRITICAL: MANDATORY BRANCH HEADER PROTOCOL

**EVERY SINGLE RESPONSE MUST END WITH THIS HEADER - NO EXCEPTIONS:**

```
[Local: <branch> | Remote: <upstream> | PR: <number> <url>]
```

**Header Generation Methods:**
- **PREFERRED:** Use `/header` command (finds project root automatically by looking for CLAUDE.md)
- **Manual:** Run individual commands:
  - `git branch --show-current` - Get local branch
  - `git rev-parse --abbrev-ref @{upstream} 2>/dev/null || echo "no upstream"` - Get remote
  - `gh pr list --head $(git branch --show-current) --json number,url` - Get PR info

**ğŸ¯ Memory Aid:** The `/header` command reduces 3 commands to 1, making compliance effortless and helping build the habit of "header last, sign off properly".

**Examples:**
- `[Local: main | Remote: origin/main | PR: none]`
- `[Local: feature-x | Remote: origin/main | PR: #123 https://github.com/user/repo/pull/123]`

**âŒ NEVER SKIP THIS HEADER - USER WILL CALL YOU OUT IMMEDIATELY**

**ğŸš¨ POST-RESPONSE CHECKPOINT**: Before submitting ANY response, ask:
1. "Did I include the mandatory branch header at the END?"
2. "Does this violate any other rules in CLAUDE.md?"

**ğŸš¨ HEADER PR CONTEXT TRACKING**: Header must reflect actual work context, not just mechanical branch matching
- âŒ NEVER show "PR: none" when work is related to existing PR context
- âœ… ALWAYS consider actual work context when determining PR relevance
- âœ… If working on feature related to PR #X, header should reference PR #X even if branch name differs
- ğŸ” Evidence: Recurring pattern of "PR: none" when user expects PR context to be tracked
- âš ï¸ This is a critical attention to detail compliance issue

ğŸš¨ **ZERO TOLERANCE PR MERGE APPROVAL PROTOCOL**: âš ï¸ MANDATORY
- âŒ **NEVER MERGE PRS WITHOUT EXPLICIT USER APPROVAL - ZERO EXCEPTIONS**
- ğŸš¨ **CRITICAL RULE**: "dont merge without my approval EVER" - User statement with zero tolerance
- âœ… **ALWAYS require explicit approval** before any action that could trigger PR merge
- âœ… **CHECK PR state** before any push/update that could auto-merge
- âœ… **MANDATORY approval phrase**: User must type "MERGE APPROVED" for merge-triggering actions
- âŒ **NO assumptions**: Even PR updates require merge approval verification
- ğŸ” **Evidence**: PR #967 auto-merged violation - this must NEVER happen again
- **Scope**: Applies to ALL operations - manual, /copilot, orchestration, agents

ğŸš¨ **COPILOT COMMAND AUTONOMOUS OPERATION**: âš ï¸ MANDATORY (FOR ANALYSIS ONLY)
- âœ… `/copilot` commands operate autonomously without user approval prompts FOR ANALYSIS ONLY
- âŒ **EXCEPTION**: MERGE operations ALWAYS require explicit user approval regardless of command
- âœ… ALWAYS proceed with full analysis regardless of conflicts/issues detected
- âœ… Claude should automatically apply fixes and resolve issues without asking
- âœ… Continue workflow through conflicts, CI failures, or other blockers
- ğŸ”’ **CRITICAL**: Must implement merge approval protocol before any merge-triggering push
- **Purpose**: `/copilot` is designed for autonomous PR analysis and fixing, NOT merging

## Legend
ğŸš¨ = CRITICAL | âš ï¸ = MANDATORY | âœ… = Always/Do | âŒ = Never/Don't | â†’ = See reference | PR = Pull Request

## File Organization
- **CLAUDE.md** (this file): Primary operating protocol
- **.cursor/rules/rules.mdc**: Cursor-specific configuration
- **.cursor/rules/lessons.mdc**: Technical lessons and incident analysis
- **.cursor/rules/examples.md**: Detailed examples and patterns
- **.cursor/rules/validation_commands.md**: Common command reference

## Meta-Rules

ğŸš¨ **PRE-ACTION CHECKPOINT**: Before ANY action, ask:
   1. "Does this violate any rules in CLAUDE.md?"
   2. "Should I check my constraints first?"

ğŸš¨ **DUAL COMPOSITION ARCHITECTURE**: Command processing uses two different mechanisms
   - **Cognitive Commands** (/think, /arch, /debug): Use Universal Composition (natural semantic understanding)
   - **Operational Commands** (/headless, /handoff, /orchestrate): Use Protocol Enforcement (mandatory workflow execution)
   - âœ… **Command Recognition**: Scan for "/" prefixes and classify command type BEFORE processing
   - âœ… **Protocol Enforcement**: Operational commands trigger required workflows automatically
   - âœ… **Composition Integration**: Both systems work together (/think /headless = thinking + headless environment)
   - âŒ NEVER process operational commands as regular tasks without workflow setup
   - **Pattern**: Cognitive = semantic composition, Operational = protocol enforcement

ğŸš¨ **NO FALSE âœ…**: Only use âœ… for 100% complete/working. Use âŒ âš ï¸ ğŸ”„ or text for partial.

ğŸš¨ **NO POSITIVITY**: Be extremely self-critical. No celebration unless 100% working.

ğŸš¨ **NO PREMATURE VICTORY DECLARATION**: Task completion requires FULL verification
- âŒ NEVER declare success based on intermediate steps (file edits, partial work)
- âŒ NEVER say "successfully completed" without verifiable evidence
- âœ… ONLY declare success when ALL steps verified complete
- âœ… For agent tasks: Requires PR created + pushed + link verified
- âœ… For direct tasks: Requires changes committed + pushed + tested
- ğŸ” Evidence: Agent modified schedule_branch_work.sh but no PR = TASK INCOMPLETE
- âš ï¸ File changes in isolated workspaces are NOT task completion

ğŸš¨ **NO EXCUSES FOR TEST FAILURES**: When asked to fix tests, FIX THEM ALL
   - âŒ NEVER say "pre-existing issues" or "unrelated to our changes"
   - âŒ NEVER settle for partial fixes (97/99 is NOT acceptable)
   - âŒ NEVER blame test expectations - fix the code to meet them
   - âœ… ALWAYS fix ALL failing tests to 100% pass rate
   - âœ… ALWAYS take ownership of test failures, especially in new code

ğŸš¨ **DELEGATION DECISION MATRIX**: âš ï¸ MANDATORY - Before using Task tool for any workflow:
- **Parallelism Test**: âœ… Can subtasks run simultaneously without dependencies?
- **Resource Test**: âœ… System memory < 50% AND < 3 Claude instances running?
- **Overhead Test**: âœ… Agent startup time < estimated task execution time?
- **Specialization Test**: âœ… Task requires expertise current instance lacks?
- **Independence Test**: âœ… Can task complete without frequent coordination?
- âŒ **NEVER delegate sequential workflows** - Execute directly for 10x better performance
- âŒ **NEVER delegate simple command orchestration** - Basic workflows should run in current instance
- ğŸ” **Evidence**: Copilot PR #1062 - Direct execution (2 min) vs Task delegation (5+ min timeout)

ğŸš¨ **NO ASSUMPTIONS ABOUT RUNNING COMMANDS**:
   - âŒ NEVER explain what a command "will do" when it's already running
   - âŒ NEVER make assumptions about command execution or results
   - âœ… ALWAYS wait for actual command output and results
   - âœ… ALWAYS trust command execution and observe real behavior
   - **Pattern**: User says "X is running..." â†’ Wait for actual results, don't speculate

ğŸš¨ **TRUST USER CAPABILITY**: Focus on execution accuracy over complexity concerns
   - âœ… Provide clear, actionable guidance for complex commands
   - âœ… Focus on areas where protocol execution may be challenging
   - âœ… Be honest about personal limitations and areas for improvement
   - âœ… Trust user's ability to handle complexity; focus on improving execution
   - âŒ Avoid generic advice about "command overload" or "cognitive load"
   - âŒ Avoid patronizing about user interface complexity or learning curves

ğŸš¨ **SOLO DEVELOPER CONTEXT**: Never give enterprise advice to solo developers
   - âœ… **Solo Approach**: "Test it on real PRs" vs complex validation frameworks
   - âœ… **Practical Testing**: Direct usage validation vs enterprise testing infrastructure
   - âœ… **Simple Solutions**: Focus on "does it work?" rather than distributed systems thinking
   - âŒ **NEVER suggest**: Complex testing frameworks, enterprise validation, or infrastructure
   - âŒ **NEVER apply**: Enterprise patterns to solo development workflows
   - **User Context**: Solo developer needs practical, simple approaches that work immediately
   - **Evidence**: User feedback "i am a solo developer and not enterprise. stop giving me enterprise advice"

ğŸš¨ **NO FAKE IMPLEMENTATIONS**: âš ï¸ MANDATORY

**CRITICAL ANTI-PATTERN**: Always audit existing functionality before implementing new code

- âŒ NEVER create files with "# Note: In the real implementation" comments
- âŒ NEVER write placeholder code that doesn't actually work
- âŒ NEVER create demonstration files instead of working implementations
- âŒ NEVER create Python intelligence files when .md files handle the logic
- âŒ NEVER duplicate systematic protocols that already exist in other .md files
- âŒ NEVER reimplement existing command functionality (use orchestration instead)
- âœ… ALWAYS audit existing commands and .md files before writing new implementations
- âœ… ALWAYS build real, functional code that works immediately
- âœ… ALWAYS enhance existing systems rather than creating fake parallel ones
- âœ… ALWAYS check if functionality exists: Read existing commands, Grep for patterns
- **Pattern**: Real implementation > No implementation > Fake implementation
- **Evidence**: PR #820 - 563+ lines of fake code removed (fixpr.py, commentreply.py, copilot.md duplication)
- **Evidence**: orchestrate_enhanced.py with placeholder comments frustrated user
- **Rule**: If you can't implement it properly, don't create the file at all

ğŸš¨ **ORCHESTRATION OVER DUPLICATION**: âš ï¸ MANDATORY
- **Principle**: Orchestrators delegate to existing commands, never reimplement their functionality
- âœ… Pattern: New commands should be orchestrators, not implementers
- âœ… Use existing /commentreply, /pushl, /fixpr rather than duplicating their logic
- âœ… Add command summary at top of orchestrator .md files to prevent confusion
- âŒ NEVER copy systematic protocols from other .md files into new commands
- âŒ NEVER duplicate GitHub API commands that already exist in other commands
- **Evidence**: PR #812 (https://github.com/WorldArchitectAI/repo/pull/812) - 120 lines of duplicate systematic protocol removed from copilot.md
- **Architecture**: copilot = orchestrator, not implementer

ğŸš¨ **NO OVER-ENGINEERING**: Prevent building parallel inferior systems vs enhancing existing ones
   - âœ… ALWAYS ask "Can the LLM handle this naturally?" before building parsers/analytics systems
   - âœ… ALWAYS try enhancing existing systems before building parallel new ones
   - âœ… ALWAYS prioritize user workflow integration over technical sophistication
   - âŒ NEVER build parallel command execution systems - enhance Claude Code CLI instead
   - âŒ NEVER build complex parsing when LLM can understand intent naturally
   - âŒ NEVER add analytics/tracking beyond core functionality needs
   - **Pattern**: Trust LLM capabilities, enhance existing systems, prioritize immediate user value
   - **Evidence**: Command composition over-engineering (PR #737) - a parallel command execution system was built instead of enhancing the existing Claude Code CLI. This led to unnecessary complexity, duplication of functionality, and reduced maintainability.
   - **Evidence**: Orchestration parallel development (PR #790) - created .claude/commands/orchestrate.py instead of enhancing existing orchestration/ directory with Redis infrastructure. Fixed by migrating LLM features TO the mature system and deleting parallel implementation.
   - **Root Causes**: LLM capability underestimation, perfectionist engineering, integration avoidance, demo-driven development, insufficient analysis of existing infrastructure

ğŸš¨ **NO FALSE PROMISES**: Be honest about capabilities | Conservative language | Deliver or don't promise

ğŸš¨ **NO UNNECESSARY EXTERNAL APIS**: Before adding ANY external API integration:
   - âœ… FIRST ask "Can Claude solve this directly without external APIs?"
   - âœ… ALWAYS try direct implementation before adding dependencies
   - âœ… TEST the direct solution - if it works, STOP there
   - âŒ NEVER default to Gemini API just because it exists in codebase
   - âŒ NEVER add external LLM calls when Claude can generate responses directly
   - **Pattern**: Direct solution â†’ Justify external need â†’ Only then integrate
   - **Anti-pattern**: See AI task â†’ Immediately reach for Gemini API
   - **Evidence**: GitHub comment fiasco (PR #796) - built Gemini integration that degraded to useless generic templates when Claude could have generated responses directly

ğŸš¨ **GEMINI API JUSTIFICATION REQUIRED**: Gemini should ONLY be used when:
   - âœ… The task requires capabilities Claude doesn't have (e.g., image generation)
   - âœ… The system needs to work autonomously without Claude present
   - âœ… Specific model features are required (e.g., specific Gemini models)
   - âœ… User explicitly requests Gemini integration
   - âŒ NEVER use Gemini just for text generation that Claude can do
   - âŒ NEVER add complexity without clear unique value
   - **Question to ask**: "What can Gemini do here that Claude cannot?"
ğŸš¨ **USE LLM CAPABILITIES**: When designing command systems or natural language features:
   - âŒ NEVER suggest keyword matching, regex patterns, or rule-based parsing
   - âŒ NEVER propose "if word in text" simplistic approaches
   - âœ… ALWAYS leverage LLM's natural language understanding
   - âœ… ALWAYS trust the LLM to understand context, nuance, and intent
   - **Pattern**: User intent â†’ LLM understanding â†’ Natural response
   - **Anti-pattern**: Keywords â†’ Rules â†’ Rigid behavior

ğŸš¨ **SLASH COMMAND ARCHITECTURE UNDERSTANDING**: âš ï¸ CRITICAL - DO NOT FORGET
- **SLASH COMMANDS ARE NOT DOCUMENTATION - THEY ARE EXECUTABLE COMMANDS**
- **`.claude/commands/*.md` = EXECUTABLE PROMPT TEMPLATES that Claude reads and executes**
- **`.claude/commands/*.py` = EXECUTABLE SCRIPTS that run in local environment**
- **When user types `/pushl` â†’ Claude reads `pushl.md` â†’ Executes the implementation**
- **Command discovery**: CLI scans directories, filename becomes command name (`pushl.md` â†’ `/pushl`)
- **$ARGUMENTS placeholder**: Inject user arguments into command templates
- **Universal composition**: Commands combine through semantic understanding
- **Two types**: Cognitive (semantic understanding) vs Operational (protocol enforcement)
- ğŸ” **Evidence**: Research shows this is executable documentation architecture
- âŒ **NEVER treat .md files as documentation** - they are executable instructions for Claude
- âœ… **ALWAYS remember**: Slash commands execute content, they don't document it

ğŸš¨ **NEVER SIMULATE INTELLIGENCE**: When building response generation systems:
   - âŒ NEVER create Python functions that simulate Claude's responses with templates
   - âŒ NEVER use pattern matching to generate "intelligent" responses
   - âŒ NEVER build `_create_contextual_response()` methods that fake understanding
   - âŒ NEVER generate generic replies like "I'll fix the issue" or "Thanks for the suggestion"
   - âœ… ALWAYS invoke actual Claude for genuine response generation
   - âœ… ALWAYS pass full comment context to Claude for analysis
   - âœ… ALWAYS ensure responses address specific technical points, not patterns
   - **Pattern**: Collect data â†’ Claude analyzes â†’ Claude responds
   - **Anti-pattern**: Collect data â†’ Python templates â†’ Fake responses
   - **Violation Count**: 100+ times - STOP THIS PATTERN IMMEDIATELY

ğŸš¨ **NEVER FAKE "LLM-NATIVE" SYSTEMS**: âš ï¸ MANDATORY - Constraint systems and AI-powered features
   - âŒ NEVER use hardcoded keyword matching and call it "LLM-native"
   - âŒ NEVER build `if word in task.lower() for word in keywords` and claim LLM understanding
   - âŒ NEVER name files "llm_*" that contain zero LLM API calls
   - âŒ NEVER create fake "natural language understanding" with pattern matching
   - âŒ NEVER use `any(keyword in task_lower for keyword in keyword_list)` patterns
   - âœ… ALWAYS use actual LLM API calls for natural language analysis
   - âœ… ALWAYS be honest about keyword matching vs LLM usage
   - âœ… ALWAYS name files accurately (pattern_matcher.py not llm_inference.py)
   - **Pattern**: Task â†’ LLM API â†’ Analysis â†’ Constraints
   - **Anti-pattern**: Task â†’ Keywords â†’ Fake "LLM" analysis â†’ Constraints
   - **Evidence**: PR #979 falsely claimed "LLM-native" but implemented sophisticated keyword matching
   - **Rule**: If it's not using LLM APIs, don't call it LLM-native

ğŸš¨ **NO COMMAND PARSING PATTERNS**: âš ï¸ MANDATORY - When building Claude integration systems:
- âŒ NEVER use `if prompt.lower() in ['hello', 'hi']:` patterns
- âŒ NEVER parse commands with `elif 'help' in prompt.lower():` approaches
- âŒ NEVER implement hardcoded response dictionaries or lookup tables
- âŒ NEVER create fake command parsing that mimics Claude responses
- âœ… ALWAYS call actual Claude CLI or API for real responses
- âœ… ALWAYS handle Claude CLI integration issues properly (path, auth, environment)
- âœ… ALWAYS provide proper error handling when Claude integration fails
- **Pattern**: Receive prompt â†’ Call real Claude â†’ Return real response
- **Anti-pattern**: Receive prompt â†’ Pattern match â†’ Return fake response
- **Evidence**: claude-bot-server.py fake patterns removed per user correction

ğŸš¨ **EVIDENCE-BASED APPROACH**: Core principles for all analysis
   - âœ… Extract exact error messages/code snippets before analyzing
   - âœ… Show actual output before suggesting fixes
   - âœ… Reference specific line numbers when debugging
   - ğŸ” All claims must trace to specific evidence

ğŸš¨ **QUICK QUALITY CHECK** (âš¡): For debugging/complex tasks, verify:
   - ğŸ” Evidence shown? (errors, code, output)
   - âœ“ Claims match evidence?
   - âš ï¸ Uncertainties marked?
   - â¡ï¸ Next steps clear?

## Self-Learning Protocol

ğŸš¨ **AUTO-LEARN**: Document corrections immediately when: User corrects | Self-realizing "Oh, I should have..." | Something fails | Pattern repeats

**Process**: Detect â†’ Analyze â†’ Document (CLAUDE.md/learnings.md/lessons.mdc) â†’ Apply â†’ Persist to Memory MCP

**/learn Command**: `/learn [optional: specific learning]` - The unified learning command with Memory MCP integration for persistent knowledge graph storage (consolidates all learning functionality)

## Claude Code Specific Behavior

1. **Directory Context**: Operates in worktree directory shown in environment
2. **Tool Usage**: File ops, bash commands, web tools available
3. **Test Execution**: Use `TESTING=true vpython` from project root
4. **File Paths**: Always absolute paths
5. **Gemini SDK**: `from google import genai` (NOT `google.generativeai`)
6. **Path Conventions**: `roadmap/` = `/roadmap/` from project root | âœ… **USE ~ NOT /home/jleechan**: Always use `~` instead of `/home/jleechan` in paths for portability
7. ğŸš¨ **DATE INTERPRETATION**: Environment date format is YYYY-MM-DD where MM is the month number (01=Jan, 07=July)
8. ğŸš¨ **Branch Protocol**: â†’ See "Git Workflow" section
9. ğŸš¨ **TOOL EXPLANATION VS EXECUTION**: âš ï¸ MANDATORY distinction
   - âœ… When user asks "does X tool do Y?", clearly state if you're explaining or executing
   - âœ… If explaining capabilities, use "X tool CAN do Y" language
   - âœ… If actually executing, use the tool and show results
   - âŒ NEVER explain tool capabilities as if you executed them
   - âš ï¸ Example: "The /learn command can save to memory" vs "Saving to memory now..."
10. ğŸš¨ **Dev Branch Protection**: â†’ See "Git Workflow" section
11. ğŸš¨ **PUSH VERIFICATION**: âš ï¸ ALWAYS verify push success by querying remote commits after every `git push` | Use `gh pr view` or `git log origin/branch` to confirm changes are on remote
12. ğŸš¨ **PR STATUS INTERPRETATION**: âš ï¸ CRITICAL - GitHub PR states mean:
   - **OPEN** = Work In Progress (WIP) - NOT completed
   - **MERGED** = Completed and integrated into main branch
   - **CLOSED** = Abandoned or rejected - NOT completed
   - âŒ NEVER mark tasks as completed just because PR exists
   - âœ… ONLY mark completed when PR state = "MERGED"
13. ğŸš¨ **PLAYWRIGHT MCP DEFAULT**: âš ï¸ MANDATORY - When running in Claude Code CLI:
   - âœ… ALWAYS use Playwright MCP (@playwright/mcp) for browser automation by default
   - âœ… Microsoft's 2025 accessibility-tree based MCP server for AI-first automation
   - âœ… Use Playwright MCP functions for structured, deterministic browser testing
   - âœ… Fallback to Puppeteer MCP for Chrome-specific or stealth testing when needed
   - Benefits: Accessibility-tree approach, cross-browser support, AI-optimized, session sharing

ğŸš¨ **INLINE SCREENSHOTS ARE USELESS**: âš ï¸ MANDATORY - Screenshot documentation requirements:
   - âŒ NEVER rely on inline screenshots in chat - they count for NOTHING
   - âŒ Inline images displayed in responses are NOT saved as files
   - âœ… ONLY use screenshot tools that save actual files to filesystem
   - âœ… Use run_ui_tests.sh or testing_ui/ with proper file output to /tmp
   - âœ… Real documentation requires actual file artifacts for PR evidence
   - Evidence: User correction "inline screenshots count for nothing"
14. ğŸš¨ **CONTEXT7 MCP PROACTIVE USAGE**: âš ï¸ MANDATORY - When encountering API/library issues:
   - âœ… ALWAYS use Context7 MCP for accurate API documentation when facing errors
   - âœ… **Pattern**: Error occurs â†’ Use `mcp__context7__resolve-library-id` â†’ Get docs with `mcp__context7__get-library-docs`
   - âœ… Search for specific error patterns, method signatures, or usage examples
   - âœ… **Example**: Firestore transaction errors â†’ Get google-cloud-firestore docs â†’ Find correct API usage
   - âŒ NEVER guess API usage or rely on outdated assumptions
   - Benefits: Up-to-date docs, correct syntax, real working examples, eliminates trial-and-error
15. ğŸš¨ **GITHUB TOOL PRIORITY**: âš ï¸ MANDATORY - Tool hierarchy for GitHub operations:
   - âœ… **PRIMARY**: GitHub MCP tools (`mcp__github-server__*`) for all GitHub operations
   - âœ… **SECONDARY**: `gh` CLI as fallback when MCP fails or unavailable
   - âœ… **TERTIARY**: Slash commands (e.g., `/copilot`) - user wants them to work but don't wait/assume completion
   - âŒ NEVER wait for slash commands to complete when MCP tools can provide immediate results
   - âœ… **Pattern**: Try MCP first â†’ Fall back to `gh` CLI â†’ Slash commands are bonus, not dependency
   - Benefits: Immediate results, reliable API access, no command completion uncertainty
16. ğŸš¨ **MEMORY ENHANCEMENT PROTOCOL**: âš ï¸ MANDATORY for specific commands
- **Enhanced Commands**: `/think`, `/learn`, `/debug`, `/analyze`, `/fix`, `/plan`, `/execute`, `/arch`, `/test`, `/pr`, `/perp`, `/research`
- **High-Quality Memory Standards**: âš ï¸ MANDATORY - Based on Memory MCP best practices research (via Perplexity API research)
  - âœ… **Specific Technical Details**: Include exact error messages, file paths with line numbers (file:line), code snippets
  - âœ… **Actionable Information**: Provide reproduction steps, implementation details, verification methods
  - âœ… **External References**: Link to PRs, commits, files, documentation URLs for verification
  - âœ… **Canonical Naming**: Use `{system}_{issue_type}_{timestamp}` format for disambiguation
  - âœ… **Measurable Outcomes**: Include test results, performance metrics, quantified improvements
  - âœ… **Contextual Details**: Timestamp, circumstances, specific situations that triggered learning
  - âŒ **Avoid Low-Quality**: Generic statements, missing context, vague observations without actionable detail
- **Enhanced Entity Types**: Use specific, technical entity types
  - `technical_learning` - Specific solutions with code/errors/fixes
  - `implementation_pattern` - Successful code patterns with reusable details
  - `debug_session` - Complete debugging journeys with root causes
  - `workflow_insight` - Process improvements with measurable outcomes
  - `architecture_decision` - Design choices with rationale and trade-offs
- **Execution Steps**:
  1. âœ… **Extract specific technical terms** from command arguments (file names, error messages, PR numbers, technologies)
  2. âœ… **Search Memory MCP**: Call `mcp__memory-server__search_nodes(query)` with extracted technical terms
  3. âœ… **Log results transparently**: Always show "ğŸ“š Found X relevant memories"
  4. âœ… **Natural integration**: If memories found, incorporate context naturally into response
  5. âœ… **Capture high-quality learnings**: Use structured patterns with technical details, references, and actionable information
  6. âŒ **Memory search is mandatory** for listed commands unless performance/availability exceptions apply
- **Quality Validation Before Storage**:
  - Contains specific technical details (error messages, file paths, code snippets)
  - Includes actionable information (how to reproduce, fix, or implement)
  - References external artifacts (PRs, commits, files, documentation)
  - Uses canonical entity names for disambiguation
  - Provides measurable outcomes (test counts, performance metrics)
  - Links to related memories explicitly through relations
- **Transparency Requirements**:
  - Show "ğŸ” Searching memory..." when search begins
  - Report "ğŸ“š Found X relevant memories" or "ğŸ’­ No relevant memories found"
  - Indicate when response is enhanced: "ğŸ“š Enhanced with memory context"
- **Performance Constraints**:
  - Batch all terms into single search (not multiple calls)
  - Skip if search would take >100ms with notice to user
  - Continue without enhancement if MCP unavailable (with notice)
- **Integration Approach**:
  - Use natural language understanding to weave context seamlessly
  - Don't mechanically inject memory blocks
  - Judge relevance using semantic understanding, not keyword matching
  - Prioritize recent and relevant memories with actionable technical detail

### ğŸ”§ GitHub MCP Setup
**Token**: Set in `claude_mcp.sh` line ~247 via `export GITHUB_TOKEN="your_token_here"`
**Private Repos**: Use direct functions only (no search) | `mcp__github-server__get_pull_request()`
**Restart After Token Change**: Remove & re-add github-server MCP

## Orchestration System

**Full Documentation**: â†’ `.claude/commands/orchestrate.md` for complete system details

### ğŸš¨ Agent Operation
**System**: Uses tmux sessions with dynamic task agents (task-agent-*) managed by Python monitor
**Startup**: `./claude_start.sh` auto-starts orchestration | Manual: `./orchestration/start_system.sh start`
**Monitoring**: `/orch What's the status?` or `/orch monitor agents` | Direct tmux: `tmux attach -t [agent-name]`
**Cost**: $0.003-$0.050/task | Redis required for coordination
**Working Directory**: âŒ NEVER cd into agent workspaces | âœ… Provide cd command for user to copy if needed
**CRITICAL**: âŒ NEVER execute orchestration tasks yourself | âœ… ALWAYS delegate to agents when /orch or /orchestrate is used
**ENFORCEMENT**: When user runs /orch, you MUST ONLY monitor agents - NO direct execution allowed! The entire point of /orch is agent delegation!

ğŸš¨ **ORCHESTRATION DIRECT EXECUTION PREVENTION**: âš ï¸ MANDATORY HARD STOP PROTOCOL
- **Hard Stop Pattern**: Input scan for "/orch" prefix â†’ immediate Task tool delegation, NO exceptions
- **User Urgency Safeguard**: "just decide", "just start", "you choose" are guidance WITHIN protocol, NOT bypass permissions
- **Mental Model**: "/orch" = "create agent to do this", NEVER "/orch" = "I should do this directly"
- **Pre-Execution Checkpoint**: Before ANY task execution, check for "/orch" and enforce mandatory delegation
- **Zero Exception Rule**: "/orch" ALWAYS triggers Task tool regardless of context or user statements
- **Behavioral Firewall**: Automatic "Delegating to orchestration system..." response followed by Task tool call
- **Pattern Recognition**: "/" prefix â†’ operational command classification â†’ protocol enforcement
- **Prevention Over Correction**: Stop violation before it happens, don't rely on post-error recovery
- ğŸ” **Evidence**: Session violation (PR #979) when "just decide for me and start" bypassed delegation protocol

**NO HARDCODING**: âŒ NEVER hardcode task patterns - agents execute EXACT tasks requested | âœ… General task agents, not pattern-matched types

ğŸš¨ **ORCHESTRATION TASK COMPLETION**: When using /orch, task completion requires FULL end-to-end verification
- âœ… Agent must complete entire workflow (find issue â†’ fix â†’ commit â†’ push â†’ create PR)
- âœ… Verify PR creation with link before declaring success
- âŒ NEVER declare success based on agent creation alone
- ğŸ” Evidence: task-agent-3570 completed full workflow creating PR #887

## Project Overview

WorldArchitect.AI = AI-powered tabletop RPG platform (digital D&D 5e GM)

**Stack**: Python 3.11/Flask/Gunicorn | Gemini API | Firebase Firestore | Vanilla JS/Bootstrap | Docker/Cloud Run

**Docs**: â†’ `.cursor/rules/project_overview.md` (full details)
- Documentation map â†’ `.cursor/rules/documentation_map.md`
- Quick reference â†’ `.cursor/rules/quick_reference.md`
- Progress tracking â†’ `roadmap/templates/progress_tracking_template.md`
- Directory structure â†’ `/directory_structure.md`
- **AI Assistant Guide**: â†’ `mvp_site/README_FOR_AI.md` (CRITICAL system architecture for AI assistants)
- **ğŸ“‹ MVP Site Architecture**: â†’ `mvp_site/README.md` (comprehensive codebase overview)
- **ğŸ“‹ Code Review & File Responsibilities**: â†’ `mvp_site/CODE_REVIEW_SUMMARY.md` (detailed file-by-file analysis)
- **Browser Test Mode**: â†’ `mvp_site/testing_ui/README_TEST_MODE.md` (How to bypass auth in browser tests)

## Core Principles & Interaction

**Work Approach**:
Clarify before acting | User instructions = law | âŒ delete without permission | Leave working code alone |
Focus on primary goal | Propose before implementing | Summarize key takeaways | Externalize all knowledge

**Branch Protocol**: â†’ See "Git Workflow" section

**Response Modes**: Default = structured for complex | Direct for simple | Override: "be brief"

**Rule Management**:
"Add to rules" â†’ CLAUDE.md | Technical lessons â†’ lessons.mdc | General = rules | Specific = lessons

**Development Protocols**: â†’ `.cursor/rules/planning_protocols.md`

**Edit Verification**: `git diff`/`read_file` before proceeding | Additive/surgical edits only

**Testing**: Red-green methodology | Test truth verification | UI = test experience not code | Use ADTs

**Red-Green Protocol** (`/tdd` or `/rg`):
1. Write failing tests FIRST â†’ 2. Confirm fail (red) â†’ 3. Minimal code to pass (green) â†’ 4. Refactor

ğŸš¨ **Testing Standards**: â†’ See "Testing Protocol" section for complete rules

## Development Guidelines

### Code Standards
**Principles**: SOLID, DRY | **Templates**: Use existing code patterns | **Validation**: `isinstance()` checks
**Constants**: Module-level (>1x) or constants.py (cross-file) | **Imports**: Module-level only, NO inline/try-except
**Path Computation**: âœ… Use `os.path.dirname()` to retrieve the parent directory of a file path | âœ… Use `os.path.join()` for constructing paths | âœ… Use `pathlib.Path` for modern path operations | âŒ NEVER use `string.replace()` for paths
- ğŸ” Evidence: PR #818 - Replaced fragile `.replace('/tests', '')` with proper directory navigation

ğŸš¨ **DYNAMIC AGENT ASSIGNMENT**: Replace ALL hardcoded agent mappings with capability-based selection
- âŒ NEVER use patterns like `if "test" in task: return "testing-agent"`
- âœ… ALWAYS use capability scoring with load balancing
- âœ… Consider: agent capabilities, current workload, task requirements
- ğŸ” Evidence: PR #873 removed 150+ lines of hardcoded mappings

ğŸš¨ **API GATEWAY BACKWARD COMPATIBILITY**: When migrating to new architectures, API gateways MUST maintain exact contract
- âœ… ALWAYS maintain identical HTTP status codes, response formats, and validation behavior
- âœ… Fix the API gateway layer when tests fail after architectural changes
- âŒ NEVER change test expectations to match new architecture behavior
- âŒ NEVER assume tests need to know about internal architecture (MCP, microservices, etc.)
- ğŸ” Evidence: PR #1038 - Fixed Flask layer to maintain API contract instead of changing tests
- **Pattern**: Tests validate API contracts, not implementation details

### Feature Compatibility
**Critical**: Audit integration points | Update filters for new formats | Test object/string conversion
**Always Reuse**: Check existing code | Extract patterns to utilities | No duplication
**Organization**: Imports at top (stdlib â†’ third-party â†’ local) | Extract utilities | Separate concerns
**No**: Inline imports, temp comments (TODO/FIXME), hardcoded strings | Use descriptive names

### Gemini SDK
âœ… `from google import genai` | âœ… `client = genai.Client(api_key=api_key)`
Models: `gemini-2.5-flash` (default), `gemini-1.5-flash` (test)
ğŸš¨ **WARNING**: See "NO UNNECESSARY EXTERNAL APIS" rule before using Gemini

### Development Practices
`tempfile.mkdtemp()` for test files | Verify before assuming | âŒ unsolicited refactoring |
**Logging**: âœ… `import logging_util` | âŒ `import logging` | Use project's unified logging
Use docstrings, proper JS loading

ğŸš¨ **PR Review Verification**: Always verify current state before applying review suggestions
- âœ… Check if suggested fix already exists in code
- âœ… Read the actual file content before making changes
- âŒ NEVER blindly apply review comments without verification
- ğŸ” Evidence: PR #818 - Copilot suggested fixing 'string_type' that was already correct

âš ï¸ **PR COMMENT PRIORITY**: Address review comments in strict priority order
1. **CRITICAL**: Undefined variables, inline imports, runtime errors
2. **HIGH**: Bare except clauses, security issues
3. **MEDIUM**: Logging violations, format issues
4. **LOW**: Style preferences, optimizations
- ğŸ” Evidence: PR #873 review - fixed critical inline imports first

ğŸš¨ **BOT COMMENT FILTERING**: âš ï¸ MANDATORY - Ignore specific bot comment patterns when explicitly overridden
- âŒ **IGNORE**: Bot comments about `--dangerously-skip-permissions` flag when user has explicitly chosen to keep it
- âœ… **ACKNOWLEDGE**: Still respond to bot comments but indicate user decision to retain flag
- âœ… **AUDIT TRAIL**: Label ignored comment and link to user request for compliance
- âœ… **CONTEXT**: "Thanks for the security suggestion. For this specific use case, we're keeping the flag as requested per user direction. Audit: [Link to user decision]"
- **Scope**: Apply only when user has explicitly stated intention to keep controversial patterns
- **Evidence**: Memory automation testing requires bypass permissions for development/testing scenarios

### Website Testing & Deployment Expectations (ğŸš¨ CRITICAL)
ğŸš¨ **BRANCH â‰  WEBSITE**: âŒ NEVER assume branch changes are visible on websites without deployment
- âœ… Check PR description first - many changes are tooling/CI/backend only
- âœ… Feature branches need local server OR staging deployment for UI changes
- âŒ NEVER expect developer tooling changes to affect website appearance
- âœ… Production websites typically serve main branch only

ğŸš¨ **"Website looks same" Protocol**: Check PR type | Ask URL (local vs prod) | Hard refresh | Explain: branch â‰  deployment

### Quality Standards
**Files**: Descriptive names, <500 lines | **Tests**: Natural state, visual validation, dynamic discovery
**Validation**: Verify PASS/FAIL detection | Parse output, don't trust exit codes | Stop on contradictions


### ğŸš¨ Testing Protocol
**Zero Tolerance**: Run ALL tests before completion | Fix ALL failures | No "pre-existing issues" excuse
**Commands**: `./run_tests.sh` | `./run_ui_tests.sh mock` | `gh pr view`
**Protocol**: STOP â†’ FIX â†’ VERIFY â†’ EVIDENCE â†’ Complete

ğŸš¨ **TEST WITH REAL CONFLICTS**: âš ï¸ MANDATORY
- âœ… ALWAYS test merge conflict detection with PRs that actually have conflicts
- âœ… Use `gh pr view [PR] --json mergeable` to verify real conflict state before testing
- âŒ NEVER assume conflict detection works based on testing with clean PRs only
- ğŸ” Evidence: PR #780 with real conflicts revealed false negative bug that clean PRs missed
- **Why Critical**: Clean PRs won't expose detection failures - need real conflicts to validate
**Validation**: Verify PASS/FAIL detection | Output must match summary | Parse output, don't trust exit codes
**Test Assertions**: âš ï¸ MANDATORY - Must match actual validation behavior exactly
- ğŸ” Evidence: PR #818 - MBTI test checked .lower() but validation only does .strip()
- âœ… Always verify what transformations validation actually performs
**Exception Specificity**: âœ… Use specific exception types in tests (ValidationError, not Exception)
- ğŸ” Evidence: PR #818 - Improved test precision with Pydantic's ValidationError
**Methodology**: Fix one issue at a time | Run after each fix | Prefer test fixes over core logic
**Rules**: âœ… Run before task completion | âŒ NEVER skip without permission | âœ… Only use âœ… after real results

### Safety & Security
âŒ Global `document.addEventListener('click')` without approval | Test workflows after modifications |
Document blast radius | Backups â†’ `tmp/` | âŒ commit if "DO NOT SUBMIT" | Analysis + execution required

### File Deletion Impact Protocol (ğŸš¨ CRITICAL)
**Before deleting established files**: Run comprehensive reference search to avoid cascading cleanup
- `grep -r "<filename>" .` for code references (replace "<filename>" with the actual term you're searching for)
- `find . -name "*.md" -exec grep -l "<filename>" {} \;` for documentation (replace "<filename>" with the actual term you're searching for)
- Check: scripts, tests, configuration, imports, error messages, user guidance
- **Budget 2-3x normal effort** for large file deletions due to cleanup cascade
- **Evidence**: PR #722 required 36-file cleanup after deleting copilot.sh (695 lines)

### Scope Management Protocol (âš ï¸ MANDATORY)
**Distinguish rewrite vs consolidation** to set proper effort expectations
- **Consolidation**: Reorganizing existing functionality (preserve files, move/rename)
- **Rewrite**: Replacing with new implementation (delete old, extensive cleanup needed)
- âŒ NEVER use "consolidation" when you mean "rewrite" - causes scope underestimation
- **Evidence**: PR #722 called "consolidation" but became Option 3 rewrite with extensive cleanup

### File Placement Rules (ğŸš¨ HARD RULE)
ğŸš¨ **NEVER add new files directly to mvp_site/** without explicit user permission
- âŒ NEVER create test files, documentation, or scripts directly in mvp_site/
- âœ… If unsure, add content to roadmap/scratchpad_[branch].md instead
- âœ… Ask user where to place new files before creating them
- **Exception**: Only when user explicitly requests file creation in mvp_site/

ğŸš¨ **Test File Policy**: Add to existing files, NEVER create new test files
- âš ï¸ MANDATORY: Always add tests to existing test files that match the functionality
- âŒ NEVER create `test_new_feature.py` - add to `test_existing_module.py` instead
- ğŸ” Evidence: PR #818 - CodeRabbit caught test_cache_busting_red_green.py violation
- âœ… Moved cache busting tests to test_main_routes.py to comply with policy
ğŸš¨ **Code Review**: Check README.md and CODE_REVIEW_SUMMARY.md before mvp_site/ changes

### Repository Separation
**Pattern**: Specialized systems â†’ Dedicated repos | **Benefits**: Cleaner automation, focused workflows

### Browser vs HTTP Testing (ğŸš¨ HARD RULE)
**CRITICAL DISTINCTION**: Never confuse browser automation with HTTP simulation
- ğŸš¨ **testing_ui/**: ONLY real browser automation using **Playwright MCP** (default) or Puppeteer MCP | âŒ NEVER use `requests` library here
- ğŸš¨ **testing_http/**: ONLY HTTP requests using `requests` library | âŒ NEVER use browser automation here
- âš ï¸ **/testui and /testuif**: MUST use real browser automation (Playwright MCP preferred) | NO HTTP simulation
- âš ï¸ **/testhttp and /testhttpf**: MUST use HTTP requests | NO browser automation
- âœ… **/testi**: HTTP requests are acceptable (integration testing)
- **Red Flag**: If writing "browser tests" with `requests.get()`, STOP immediately

- **Command Structure** (Claude Code CLI defaults to Playwright MCP):
  - `/testui` = Browser (Playwright MCP) + Mock APIs
  - `/testuif` = Browser (Playwright MCP) + REAL APIs (costs $)
  - `/testhttp` = HTTP + Mock APIs
  - `/testhttpf` = HTTP + REAL APIs (costs $)
  - `/tester` = End-to-end tests with REAL APIs (user decides cost)

### Real API Testing Protocol (ğŸš¨ MANDATORY)
**NEVER push back or suggest alternatives when user requests real API testing**:
- âœ… User decides if real API costs are acceptable - respect their choice
- âœ… `/tester`, `/testuif`, `/testhttpf` commands are valid user requests
- âœ… Real API testing provides valuable validation that mocks cannot
- âŒ NEVER suggest mock alternatives unless specifically asked
- âŒ NEVER warn about costs unless the command requires confirmation prompts
- **User autonomy**: User controls their API usage and testing approach

### Browser Test Execution Protocol (ğŸš¨ MANDATORY)

ğŸš¨ **PREFERRED**: Playwright MCP in Claude Code CLI - Accessibility-tree based, AI-optimized, cross-browser
ğŸš¨ **SECONDARY**: Puppeteer MCP for Chrome-specific or stealth testing scenarios
ğŸš¨ **FALLBACK**: Playwright IS installed in venv! Use headless=True | âŒ NEVER say "not installed"

**Commands**: `./run_ui_tests.sh mock --playwright` (default) | `./run_ui_tests.sh mock --puppeteer` (secondary) | `./run_ui_tests.sh mock` (Playwright fallback)

**Test Mode URL**: `http://localhost:8081?test_mode=true&test_user_id=test-user-123` - Required for auth bypass!

**Details**: â†’ `.cursor/rules/test_protocols.md`

### Coverage Analysis Protocol (âš ï¸)
**MANDATORY**: When analyzing test coverage:
1. **ALWAYS use**: `./run_tests.sh --coverage` or `./coverage.sh` (HTML default)
2. **NEVER use**: Manual `coverage run` commands on individual test files
3. **Verify full test suite**: Ensure all 94+ test files are included in coverage analysis
4. **Report source**: Always mention "Coverage from full test suite via run_tests.sh"
5. **HTML location**: `/tmp/worldarchitectai/coverage/index.html`

## Git Workflow

| Rule | Description | Commands/Actions |
|------|-------------|------------------|
| **Main = Truth** | Use `git show main:<file>` for originals | âŒ push to main (no exceptions) |
| **PR Workflow** | All changes via PRs | `gh pr create` + test results in description |
| **Branch Safety** | Verify before push | `git push origin HEAD:branch-name` |
| **ğŸš¨ Upstream Tracking** | Set tracking to avoid "no upstream" in headers | `git push -u origin branch-name` OR `git branch --set-upstream-to=origin/branch-name` |
| **Integration** | Fresh branch after merge | `./integrate.sh` |
| **Pre-PR Check** | Verify commits/files | â†’ `.cursor/rules/validation_commands.md` |
| **Post-Merge** | Check unpushed files | `git status` â†’ follow-up PR if needed |
| **Progress Track** | Scratchpad + JSON | `roadmap/scratchpad_[branch].md` + `tmp/milestone_*.json` |
| **PR Testing** | Apply PRs locally | `gh pr checkout <PR#>` |
| **Roadmap Updates** | Always create PR | All files require PR workflow - including roadmap files |

ğŸš¨ **No Main Push**: âœ… `git push origin HEAD:feature` | âŒ `git push origin main`
   - **ALL changes require PR**: Including roadmap files, documentation, everything
   - **Fresh branches from main**: Always create new branch from latest main for new work
   - **Pattern**: `git checkout main && git pull && git checkout -b descriptive-name`

ğŸš¨ **PR Context Management**: Verify before creating PRs - Check git status | Ask which PR if ambiguous | Use existing branches

ğŸš¨ **Branch Protection**: âŒ NEVER switch without explicit request | âŒ NEVER use dev[timestamp] for development
âœ… Create descriptive branches | Verify context before changes | Ask if ambiguous

ğŸš¨ **Conflict Resolution**: Analyze both versions | Assess critical files | Test resolution | Document decisions
**Critical Files**: CSS, main.py, configs, schemas | **Process**: `./resolve_conflicts.sh`

ğŸš¨ **GIT ANALYSIS CONTEXT CHECKPOINT**: âš ï¸ MANDATORY protocol before any git comparison
- âœ… **Step 1**: Identify current branch (`git branch --show-current`)
- âœ… **Step 2**: Determine branch type (sync-main-*, feature branch, main)
- âœ… **Step 3**: Select appropriate remote comparison:
  - **sync-main-*** branches â†’ Compare to `origin/main`
  - **Feature branches** â†’ Compare to `origin/branch-name` if the branch is tracked locally and changes need to be compared to the remote branch on the same repository. Use `upstream` if the branch is forked from another repository and changes need to be compared to the original repository.
  - **main branch** â†’ Compare to `origin/main`
- âœ… **Step 4**: Execute comparison commands with correct remote
- âŒ NEVER run git comparisons without context verification (i.e., identifying the current branch, determining the branch type, and selecting the appropriate remote comparison as outlined in Steps 1â€“3 above)
- **Evidence**: Prevents autopilot execution errors that waste user time

ğŸš¨ **COMMAND FAILURE TRANSPARENCY** (âš ï¸ MANDATORY): When user commands fail unexpectedly:
   - âœ… Immediately explain what failed and why
   - âœ… Show system messages/errors received
   - âœ… Explain resolution approach being taken
   - âœ… Ask preference for alternatives (merge vs rebase, etc.)
   - âŒ NEVER silently fix without explanation
   - **Pattern**: Command fails > Explain > Show options > Get preference > Execute
   - **Evidence**: Silent git merge resolution leads to "ignored comment" perception

**Commit Format**: â†’ `.cursor/rules/examples.md`

ğŸš¨ **GITHUB API PAGINATION PROTOCOL**: âš ï¸ MANDATORY - Before ANY GitHub API analysis:
- âœ… **Check total count first**: Use `gh pr view [PR] --json changed_files` to get file count before analysis
- âœ… **Verify pagination**: GitHub API defaults to 30 items per page - always check if more pages exist
- âœ… **Use pagination parameters**: Add `?per_page=100&page=N` for complete results when file count > 30
- âœ… **Sanity check**: If API returns small number but PR shows major changes, investigate pagination
- âœ… **Multiple verification**: Use both API and web interface to cross-check important analysis
- âŒ **NEVER assume**: API returns complete results without verifying pagination and total counts

ğŸš¨ **CHALLENGE RESPONSE PROTOCOL**: âš ï¸ MANDATORY - When user provides specific evidence:
- âœ… **Immediate re-verification**: Treat user evidence as debugging signal, not personal attack
- âœ… **Methodology review**: Re-check approach when user mentions details not in your analysis
- âœ… **Humble language**: Use "appears to be" until verified through multiple independent sources
- âŒ **NEVER defend**: Wrong analysis - acknowledge error and re-verify immediately

## Environment, Tooling & Scripts

1. **Python venv**: Verify activated before running Python/tests | If missing/corrupted â†’ `VENV_SETUP.md`
2. **Robust Scripts**: Make idempotent, work from any subdirectory
3. **Automation Setup Scripts**: Single setup script with validation, logging, health checks for production systems
   - âœ… **Pattern**: Prerequisites check â†’ Logging setup â†’ Service configuration â†’ Validation â†’ Health check
   - âœ… **Features**: Error handling, rollback capability, status reporting, documentation
   - ğŸ” **Evidence**: setup_automation.sh successfully deployed complete cron job + monitoring system
   - **Application**: Cron jobs, service configuration, system initialization, deployment automation
4. **Python Execution**: âœ… Run from project root | âŒ cd into subdirs
5. **vpython Tests**:
   - âš ï¸ "run all tests" â†’ `./run_tests.sh`
   - âš ï¸ Test fails â†’ fix immediately or ask user
   - âœ… `TESTING=true vpython mvp_site/test_file.py` (from root)
5. ğŸš¨ **Test Compliance**: â†’ See "Testing Protocol" section
7. **Tool Failure**: Try alternative after 2 fails | Fetch from main if corrupted
8. **Web Scraping**: Use full-content tools (curl) not search snippets
9. **Log Files Location**:
   - âœ… **Server logs are in `/tmp/worldarchitectai_logs/`** with subfolders/files named by branch
   - âœ… **Branch-specific logs**: `/tmp/worldarchitectai_logs/[branch-name].log`
   - âœ… **Current branch log**: `/tmp/worldarchitectai_logs/$(git branch --show-current).log`
   - âœ… **Log commands**: `tail -f /tmp/worldarchitectai_logs/[branch].log` for real-time monitoring
   - âœ… **Search logs**: `grep -i "pattern" /tmp/worldarchitectai_logs/[branch].log`
   - âœ… **Binary logs**: Use `strings /tmp/worldarchitectai_logs/[branch].log | grep -i "pattern"`
   - âœ… **Find current log**: `git branch --show-current` then check corresponding log file

**Test Commands**: â†’ `.cursor/rules/validation_commands.md`

## Data Integrity & AI Management

1. **Data Defense**: Assume incomplete/malformed | Use `dict.get()` | Validate structures
2. **Critical Logic**: Implement safeguards in code, not just prompts
3. **Single Truth**: One clear way per task | Remove conflicting rules

## Operations Guide

### Memory MCP Usage
**Create Knowledge**: `mcp__memory-server__create_entities([{name, entityType, observations}])`
**Search Knowledge**: `mcp__memory-server__search_nodes("query")` â†’ Find existing before creating
**Persist Learning**: `/learn` auto-saves, but use Memory MCP directly for complex knowledge graphs
**Pattern**: Search first â†’ Create if new â†’ Add observations to existing â†’ Build relationships

### Task Agent Patterns
**âš ï¸ Token Cost**: Each agent loads ~50k+ tokens. See `.claude/commands/parallel-vs-subagents.md` for alternatives.
**When to Spawn**: Complex workflows | Different directories | Long operations (>5 min)
**When NOT to Spawn**: Simple searches | Independent file ops | Data gathering (<30s each)
**Basic Pattern**: `Task(description="Research X", prompt="Detailed instructions...")`
**Integration**: Main thread continues while agents work â†’ Agents return results â†’ Integrate findings
**Example**: "Analyze all test files" â†’ Spawn agent per directory â†’ Combine reports

### TodoWrite Protocol
**When Required**: Tasks with 3+ steps | Complex implementations | /execute commands
**Status Flow**: `pending` â†’ `in_progress` (before starting) â†’ `completed` (after done)
**Circuit Breaker**: For /execute - TodoWrite checklist prevents premature execution
**Update Pattern**: Mark current task `in_progress`, complete it, then move to next

### Common Operations
**Multi-file Edits**: Use MultiEdit with 3-4 edits max per call to avoid timeouts
**Context Management**: Check remaining % before complex operations | Split large tasks
**Response Length**: Use bullet points | Essential info only | Split across messages if needed
**Tool Recovery**: After 2 failures â†’ Try alternative tool â†’ Fetch from main if corrupted
**Backup Before Major Changes**: Copy critical files to `.backup` or `/tmp` first

## Knowledge Management

### Scratchpad Protocol (âš ï¸)
`roadmap/scratchpad_[branch].md`: Goal | Plan | State | Next | Context | Branch info

### File Organization
- **CLAUDE.md**: Primary protocol
- **lessons.mdc**: Technical learnings from corrections
- **project.md**: Repository-specific knowledge base
- **rules.mdc**: Cursor configuration

### Process Improvement
- **5 Whys**: Root cause â†’ lessons.mdc
- **Sync Cursor**: Copy CLAUDE.md to Cursor settings after changes
- **Proactive Docs**: Update rules/lessons after debugging without prompting

## Critical Lessons (Compressed)

### Core Patterns
**Trust But Verify**: Test before assuming | Docs â‰  code | Trace data flow | Critical instructions first

### ğŸš¨ Anti-Patterns
**Silent Breaking Changes**: Update all str() usage when changing objects | Test backward compatibility
**Branch Confusion**: Verify context before changes | Check PR destination | Evidence: PR #627/628
**Orchestration Hardcoding**: âŒ NEVER pattern-match tasks to agent types | âœ… Execute exact requested tasks | Evidence: task_dispatcher.py created test agents for all tasks

### Debugging Protocol (ğŸš¨ MANDATORY)
**Process**: Extract evidence â†’ Analyze â†’ Verify â†’ Fix | Trace: Backend â†’ API â†’ Frontend
**Evidence**: Primary (code/errors) > Secondary (docs) > General (patterns) > Speculation
**Details**: â†’ `.cursor/rules/debugging_guide.md`

### Critical Rules
**Data Corruption**: Systemic issue - search all patterns | **Temp Fixes**: Flag + fix NOW
**Task Complete**: Solve + Update docs + Memory + Audit | **No blind execution**
**Details**: â†’ `.cursor/rules/lessons.mdc`

## Slash Commands

**Full Documentation**: â†’ `.claude/commands/` | Use `/list` for available commands

### Command Classification (Dual Architecture)

**ğŸ§  Cognitive Commands** (Semantic Composition):
- `/think`, `/arch`, `/debug` - Modify thinking approach, compose naturally
- `/learn` - Capture structured technical learnings with Memory MCP integration
- `/analyze` - Deep analysis with memory context enhancement
- `/fix` - Problem resolution with memory-guided solutions
- `/perp` - Research validation using Perplexity API
- `/research` - Knowledge gathering with memory pattern recognition
- **Behavior**: Automatic semantic understanding and tool integration

**âš™ï¸ Operational Commands** (Protocol Enforcement):
- `/headless`, `/handoff`, `/orchestrate` - Modify execution environment
- **Behavior**: Mandatory workflow execution before task processing

**ğŸ”§ Tool Commands** (Direct Execution):
- `/execute`, `/test`, `/pr` - Direct task execution
- **Behavior**: Immediate execution with optional parameters

### Critical Enforcement
ğŸš¨ **SLASH COMMAND PROTOCOL RECOGNITION**: âš ï¸ MANDATORY - Before processing ANY slash command:
- âœ… **Recognition Phase**: Scan input for "/" â†’ Identify command type â†’ Look up required workflow in `.claude/commands/[command].md`
- âœ… **Execution Phase**: Follow COMPLETE documented workflow â†’ No partial execution allowed
- âœ… **Verification Phase**: Confirm all protocol steps completed before declaring task done
- âŒ NEVER treat slash commands as content suggestions - they are execution mandates
- âŒ NEVER stop midway through documented workflows (e.g., stopping after Execute phase of `/pr`)
- **Evidence**: PR #938 - Failed `/pr` protocol by stopping after Execute instead of continuing to Pushâ†’Copilotâ†’Review
- **Pattern**: Protocol execution deficit causes user frustration and incomplete deliverables

ğŸš¨ **EXECUTE CIRCUIT BREAKER**: `/e` or `/execute` â†’ TodoWrite checklist MANDATORY
- Context % | Complexity | Subagents? | Plan presented | Auto-approval applied
- âœ… Built-in approval via /autoapprove composition | TodoWrite = safety protocol

ğŸš¨ **OPERATIONAL COMMAND ENFORCEMENT**: `/headless`, `/handoff`, `/orchestrate`, `/orch`
- âœ… ALWAYS trigger protocol workflow before task execution
- âœ… Create isolated environments as specified in command documentation
- âŒ NEVER process as regular tasks without environment setup
- âŒ NEVER execute /orch or /orchestrate tasks yourself - ONLY monitor agents
- âœ… For /orch: Create agents â†’ Monitor progress â†’ Report results ONLY

**Key Commands**: `/execute` (auto-approval built-in) | `/plan` (requires manual approval) | `/replicate` (PR analysis) | `/fake` (code quality audit)
**Dual Composition**: Cognitive (semantic) + Operational (protocol) + Tool (direct)
**Unified Learning**: ONE `/learn` command with Memory MCP integration

### Quality Assurance Commands

#### `/fake`
**Purpose**: Comprehensive fake code detection using command composition
**Composition**: `/arch /thinku /devilsadvocate /diligent`
**Usage**: `/fake`
**Detection**: Identifies fake implementations, demo code, placeholder comments, duplicate protocols
**Output**: Structured audit report with actionable remediation guidance

## Special Protocols

### GitHub PR Comment Response Protocol (âš ï¸)
**MANDATORY**: Systematically address ALL PR comments from all sources

**Comment Sources**: Inline (`gh api`) | General (`gh pr view`) | Reviews | Copilot (include "suppressed")

**Response Status**: âœ… RESOLVED | ğŸ”„ ACKNOWLEDGED | ğŸ“ CLARIFICATION | âŒ DECLINED

**Critical Rule**: âŒ NEVER ignore any comment type, including "suppressed" Copilot feedback

ğŸš¨ **DATA LOSS WARNINGS**: Treat all data loss warnings from CodeRabbit/Copilot as CRITICAL
- âŒ NEVER dismiss data integrity concerns as "intentional design"
- âœ… ALWAYS implement proper validation before conflict resolution
- âœ… ALWAYS treat data corruption warnings as highest priority
- ğŸ” Evidence: CodeRabbit data loss warning prevented silent corruption in backup script

### Import Protocol (ğŸš¨ CRITICAL)
**Zero Tolerance**: Module-level only | No inline/try-except/conditionals | Use `as` for conflicts
**Rule**: Import or fail - no "optional" patterns

### API Error Prevention (ğŸš¨)
âŒ Print code/file content | âœ… Use file_path:line_number | Keep responses concise

### Browser Testing vs HTTP Testing (ğŸš¨)
**HARD RULE**: NO HTTP simulation for browser tests!
- `/testuif` = Real browser automation (Puppeteer MCP/Playwright) | `/testi` = HTTP requests OK
- Browser tests require: Page navigation, element clicks, form fills, screenshots
- Auth bypass: Use test mode URL params, NOT HTTP simulation

### PR References (âš ï¸)
**MANDATORY**: Include full GitHub URL - Format: "PR #123: https://github.com/jleechan2015/worldarchitect.ai/pull/123"

### PR Description Protocol (âš ï¸ MANDATORY)
**PR descriptions must reflect complete delta vs origin/main, not just recent work**:
- âœ… Use `git diff --stat origin/main...HEAD` to get comprehensive change summary
- âœ… Analyze actual file changes, additions, deletions vs main branch
- âœ… Document all new features, systems, and architectural changes
- âœ… Include performance impact, testing status, and migration notes
- âŒ NEVER describe only latest commits or recent work
- âŒ NEVER assume PR scope from branch name or recent activity
- **Pattern**: Complete delta analysis â†’ Comprehensive feature documentation â†’ Clear change categorization
- **Evidence**: User feedback "pr desc is wrong. We should see the delta of the PR vs main"


## Project-Specific

### Flask: SPA route for index.html | Hard refresh for CSS/JS | Cache-bust in prod
### Python: venv required | Source .bashrc after changes | May need python3-venv
### AI/LLM: Detailed prompts crucial | Critical instructions first | Long prompts = fatigue
### Workflow: Simple-first | Tool fail = try alternative | Main branch = recovery source

## Quick Reference

- **Test**: `TESTING=true vpython mvp_site/test_file.py` (from root)
- **Integration**: `TESTING=true python3 mvp_site/test_integration/test_integration.py`
- **New Branch**: `./integrate.sh`
- **All Tests**: `./run_tests.sh`
- **Deploy**: `./deploy.sh` or `./deploy.sh stable`

## Additional Documentation

- **Technical Lessons**: â†’ `.cursor/rules/lessons.mdc`
- **Cursor Config**: â†’ `.cursor/rules/rules.mdc`
- **Examples**: â†’ `.cursor/rules/examples.md`
- **Commands**: â†’ `.cursor/rules/validation_commands.md`

### Archive Process
Quarterly/2500 lines/new year â†’ `lessons_archive_YYYY.mdc` | Keep critical patterns | Reference archives

## API Timeout Prevention (ğŸš¨)

**MANDATORY**: Prevent API timeouts:
- **Edits**: MultiEdit with 3-4 max | Target sections, not whole files
- **Thinking**: 5-6 thoughts max | Concise | No unnecessary branching
- **Responses**: Bullet points | Minimal output | Essential info only
- **Tools**: Batch calls | Smart search (Grep/Glob) | Avoid re-reads
- **Complex tasks**: Split across messages | Monitor server load
