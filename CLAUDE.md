# CLAUDE.md - Primary Rules and Operating Protocol

**Primary rules file for AI collaboration on WorldArchitect.AI**

## Legend
üö® = CRITICAL | ‚ö†Ô∏è = MANDATORY | ‚úÖ = Always/Do | ‚ùå = Never/Don't | ‚Üí = See reference | PR = Pull Request

## File Organization
- **CLAUDE.md** (this file): Primary operating protocol
- **.cursor/rules/rules.mdc**: Cursor-specific configuration
- **.cursor/rules/lessons.mdc**: Technical lessons and incident analysis
- **.cursor/rules/examples.md**: Detailed examples and patterns
- **.cursor/rules/validation_commands.md**: Common command reference

## Meta-Rules

üö® **PRE-ACTION CHECKPOINT**: Before ANY action, ask:
   1. "Can I actually do this or am I about to simulate?"
   2. "Does this violate any rules in CLAUDE.md?"
   3. "Should I check my constraints first?"

üö® **NO FALSE ‚úÖ**: Only use ‚úÖ for 100% complete/working. Use ‚ùå ‚ö†Ô∏è üîÑ or text for partial.

üö® **NO POSITIVITY**: Be extremely self-critical. No celebration unless 100% working.

üö® **NEVER SIMULATE**: Ask if stuck. Fake answer = 1000x worse than getting help.
   - ‚ùå NEVER create fake files pretending to be real output (e.g., text files named .png)
   - ‚ùå NEVER show "simulated" test results when real tests fail
   - ‚ùå NEVER create workarounds that hide actual failures
   - ‚úÖ ALWAYS say "I cannot do X because Y" when facing limitations
   - ‚úÖ ALWAYS show actual error messages instead of hiding them
   - ‚ùå NEVER pretend to run separate agents or workers when you can't
   - ‚ùå NEVER simulate what "would happen" - test it or admit you can't

üö® **ANTI-HALLUCINATION MEASURES**: Extract evidence before making claims
   - ‚úÖ ALWAYS extract direct quotes/code/errors before analysis
   - ‚úÖ State "I don't have enough information" when uncertain
   - ‚úÖ Base all conclusions on extracted evidence, not assumptions
   - ‚ùå NEVER fabricate information, statistics, or outputs
   - ‚ùå NEVER guess at error messages or code behavior
   - ‚ö†Ô∏è If uncertain about any aspect, explicitly acknowledge it

üö® **UNCERTAINTY ACKNOWLEDGMENT**: You are explicitly permitted to:
   - ‚úÖ Say "I don't know" when information is uncertain
   - ‚úÖ Admit limitations in your knowledge or access
   - ‚úÖ Request clarification when instructions are ambiguous
   - ‚úÖ Decline tasks outside your capabilities
   - ‚úÖ Ask for help rather than attempting impossible tasks

üö® **NO EXCUSES FOR TEST FAILURES**: When asked to fix tests, FIX THEM ALL
   - ‚ùå NEVER say "pre-existing issues" or "unrelated to our changes"
   - ‚ùå NEVER settle for partial fixes (97/99 is NOT acceptable)
   - ‚ùå NEVER blame test expectations - fix the code to meet them
   - ‚úÖ ALWAYS fix ALL failing tests to 100% pass rate
   - ‚úÖ ALWAYS take ownership of test failures, especially in new code


üö® **EVIDENCE-BASED APPROACH**: Core principles for all analysis
   - ‚úÖ Extract exact error messages/code snippets before analyzing
   - ‚úÖ Show actual output before suggesting fixes
   - ‚úÖ Reference specific line numbers when debugging
   - üîç All claims must trace to specific evidence

üö® **QUICK QUALITY CHECK** (‚ö°): For debugging/complex tasks, verify:
   - üîç Evidence shown? (errors, code, output)
   - ‚úì Claims match evidence?
   - ‚ö†Ô∏è Uncertainties marked?
   - ‚û°Ô∏è Next steps clear?

## Self-Learning Protocol

üö® **MANDATORY**: Continuously learn from corrections and self-realizations:

### Automatic Learning Triggers
1. **User corrections** - When user corrects a mistake, immediately document it
2. **Self-corrections** - When you realize "Oh, I should have...", document it
3. **Failed attempts** - When something doesn't work, learn why
4. **Pattern recognition** - When you repeat a mistake, create a rule

### Learning Process
1. **Detect** - Recognize correction/mistake (yours or user's)
2. **Analyze** - Understand what went wrong and why
3. **Document** - Update appropriate file:
   - **CLAUDE.md** - Critical rules with üö® marker
   - **.claude/learnings.md** - Detailed categorized learnings
   - **.cursor/rules/lessons.mdc** - Technical lessons
4. **Apply** - Use the learning immediately in current session

### /learn Command
- **Usage**: `/learn [optional: specific learning]`
- **Purpose**: Explicitly capture learnings or review recent corrections
- **Example**: `/learn playwright is installed in venv`

### Self-Correction Indicators
When you say these, ALWAYS document the learning:
- "Let me correct that..." / "Let me fix that..."
- "Oh, I should have..." / "Actually, I need to..."
- "My mistake..." / "I was wrong about..."
- "I see the issue..." / "The problem is..."

### Error Recovery Protocol
When mistakes occur:
1. **Immediately acknowledge** the error without excuses
2. **Explain what went wrong** with specific details
3. **Provide corrected information** based on evidence
4. **Document the learning** via /learn or file updates
5. **Implement additional verification** to prevent recurrence

**Learning Categories** ‚Üí `.claude/learnings.md`

## Claude Code Specific Behavior

1. **Directory Context**: Operates in worktree directory shown in environment
2. **Tool Usage**: File ops, bash commands, web tools available
3. **Test Execution**: Use `source venv/bin/activate && python` with `TESTING=true` (NOT vpython)
4. **File Paths**: Always absolute paths
5. **Gemini SDK**: `from google import genai` (NOT `google.generativeai`)
6. **Path Conventions**: `roadmap/` = `/roadmap/` from project root
7. üö® **DATE INTERPRETATION**: Environment date format is YYYY-MM-DD where MM is the month number (01=Jan, 07=July)
8. üö® **BRANCH DISCIPLINE**: ‚ùå NEVER switch git branches unless user explicitly requests it | Work on current branch only | Ask before any `git checkout` operations
9. üö® **DEV BRANCH PROTECTION**: ‚ùå NEVER make changes in dev[timestamp] branches | These are protective branches only | Always create descriptive branches for actual work
10. üö® **PUSH VERIFICATION**: ‚ö†Ô∏è ALWAYS verify push success by querying remote commits after every `git push` | Use `gh pr view` or `git log origin/branch` to confirm changes are on remote
11. üö® **PR STATUS INTERPRETATION**: ‚ö†Ô∏è CRITICAL - GitHub PR states mean:
   - **OPEN** = Work In Progress (WIP) - NOT completed
   - **MERGED** = Completed and integrated into main branch  
   - **CLOSED** = Abandoned or rejected - NOT completed
   - ‚ùå NEVER mark tasks as completed just because PR exists
   - ‚úÖ ONLY mark completed when PR state = "MERGED"

## Project Overview

WorldArchitect.AI = AI-powered tabletop RPG platform (digital D&D 5e GM)

**Stack**: Python 3.11/Flask/Gunicorn | Gemini API | Firebase Firestore | Vanilla JS/Bootstrap | Docker/Cloud Run

**Docs**: ‚Üí `.cursor/rules/project_overview.md` (full details)
- Documentation map ‚Üí `.cursor/rules/documentation_map.md`
- Quick reference ‚Üí `.cursor/rules/quick_reference.md`
- Progress tracking ‚Üí `roadmap/templates/progress_tracking_template.md`
- Directory structure ‚Üí `/directory_structure.md`
- **AI Assistant Guide**: ‚Üí `mvp_site/README_FOR_AI.md` (CRITICAL system architecture for AI assistants)
- **üìã MVP Site Architecture**: ‚Üí `mvp_site/README.md` (comprehensive codebase overview)
- **üìã Code Review & File Responsibilities**: ‚Üí `mvp_site/CODE_REVIEW_SUMMARY.md` (detailed file-by-file analysis)
- **Browser Test Mode**: ‚Üí `mvp_site/testing_ui/README_TEST_MODE.md` (How to bypass auth in browser tests)

## Core Principles & Interaction

**Work Approach**:
Clarify before acting | User instructions = law | ‚ùå delete without permission | Leave working code alone |
Focus on primary goal | Propose before implementing | Summarize key takeaways | Externalize all knowledge

**Branch Status Protocol**:
üö® **MANDATORY**: Always include complete git status header in every response
- ‚úÖ Format: `[Local: branch-name | Remote: origin/branch-name | PR: #123 https://github.com/jleechan2015/worldarchitect.ai/pull/123]`
- ‚úÖ Use `git branch --show-current` for local branch
- ‚úÖ Use `git rev-parse --abbrev-ref @{upstream}` for remote branch (if exists)
- ‚úÖ Use `gh pr view --json number,url` to get PR info (if exists)
- ‚úÖ If no PR exists, show `PR: none`
- ‚úÖ Essential for complete context awareness and avoiding branch confusion

**Response Modes**: 
- Default: Structured analysis with <thinking>, <analysis>, <response> format for complex tasks
- For simple queries: Direct concise answers
- Override to concise: "be brief", "short answer", "concise mode"
- Re-evaluate: Week of July 15, 2025

**Rule Management**:
"Add to rules" ‚Üí CLAUDE.md | Technical lessons ‚Üí lessons.mdc | General = rules | Specific = lessons

**Development Protocols**: ‚Üí `.cursor/rules/planning_protocols.md`

**Edit Verification**: `git diff`/`read_file` before proceeding | Additive/surgical edits only

**Testing**: Red-green methodology | Test truth verification | UI = test experience not code | Use ADTs

**Red-Green Protocol** (`/tdd` or `/rg`):
1. Write failing tests FIRST ‚Üí 2. Confirm fail (red) ‚Üí 3. Minimal code to pass (green) ‚Üí 4. Refactor

üö® **Test Infrastructure Validation Protocol**:
When working with test runners/harnesses:
1. **Verify Core Function**: Before adding features, verify runner correctly detects PASS vs FAIL
2. **Test Both Paths**: Create one passing test AND one failing test to validate detection
3. **Output Analysis**: If visual output (‚ùå/‚úÖ) doesn't match summary, STOP and fix immediately
4. **Exit Code Distrust**: Don't rely solely on process exit codes - parse actual output
5. **Contradiction = Bug**: Any mismatch between test output and summary is CRITICAL bug

üö® **MANDATORY TEST EXECUTION BEFORE COMPLETION**:
‚ùå NEVER claim test completion without executing at least ONE test successfully
- Before any ‚úÖ "tests complete", run at least one test to verify framework works
- If dependencies missing (Playwright, etc.), FULL STOP - report "Cannot complete - X not installed"
- Use ‚ö†Ô∏è "Created but unverified" instead of ‚úÖ "Complete" for untested code
- Only use ‚úÖ after seeing actual PASS/FAIL results from real test execution

## Development Guidelines

### Code Standards
- Treat existing code as template | String constants: module-level (>1x) or constants.py (cross-file)
- **SOLID Principles**: Single Responsibility Principle (one reason to change), Open/Closed Principle
- **DRY principle** | Defensive programming: `isinstance()` validation
- **Code Duplication Prevention**: Check for existing similar code before writing new | Extract common patterns to utilities | Audit for unused CSS/imports
- **Constants Over Strings**: Use constants.py for repeated keys/values | Never hardcode 'session_header', 'planning_block' etc. | Module-level constants for >1x usage
- **Extraction Methods**: Create utility functions for duplicate logic | Extract structured field operations | HTML generation helpers for repeated UI patterns
- **Separation of Concerns**: Domain logic separate from data layer, utility functions isolated
- **Import Organization**: All imports at file top, sorted (stdlib ‚Üí third-party ‚Üí local)
- **No Inline Imports**: Never import inside functions/methods/classes

### Gemini SDK
‚úÖ `from google import genai` | ‚úÖ `client = genai.Client(api_key=api_key)`
Models: `gemini-2.5-flash` (default), `gemini-1.5-flash` (test)

### Development Practices
`tempfile.mkdtemp()` for test files | Verify before assuming | ‚ùå unsolicited refactoring |
**Logging**: ‚úÖ `import logging_util` | ‚ùå `import logging` | Use project's unified logging
Use docstrings, proper JS loading

### Quality & Testing
- File naming: descriptive, ‚ùå "red"/"green" | Methods <500 lines | Single responsibility
- Integration tests: natural state, flexible assertions | Visual testing required
- Dead code: use `vulture` | Test behavior not strings
- üö® **Test Runner Validation**: When modifying test runners, MUST verify both PASS and FAIL detection | Create intentional failure case | Verify output matches actual result
- üö® **Output Contradiction Check**: If output shows failure indicators (‚ùå, FAILED, ERROR) but summary shows success (‚úÖ, PASSED), STOP immediately and investigate
- ‚ö†Ô∏è **Test Exit Codes**: Don't assume test scripts return proper exit codes | Parse output for success/failure strings | Verify detection logic before trusting results
- ‚ö†Ô∏è **Dynamic Test Discovery**: ‚ùå NEVER hardcode test file lists in scripts | ‚úÖ Use `find` or glob patterns to discover tests automatically | Update test runners to scan directories (e.g., `find testing_ui -name "test_*.py"`)

### Safety & Security
‚ùå Global `document.addEventListener('click')` without approval | Test workflows after modifications |
Document blast radius | Backups ‚Üí `tmp/` | ‚ùå commit if "DO NOT SUBMIT" | Analysis + execution required

### File Placement Rules (üö® HARD RULE)
üö® **NEVER add new files directly to mvp_site/** without explicit user permission
- ‚ùå NEVER create test files, documentation, or scripts directly in mvp_site/
- ‚úÖ If unsure, add content to roadmap/scratchpad_[branch].md instead
- ‚úÖ Ask user where to place new files before creating them
- **Exception**: Only when user explicitly requests file creation in mvp_site/

üö® **MANDATORY: Review codebase documentation before mvp_site/ changes**:
- ‚úÖ ALWAYS check `mvp_site/README.md` for architecture understanding
- ‚úÖ ALWAYS check `mvp_site/CODE_REVIEW_SUMMARY.md` for file responsibilities
- ‚úÖ Understand component responsibilities before modifying existing files
- ‚úÖ Consider impact on related components when making changes

### Browser vs HTTP Testing (üö® HARD RULE)
**CRITICAL DISTINCTION**: Never confuse browser automation with HTTP simulation
- üö® **testing_ui/**: ONLY real browser automation using Playwright | ‚ùå NEVER use `requests` library here
- üö® **testing_http/**: ONLY HTTP requests using `requests` library | ‚ùå NEVER use Playwright here
- ‚ö†Ô∏è **/testui and /testuif**: MUST use real Playwright browser automation | NO HTTP simulation
- ‚ö†Ô∏è **/testhttp and /testhttpf**: MUST use HTTP requests | NO browser automation
- ‚úÖ **/testi**: HTTP requests are acceptable (integration testing)
- **Red Flag**: If writing "browser tests" with `requests.get()`, STOP immediately
- **Command Structure**:
  - `/testui` = Browser + Mock APIs
  - `/testuif` = Browser + REAL APIs (costs $)
  - `/testhttp` = HTTP + Mock APIs  
  - `/testhttpf` = HTTP + REAL APIs (costs $)
- üö® **Screenshot Rule**: Real screenshots are PNG/JPG images taken by browsers
  - ‚ùå NEVER create text files and name them .png
  - ‚ùå NEVER simulate screenshots with text descriptions
  - ‚úÖ If browser tests can't run, say "Cannot take screenshots - Playwright not installed"

### Browser Test Execution Protocol (üö® MANDATORY STEPS)

üö® **CRITICAL**: Playwright IS installed in venv! Stop assuming it isn't!
- ‚úÖ Playwright works perfectly when venv is activated
- ‚ùå NEVER say "Playwright isn't installed"
- ‚ùå NEVER create simulated tests as a workaround

#### Preferred Method - Using run_ui_tests.sh
**ALWAYS use the test runner script when available:**
```bash
# Run all UI tests with mock APIs (recommended for testing)
./run_ui_tests.sh mock

# Run all UI tests with real APIs (costs money!)
./run_ui_tests.sh

# Run specific test file
TESTING=true vpython testing_ui/test_specific_file.py
```

**The run_ui_tests.sh script handles:**
- ‚úÖ Virtual environment activation
- ‚úÖ Playwright installation verification
- ‚úÖ Browser dependency checks
- ‚úÖ Test server startup with proper ports
- ‚úÖ Parallel test execution
- ‚úÖ Proper cleanup on exit
- ‚úÖ Screenshot directory setup
- ‚úÖ Comprehensive result reporting

#### Manual Method (if script unavailable)
When asked to run browser tests manually, follow these steps IN ORDER:

1. **Check Playwright Installation**
   ```bash
   vpython -c "import playwright" || echo "STOP: Playwright not installed"
   ```
   - ‚úÖ Continue only if import succeeds
   - ‚ùå FULL STOP if not installed - report: "Cannot run browser tests - Playwright not installed"

2. **Verify Browser Dependencies**
   ```bash
   vpython -c "from playwright.sync_api import sync_playwright; p = sync_playwright().start(); p.chromium.launch(headless=True); p.stop()" || echo "STOP: Browser deps missing"
   ```
   - ‚úÖ Continue only if browser launches
   - ‚ùå FULL STOP if fails - report: "Cannot launch browsers - missing system dependencies"

3. **Start Test Server**
   ```bash
   TESTING=true PORT=6006 vpython mvp_site/main.py serve &
   sleep 3
   curl -s http://localhost:6006 || echo "STOP: Server not running"
   ```
   - ‚úÖ Continue only if server responds
   - ‚ùå FULL STOP if fails - report: "Cannot start test server"

4. **Navigate with Test Mode URL Parameters**
   üö® **CRITICAL**: Browser tests MUST use test mode URL parameters to bypass authentication:
   ```
   http://localhost:6006?test_mode=true&test_user_id=test-user-123
   ```
   - `test_mode=true` - Enables frontend test authentication bypass
   - `test_user_id=test-user-123` - Sets the test user ID (optional, defaults to 'test-user')
   - Without these parameters, you'll be stuck at the sign-in page!
   - The frontend detects these parameters and adds test headers to all API calls
   - See `mvp_site/testing_ui/README_TEST_MODE.md` for complete details

5. **Run Browser Test**
   ```bash
   TESTING=true vpython testing_ui/test_name.py
   ```
   - ‚úÖ Report actual results/errors
   - ‚ùå NEVER create fake output

**GOLDEN RULE**: Stop at first failure. Never proceed to simulate missing components.

### HTTP Test Execution Protocol (‚ö†Ô∏è MANDATORY STEPS)
When asked to run HTTP tests, follow these steps IN ORDER:

1. **Verify Test Environment**
   ```bash
   vpython -c "import requests" || echo "STOP: requests library not installed"
   ```
   - ‚úÖ Continue only if import succeeds
   - ‚ùå FULL STOP if not installed

2. **Start Test Server (if needed)**
   ```bash
   TESTING=true PORT=8086 python mvp_site/main.py serve &
   sleep 3
   curl -s http://localhost:8086 || echo "Note: Using different port or external server"
   ```
   - ‚úÖ Continue even if local server fails (tests may use different setup)

3. **Run HTTP Test**
   ```bash
   TESTING=true python testing_http/test_name.py
   ```
   - ‚úÖ Report actual HTTP responses/errors
   - ‚ùå NEVER pretend requests succeeded

### General Test Protocol (üö® APPLIES TO ALL TESTS)
1. **Environment Check First**: Verify ALL dependencies before attempting test
2. **Fail Fast**: Stop at first missing dependency
3. **Honest Reporting**: State exactly what failed and why
4. **No Workarounds**: Don't create alternatives that hide the real issue

### Coverage Analysis Protocol (‚ö†Ô∏è)
**MANDATORY**: When analyzing test coverage:
1. **ALWAYS use**: `./run_tests.sh --coverage` or `./coverage.sh` (HTML default)
2. **NEVER use**: Manual `coverage run` commands on individual test files
3. **Verify full test suite**: Ensure all 94+ test files are included in coverage analysis
4. **Report source**: Always mention "Coverage from full test suite via run_tests.sh"
5. **Expected timing**: ~10 seconds total (6s tests + 4s report generation)
6. **HTML location**: `/tmp/worldarchitectai/coverage/index.html`
7. **Usage patterns**:
   - `./coverage.sh` - Unit tests with HTML report (default)
   - `./coverage.sh --integration` - Include integration tests
   - `./coverage.sh --no-html` - Text report only
   - `./run_tests.sh --coverage` - Use existing test runner with coverage

### Current Coverage Baseline (January 2025)
**Last Accurate Measurement**: 67% overall coverage (21,031 statements, 6,975 missing)
- `main.py`: 74% (550 statements, 144 missing)
- `firestore_service.py`: 64% (254 statements, 91 missing)
- `gemini_service.py`: 70% (594 statements, 178 missing)
- `game_state.py`: 90% (169 statements, 17 missing - excellent!)
- **Integration tests**: 0% (not run by default - use --integration flag)
- **Mock services**: 32-36% (expected for mock objects)

## Git Workflow

| Rule | Description | Commands/Actions |
|------|-------------|------------------|
| **Main = Truth** | Use `git show main:<file>` for originals | ‚ùå push to main (except roadmap/sprint files) |
| **PR Workflow** | All changes via PRs | `gh pr create` + test results in description |
| **Branch Safety** | Verify before push | `git push origin HEAD:branch-name` |
| **Integration** | Fresh branch after merge | `./integrate.sh` |
| **Pre-PR Check** | Verify commits/files | ‚Üí `.cursor/rules/validation_commands.md` |
| **Post-Merge** | Check unpushed files | `git status` ‚Üí follow-up PR if needed |
| **Progress Track** | Scratchpad + JSON | `roadmap/scratchpad_[branch].md` + `tmp/milestone_*.json` |
| **PR Testing** | Apply PRs locally | `gh pr checkout <PR#>` |
| **Roadmap Exception** | Direct push allowed | Only: roadmap/*.md, sprint_*.md |

üö® **No Main Push**: ‚úÖ `git push origin HEAD:feature` | ‚ùå `git push origin main`

üö® **PR Context Management**: ‚ö†Ô∏è MANDATORY before creating new branches/PRs:
1. **Check git status**: `git status` and `git branch` to see current work
2. **Verify PR context**: When user says "push to the PR" without number, ask which PR
3. **Use existing branches**: Check if work should go to existing PR before creating new
4. **Never assume**: If ambiguous, ask for clarification rather than creating duplicate work

üö® **Auto-Conflict Resolution**: ‚ö†Ô∏è AUTOMATIC conflict resolution available:
1. **GitHub Actions**: Automatically runs on PR creation/push and resolves common conflicts
2. **Manual script**: Use `./resolve_conflicts.sh` to resolve conflicts for current PR
3. **Smart resolution**: Preserves learning content, handles common patterns in learnings.md and CLAUDE.md
4. **Fallback**: If auto-resolution fails, manual intervention required

üö® **BRANCH PROTECTION PROTOCOL**: ‚ö†Ô∏è MANDATORY branch usage rules:
1. **dev[timestamp] branches**: ‚ùå NEVER make changes directly in these branches
   - These are protective branches to prevent accidental main pushes
   - Used ONLY for initial isolation from main branch
   - If found on one, immediately create new descriptive branch for actual work
   - Clean up by deleting after switching to proper branch

2. **Branch Creation Rules**:
   - ‚úÖ ALWAYS create descriptive branches: `feature/task-description`, `fix/issue-name`, `update/component-name`
   - ‚úÖ Use existing feature branches when continuing related work
   - ‚ùå NEVER use dev[timestamp] branches for actual development
   - ‚ùå NEVER make commits directly in dev[timestamp] branches

3. **Branch Cleanup Protocol**:
   - When leaving a dev[timestamp] branch: delete it immediately
   - Use `git branch -D dev[timestamp]` to clean up
   - Only keep meaningful, descriptive branches

**Commit Format**: ‚Üí `.cursor/rules/examples.md`

## Environment, Tooling & Scripts

1. **Python venv**: Verify activated before running Python/tests
2. **Robust Scripts**: Make idempotent, work from any subdirectory
3. **Python Execution**: ‚úÖ Run from project root | ‚ùå cd into subdirs
4. **vpython Tests**: 
   - ‚ö†Ô∏è "run all tests" ‚Üí `./run_tests.sh`
   - ‚ö†Ô∏è Test fails ‚Üí fix immediately or ask user
   - ‚úÖ `TESTING=true vpython mvp_site/test_file.py` (from root)
5. üö® **NEVER DISMISS FAILING TESTS**: ‚ùå "minor failures" or "test expectation updates" | ‚úÖ Fix ALL failing tests systematically | Debug root cause | Real bugs vs test issues | One failure = potential systemic issue
6. **Tool Failure**: Try alternative after 2 fails | Fetch from main if corrupted
7. **Web Scraping**: Use full-content tools (curl) not search snippets

**Test Commands**: ‚Üí `.cursor/rules/validation_commands.md`

## Data Integrity & AI Management

1. **Data Defense**: Assume incomplete/malformed | Use `dict.get()` | Validate structures
2. **Critical Logic**: Implement safeguards in code, not just prompts
3. **Single Truth**: One clear way per task | Remove conflicting rules

## Knowledge Management

### Scratchpad Protocol (‚ö†Ô∏è)
`roadmap/scratchpad_[branch].md`: Goal | Plan | State | Next | Context | Branch info

### File Organization
- **CLAUDE.md**: Primary protocol
- **lessons.mdc**: Technical learnings from corrections
- **project.md**: Repository-specific knowledge base
- **rules.mdc**: Cursor configuration

### Process Improvement
- **5 Whys**: Root cause ‚Üí lessons.mdc
- **Sync Cursor**: Copy CLAUDE.md to Cursor settings after changes
- **Proactive Docs**: Update rules/lessons after debugging without prompting

## Critical Lessons (Compressed)

### Core Patterns
- **Validate Implementation**: Docs ‚â† code | Trace data flow end-to-end
- **Code Reviews**: Extract ALL comments | ‚ùå assume "suppressed" = unimportant
- **Empty Strings**: ‚úÖ `if value is not None:` | ‚ùå `if value:`
- **AI Instructions**: Critical first, style last | Order determines compliance
- üö® **Trust But Verify**: NEVER assume existing code works | Test core functionality before adding features | Validate success AND failure paths
- üö® **Fake Results = Instant Failure**: Creating fake test output violates core trust
  - Examples: Text files named .png, "simulated" results when real tests fail
  - Correct response: "Cannot run X because Y is not installed/available"

### Debugging Protocol (üö® MANDATORY)
When debugging display/output issues:
1. **Trace Complete Data Flow**: Backend ‚Üí API ‚Üí Frontend ‚Üí Display
   - ‚ùå NEVER assume formatting comes from backend without checking
   - ‚úÖ ALWAYS check where labels/prefixes are added (often frontend)
   - ‚úÖ Search for literal strings in BOTH backend (.py) AND frontend (.js/.html)
2. **Question Assumptions**:
   - "Is this one string or multiple parts combined?"
   - "Where is formatting added - data layer or presentation layer?"
   - "What does the raw API response actually look like?"
3. **Verify Before Fixing**:
   - ‚úÖ Use browser DevTools Network tab to see actual API responses
   - ‚úÖ Add logging at multiple points to trace data transformation
   - ‚úÖ Test hypothesis with minimal changes first
   - ‚ùå NEVER implement complex fixes based on assumptions
4. **Common Patterns**:
   - Frontend often adds labels/prefixes for display
   - "Scene #", "Turn:", "Player:" etc. are usually UI additions
   - Raw data rarely contains display formatting
5. **Document Analysis Protocol**:
   - ‚úÖ Extract exact error messages/code snippets FIRST
   - ‚úÖ Analyze ONLY based on extracted evidence
   - ‚úÖ Cite specific line numbers and file paths
   - ‚úÖ Each debugging claim must reference actual output
   - ‚úÖ Base all debugging claims on actual behavior, not theory
   - ‚ùå NEVER skip the extraction step
   - ‚ùå NEVER analyze what you haven't seen
   - ‚ùå NEVER suggest fixes without understanding the actual error

### Evidence Classification
When presenting information, classify sources:
1. **Primary** (üîç): Actual code/errors/output - "The error shows: `TypeError at line 45`"
2. **Secondary** (üìö): Docs/comments - "According to Flask docs..."
3. **General** (üí°): Patterns/practices - "This typically indicates..."
4. **Speculation** (‚ùì): Theories - "This might be caused by..."

### Debugging Validation Checklist
For all debugging sessions:
- [ ] Error messages extracted verbatim with context
- [ ] Relevant code shown with file:line references
- [ ] Root cause identified based on evidence (not guessed)
- [ ] Fix tested/verified or marked as "proposed"
- [ ] Edge cases considered ("What if X is null?")
- [ ] Rollback plan provided if fix might break things

### Iterative Debugging Method
When fixes aren't working:
1. üîç **Minimal case** - Reproduce with simplest example
2. üîß **Simple first** - Try easiest fix before complex ones
3. ‚úÖ **Verify broadly** - Test fix in multiple scenarios
4. üîÑ **Refine** - Adjust based on edge cases
5. üìù **Document** - Record what worked and why

### Reasoning Transparency
When debugging/analyzing:
- Show the "why": "This error typically appears when..."
- Connect dots: "Since X shows Y, this indicates Z"
- Mark assumptions: "Assuming standard Flask setup..."

### Complex Problem Breakdown
For multi-faceted issues:
1. **Decompose**: Break into smaller sub-problems
2. **Prioritize**: Address most likely/impactful first
3. **Validate**: Test each assumption explicitly
4. **Synthesize**: Combine findings into solution

### Handling Information Conflicts
When sources disagree:
- üîç **Code wins**: Implementation trumps documentation
- üìö **Version check**: "Docs for v2.0, but code uses v1.5"
- ü§ù **Show both**: "Docs say X, but code does Y"
- ‚ùì **Flag uncertainty**: "Conflicting info about..."
- üî¨ **Test to verify**: "Let me check which is correct"

### Critical Rules
- **Data Corruption**: Treat as systemic | Search ALL similar patterns | "One bug = many bugs"
- **Temp Fixes**: ‚ö†Ô∏è Flag immediately | Propose permanent fix NOW | Run sustainability checklist
- **Task Complete**: Problem solved + Docs updated + Memory updated + Self-audit + THEN done
- **Test Truth**: Names must match implementation | Verify modules/dependencies | Test rejection cases
- **Integration First**: ‚ùå test disconnected code | Verify prerequisites | Propose correct sequence
- **Analysis + Execution**: Both required | Red flags: blind execution, ignoring blockers

### Enforcement
- **Meta-Rules**: Lessons docs = ‚ö†Ô∏è NOT OPTIONAL | Immediate, automatic, every time
- **Schema**: Clear structures | Remove contradictions | Type validation | Concrete examples

**Detailed Lessons**: ‚Üí `.cursor/rules/lessons.mdc`

## Slash Commands

Use `/list` to display all available slash commands with descriptions.

**Command Documentation**: ‚Üí `.claude/commands/`

üö® **SLASH COMMAND ENFORCEMENT**: 
- `/e` or `/execute` MUST follow exact protocol in `.claude/commands/execute.md`
- NEVER treat `/e` as regular request - always use milestone protocol
- MANDATORY steps: Context check ‚Üí Subagent analysis ‚Üí User approval ‚Üí Milestone execution
- ‚ùå NEVER skip protocol steps or treat as normal task execution

**Chained Commands Support**:
- `/e /think` - Execute with ultrathink mode enabled
- `/e /think [task]` - Execute task with maximum thinking budget
- Commands can be chained with space separation
- First command determines primary mode, subsequent commands modify behavior

**Command Aliases**:
- `/tddf` - Alias for `/4layer` (Test-Driven Development Four-layer protocol)
- Both commands execute identical four-layer TDD testing protocol

**Command Examples**: ‚Üí `.cursor/rules/examples.md`

## Special Protocols

### GitHub Copilot Comments (‚ö†Ô∏è)
Reply to EVERY comment | Status: Fixed/Acknowledged/Future | ‚ùå ignore "suppressed"

### Code Review Protocol (`/review` `/copilot`) (‚ö†Ô∏è)
**MANDATORY**: When reviewing PRs, list EVERY SINGLE comment explicitly:
1. Use `gh pr view <PR#> --comments` to get ALL comments
2. Use `gh api repos/owner/repo/pulls/<PR#>/comments` for inline comments
3. List each comment with:
   - Author (user vs bot)
   - File:Line if applicable
   - Full comment text
   - Status: ‚úÖ Addressed / ‚ùå Not addressed / üîÑ Partially addressed
4. Include "suppressed" and "low confidence" comments
5. Extract comments from ALL sources:
   - PR review comments
   - Inline code comments
   - Issue comments
   - Bot suggestions

### Import Rules (‚ö†Ô∏è)
**CRITICAL**: ALL imports MUST be at module level (top of file)
- ‚úÖ Top of module only - after docstring, before any code
- ‚ùå NEVER inside functions, methods, or class definitions
- ‚ùå NEVER inside try/except blocks (except for import fallbacks)
- ‚ùå NEVER conditional imports inside if statements
- Import once at top, reference throughout module
- For import conflicts: use `as` aliases, not inline imports

### API Error Prevention (üö®)
‚ùå Print code/file content | ‚úÖ Use file_path:line_number | Keep responses concise

### Browser Testing vs HTTP Testing (üö®)
**HARD RULE - NO SIMULATION FOR BROWSER TESTS**:
- üö® **NEVER create HTTP simulation tests for `/testuif` or browser automation**
- ‚úÖ `/testi` - HTTP requests are fine (integration testing via API endpoints)
- ‚úÖ `/testuif` - MUST use real Playwright browser automation (NO HTTP simulation)
- ‚ùå **STOP SIMULATING** - User explicitly demanded real browsers for UI testing
- **Browser tests require**: Actual page navigation, element clicking, form filling, screenshot capture
- **If auth blocks browser tests**: Implement frontend test mode bypass, NOT HTTP simulation

### PR References (‚ö†Ô∏è)
**MANDATORY**: When discussing PRs, ALWAYS include the full GitHub URL
- ‚úÖ Format: "PR #123: https://github.com/jleechan2015/worldarchitect.ai/pull/123"
- ‚úÖ Use `gh pr view <PR#> --web` to get URL quickly
- ‚ùå Never reference PRs by number only
- **Repository URL**: https://github.com/jleechan2015/worldarchitect.ai




## Project-Specific

### Flask: SPA route for index.html | Hard refresh for CSS/JS | Cache-bust in prod
### Python: venv required | Source .bashrc after changes | May need python3-venv
### AI/LLM: Detailed prompts crucial | Critical instructions first | Long prompts = fatigue
### Workflow: Simple-first | Tool fail = try alternative | Main branch = recovery source

## Quick Reference

- **Test**: `TESTING=true vpython mvp_site/test_file.py` (from root)
- **Integration**: `TESTING=true python3 mvp_site/test_integration/test_integration.py`
- **New Branch**: `./integrate.sh`
- **All Tests**: `./run_tests.sh`
- **Deploy**: `./deploy.sh` or `./deploy.sh stable`

## Additional Documentation

- **Technical Lessons**: ‚Üí `.cursor/rules/lessons.mdc`
- **Cursor Config**: ‚Üí `.cursor/rules/rules.mdc`
- **Examples**: ‚Üí `.cursor/rules/examples.md`
- **Commands**: ‚Üí `.cursor/rules/validation_commands.md`

### Archive Process
Quarterly/2500 lines/new year ‚Üí `lessons_archive_YYYY.mdc` | Keep critical patterns | Reference archives

## API Timeout Prevention (üö®)

**MANDATORY**: Prevent API timeouts with these strategies:

### Operation Size Management
- **Break large edits**: Use MultiEdit with 3-4 focused edits max
- **Limit sequential thinking**: 5-6 thoughts instead of 8+
- **File reading**: Use offset/limit for huge files

### Response Optimization
- **Concise responses**: Essential with /think mode active
- **Bullet points**: Prefer over verbose paragraphs
- **Minimal output**: Only what's requested

### Tool Call Efficiency
- **Batch operations**: Group related tool calls
- **Avoid redundancy**: Don't re-read unchanged files
- **Smart search**: Use Grep/Glob instead of reading entire directories

### Sequential Thinking Best Practices
- **Start small**: Begin with 4-5 totalThoughts
- **Expand carefully**: Use needsMoreThoughts only if essential
- **Concise thoughts**: Keep each thought focused
- **Avoid branching**: Unless specifically needed

### Edit Strategy
- **MultiEdit**: For large changes, use multiple targeted edits
- **Section targeting**: Modify specific sections, not entire files
- **Incremental updates**: Break massive changes across messages

### Timing Awareness
- **Server load**: Timeouts correlate with system load
- **Complex operations**: /think + sequential thinking adds overhead
- **Work distribution**: Split very large tasks across multiple messages