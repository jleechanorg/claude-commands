# CLAUDE.md - Primary Rules and Operating Protocol

**Primary rules file for AI collaboration on WorldArchitect.AI**

## Legend
üö® = CRITICAL | ‚ö†Ô∏è = MANDATORY | ‚úÖ = Always/Do | ‚ùå = Never/Don't | ‚Üí = See reference | PR = Pull Request

## File Organization
- **CLAUDE.md** (this file): Primary operating protocol
- **.cursor/rules/rules.mdc**: Cursor-specific configuration
- **.cursor/rules/lessons.mdc**: Technical lessons and incident analysis
- **.cursor/rules/examples.md**: Detailed examples and patterns
- **.cursor/rules/validation_commands.md**: Common command reference

## Meta-Rules


üö® **NO FALSE ‚úÖ**: Only use ‚úÖ for 100% complete/working. Use ‚ùå ‚ö†Ô∏è üîÑ or text for partial.

üö® **NO POSITIVITY**: Be extremely self-critical. No celebration unless 100% working.

üö® **NEVER SIMULATE**: Ask if stuck. Fake answer = 1000x worse than getting help.
   - ‚ùå NEVER create fake files pretending to be real output (e.g., text files named .png)
   - ‚ùå NEVER show "simulated" test results when real tests fail
   - ‚ùå NEVER create workarounds that hide actual failures
   - ‚úÖ ALWAYS say "I cannot do X because Y" when facing limitations
   - ‚úÖ ALWAYS show actual error messages instead of hiding them

üö® **NO EXCUSES FOR TEST FAILURES**: When asked to fix tests, FIX THEM ALL
   - ‚ùå NEVER say "pre-existing issues" or "unrelated to our changes"
   - ‚ùå NEVER settle for partial fixes (97/99 is NOT acceptable)
   - ‚ùå NEVER blame test expectations - fix the code to meet them
   - ‚úÖ ALWAYS fix ALL failing tests to 100% pass rate
   - ‚úÖ ALWAYS take ownership of test failures, especially in new code

## Claude Code Specific Behavior

1. **Directory Context**: Operates in worktree directory shown in environment
2. **Tool Usage**: File ops, bash commands, web tools available
3. **Test Execution**: Use `vpython` with `TESTING=true`
4. **File Paths**: Always absolute paths
5. **Gemini SDK**: `from google import genai` (NOT `google.generativeai`)
6. **Path Conventions**: `roadmap/` = `/roadmap/` from project root
7. üö® **BRANCH DISCIPLINE**: ‚ùå NEVER switch git branches unless user explicitly requests it | Work on current branch only | Ask before any `git checkout` operations
8. üö® **PUSH VERIFICATION**: ‚ö†Ô∏è ALWAYS verify push success by querying remote commits after every `git push` | Use `gh pr view` or `git log origin/branch` to confirm changes are on remote
9. üö® **PR STATUS INTERPRETATION**: ‚ö†Ô∏è CRITICAL - GitHub PR states mean:
   - **OPEN** = Work In Progress (WIP) - NOT completed
   - **MERGED** = Completed and integrated into main branch  
   - **CLOSED** = Abandoned or rejected - NOT completed
   - ‚ùå NEVER mark tasks as completed just because PR exists
   - ‚úÖ ONLY mark completed when PR state = "MERGED"

## Project Overview

WorldArchitect.AI = AI-powered tabletop RPG platform (digital D&D 5e GM)

**Stack**: Python 3.11/Flask/Gunicorn | Gemini API | Firebase Firestore | Vanilla JS/Bootstrap | Docker/Cloud Run

**Docs**: ‚Üí `.cursor/rules/project_overview.md` (full details)
- Documentation map ‚Üí `.cursor/rules/documentation_map.md`
- Quick reference ‚Üí `.cursor/rules/quick_reference.md`
- Progress tracking ‚Üí `roadmap/templates/progress_tracking_template.md`
- Directory structure ‚Üí `/directory_structure.md`

## Core Principles & Interaction

**Work Approach**:
Clarify before acting | User instructions = law | ‚ùå delete without permission | Leave working code alone |
Focus on primary goal | Propose before implementing | Summarize key takeaways | Externalize all knowledge

**Rule Management**:
"Add to rules" ‚Üí CLAUDE.md | Technical lessons ‚Üí lessons.mdc | General = rules | Specific = lessons

**Development Protocols**: ‚Üí `.cursor/rules/planning_protocols.md`

**Edit Verification**: `git diff`/`read_file` before proceeding | Additive/surgical edits only

**Testing**: Red-green methodology | Test truth verification | UI = test experience not code | Use ADTs

**Red-Green Protocol** (`/tdd` or `/rg`):
1. Write failing tests FIRST ‚Üí 2. Confirm fail (red) ‚Üí 3. Minimal code to pass (green) ‚Üí 4. Refactor

üö® **Test Infrastructure Validation Protocol**:
When working with test runners/harnesses:
1. **Verify Core Function**: Before adding features, verify runner correctly detects PASS vs FAIL
2. **Test Both Paths**: Create one passing test AND one failing test to validate detection
3. **Output Analysis**: If visual output (‚ùå/‚úÖ) doesn't match summary, STOP and fix immediately
4. **Exit Code Distrust**: Don't rely solely on process exit codes - parse actual output
5. **Contradiction = Bug**: Any mismatch between test output and summary is CRITICAL bug

üö® **MANDATORY TEST EXECUTION BEFORE COMPLETION**:
‚ùå NEVER claim test completion without executing at least ONE test successfully
- Before any ‚úÖ "tests complete", run at least one test to verify framework works
- If dependencies missing (Playwright, etc.), FULL STOP - report "Cannot complete - X not installed"
- Use ‚ö†Ô∏è "Created but unverified" instead of ‚úÖ "Complete" for untested code
- Only use ‚úÖ after seeing actual PASS/FAIL results from real test execution

## Development Guidelines

### Code Standards
- Treat existing code as template | String constants: module-level (>1x) or constants.py (cross-file)
- **SOLID Principles**: Single Responsibility Principle (one reason to change), Open/Closed Principle
- **DRY principle** | Defensive programming: `isinstance()` validation
- **Separation of Concerns**: Domain logic separate from data layer, utility functions isolated
- **Import Organization**: All imports at file top, sorted (stdlib ‚Üí third-party ‚Üí local)
- **No Inline Imports**: Never import inside functions/methods/classes

### Gemini SDK
‚úÖ `from google import genai` | ‚úÖ `client = genai.Client(api_key=api_key)`
Models: `gemini-2.5-flash` (default), `gemini-1.5-flash` (test)

### Development Practices
`tempfile.mkdtemp()` for test files | Verify before assuming | ‚ùå unsolicited refactoring |
**Logging**: ‚úÖ `import logging_util` | ‚ùå `import logging` | Use project's unified logging
Use docstrings, proper JS loading

### Quality & Testing
- File naming: descriptive, ‚ùå "red"/"green" | Methods <500 lines | Single responsibility
- Integration tests: natural state, flexible assertions | Visual testing required
- Dead code: use `vulture` | Test behavior not strings
- üö® **Test Runner Validation**: When modifying test runners, MUST verify both PASS and FAIL detection | Create intentional failure case | Verify output matches actual result
- üö® **Output Contradiction Check**: If output shows failure indicators (‚ùå, FAILED, ERROR) but summary shows success (‚úÖ, PASSED), STOP immediately and investigate
- ‚ö†Ô∏è **Test Exit Codes**: Don't assume test scripts return proper exit codes | Parse output for success/failure strings | Verify detection logic before trusting results
- ‚ö†Ô∏è **Dynamic Test Discovery**: ‚ùå NEVER hardcode test file lists in scripts | ‚úÖ Use `find` or glob patterns to discover tests automatically | Update test runners to scan directories (e.g., `find testing_ui -name "test_*.py"`)

### Safety & Security
‚ùå Global `document.addEventListener('click')` without approval | Test workflows after modifications |
Document blast radius | Backups ‚Üí `tmp/` | ‚ùå commit if "DO NOT SUBMIT" | Analysis + execution required

### Browser vs HTTP Testing (üö® HARD RULE)
**CRITICAL DISTINCTION**: Never confuse browser automation with HTTP simulation
- üö® **testing_ui/**: ONLY real browser automation using Playwright | ‚ùå NEVER use `requests` library here
- üö® **testing_http/**: ONLY HTTP requests using `requests` library | ‚ùå NEVER use Playwright here
- ‚ö†Ô∏è **/testui and /testuif**: MUST use real Playwright browser automation | NO HTTP simulation
- ‚ö†Ô∏è **/testhttp and /testhttpf**: MUST use HTTP requests | NO browser automation
- ‚úÖ **/testi**: HTTP requests are acceptable (integration testing)
- **Red Flag**: If writing "browser tests" with `requests.get()`, STOP immediately
- **Command Structure**:
  - `/testui` = Browser + Mock APIs
  - `/testuif` = Browser + REAL APIs (costs $)
  - `/testhttp` = HTTP + Mock APIs  
  - `/testhttpf` = HTTP + REAL APIs (costs $)
- üö® **Screenshot Rule**: Real screenshots are PNG/JPG images taken by browsers
  - ‚ùå NEVER create text files and name them .png
  - ‚ùå NEVER simulate screenshots with text descriptions
  - ‚úÖ If browser tests can't run, say "Cannot take screenshots - Playwright not installed"

### Browser Test Execution Protocol (üö® MANDATORY STEPS)

#### Preferred Method - Using run_ui_tests.sh
**ALWAYS use the test runner script when available:**
```bash
# Run all UI tests with mock APIs (recommended for testing)
./run_ui_tests.sh mock

# Run all UI tests with real APIs (costs money!)
./run_ui_tests.sh

# Run specific test file
TESTING=true vpython testing_ui/test_specific_file.py
```

**The run_ui_tests.sh script handles:**
- ‚úÖ Virtual environment activation
- ‚úÖ Playwright installation verification
- ‚úÖ Browser dependency checks
- ‚úÖ Test server startup with proper ports
- ‚úÖ Parallel test execution
- ‚úÖ Proper cleanup on exit
- ‚úÖ Screenshot directory setup
- ‚úÖ Comprehensive result reporting

#### Manual Method (if script unavailable)
When asked to run browser tests manually, follow these steps IN ORDER:

1. **Check Playwright Installation**
   ```bash
   vpython -c "import playwright" || echo "STOP: Playwright not installed"
   ```
   - ‚úÖ Continue only if import succeeds
   - ‚ùå FULL STOP if not installed - report: "Cannot run browser tests - Playwright not installed"

2. **Verify Browser Dependencies**
   ```bash
   vpython -c "from playwright.sync_api import sync_playwright; p = sync_playwright().start(); p.chromium.launch(headless=True); p.stop()" || echo "STOP: Browser deps missing"
   ```
   - ‚úÖ Continue only if browser launches
   - ‚ùå FULL STOP if fails - report: "Cannot launch browsers - missing system dependencies"

3. **Start Test Server**
   ```bash
   TESTING=true PORT=6006 vpython mvp_site/main.py serve &
   sleep 3
   curl -s http://localhost:6006 || echo "STOP: Server not running"
   ```
   - ‚úÖ Continue only if server responds
   - ‚ùå FULL STOP if fails - report: "Cannot start test server"

4. **Run Browser Test**
   ```bash
   TESTING=true vpython testing_ui/test_name.py
   ```
   - ‚úÖ Report actual results/errors
   - ‚ùå NEVER create fake output

**GOLDEN RULE**: Stop at first failure. Never proceed to simulate missing components.

### HTTP Test Execution Protocol (‚ö†Ô∏è MANDATORY STEPS)
When asked to run HTTP tests, follow these steps IN ORDER:

1. **Verify Test Environment**
   ```bash
   vpython -c "import requests" || echo "STOP: requests library not installed"
   ```
   - ‚úÖ Continue only if import succeeds
   - ‚ùå FULL STOP if not installed

2. **Start Test Server (if needed)**
   ```bash
   TESTING=true PORT=8086 vpython mvp_site/main.py serve &
   sleep 3
   curl -s http://localhost:8086 || echo "Note: Using different port or external server"
   ```
   - ‚úÖ Continue even if local server fails (tests may use different setup)

3. **Run HTTP Test**
   ```bash
   TESTING=true vpython testing_http/test_name.py
   ```
   - ‚úÖ Report actual HTTP responses/errors
   - ‚ùå NEVER pretend requests succeeded

### General Test Protocol (üö® APPLIES TO ALL TESTS)
1. **Environment Check First**: Verify ALL dependencies before attempting test
2. **Fail Fast**: Stop at first missing dependency
3. **Honest Reporting**: State exactly what failed and why
4. **No Workarounds**: Don't create alternatives that hide the real issue

### Coverage Analysis Protocol (‚ö†Ô∏è)
**MANDATORY**: When analyzing test coverage:
1. **ALWAYS use**: `./run_tests.sh --coverage` or `./coverage.sh` (HTML default)
2. **NEVER use**: Manual `coverage run` commands on individual test files
3. **Verify full test suite**: Ensure all 94+ test files are included in coverage analysis
4. **Report source**: Always mention "Coverage from full test suite via run_tests.sh"
5. **Expected timing**: ~10 seconds total (6s tests + 4s report generation)
6. **HTML location**: `/tmp/worldarchitectai/coverage/index.html`
7. **Usage patterns**:
   - `./coverage.sh` - Unit tests with HTML report (default)
   - `./coverage.sh --integration` - Include integration tests
   - `./coverage.sh --no-html` - Text report only
   - `./run_tests.sh --coverage` - Use existing test runner with coverage

## Git Workflow

| Rule | Description | Commands/Actions |
|------|-------------|------------------|
| **Main = Truth** | Use `git show main:<file>` for originals | ‚ùå push to main (except roadmap/sprint files) |
| **PR Workflow** | All changes via PRs | `gh pr create` + test results in description |
| **Branch Safety** | Verify before push | `git push origin HEAD:branch-name` |
| **Integration** | Fresh branch after merge | `./integrate.sh` |
| **Pre-PR Check** | Verify commits/files | ‚Üí `.cursor/rules/validation_commands.md` |
| **Post-Merge** | Check unpushed files | `git status` ‚Üí follow-up PR if needed |
| **Progress Track** | Scratchpad + JSON | `roadmap/scratchpad_[branch].md` + `tmp/milestone_*.json` |
| **PR Testing** | Apply PRs locally | `gh pr checkout <PR#>` |
| **Roadmap Exception** | Direct push allowed | Only: roadmap/*.md, sprint_*.md |

üö® **No Main Push**: ‚úÖ `git push origin HEAD:feature` | ‚ùå `git push origin main`

üö® **PR Context Management**: ‚ö†Ô∏è MANDATORY before creating new branches/PRs:
1. **Check git status**: `git status` and `git branch` to see current work
2. **Verify PR context**: When user says "push to the PR" without number, ask which PR
3. **Use existing branches**: Check if work should go to existing PR before creating new
4. **Never assume**: If ambiguous, ask for clarification rather than creating duplicate work

**Commit Format**: ‚Üí `.cursor/rules/examples.md`

## Environment, Tooling & Scripts

1. **Python venv**: Verify activated before running Python/tests
2. **Robust Scripts**: Make idempotent, work from any subdirectory
3. **Python Execution**: ‚úÖ Run from project root | ‚ùå cd into subdirs
4. **vpython Tests**: 
   - ‚ö†Ô∏è "run all tests" ‚Üí `./run_tests.sh`
   - ‚ö†Ô∏è Test fails ‚Üí fix immediately or ask user
   - ‚úÖ `TESTING=true vpython mvp_site/test_file.py` (from root)
5. üö® **NEVER DISMISS FAILING TESTS**: ‚ùå "minor failures" or "test expectation updates" | ‚úÖ Fix ALL failing tests systematically | Debug root cause | Real bugs vs test issues | One failure = potential systemic issue
6. **Tool Failure**: Try alternative after 2 fails | Fetch from main if corrupted
7. **Web Scraping**: Use full-content tools (curl) not search snippets

**Test Commands**: ‚Üí `.cursor/rules/validation_commands.md`

## Data Integrity & AI Management

1. **Data Defense**: Assume incomplete/malformed | Use `dict.get()` | Validate structures
2. **Critical Logic**: Implement safeguards in code, not just prompts
3. **Single Truth**: One clear way per task | Remove conflicting rules

## Knowledge Management

### Scratchpad Protocol (‚ö†Ô∏è)
`roadmap/scratchpad_[branch].md`: Goal | Plan | State | Next | Context | Branch info

### File Organization
- **CLAUDE.md**: Primary protocol
- **lessons.mdc**: Technical learnings from corrections
- **project.md**: Repository-specific knowledge base
- **rules.mdc**: Cursor configuration

### Process Improvement
- **5 Whys**: Root cause ‚Üí lessons.mdc
- **Sync Cursor**: Copy CLAUDE.md to Cursor settings after changes
- **Proactive Docs**: Update rules/lessons after debugging without prompting

## Critical Lessons (Compressed)

### Core Patterns
- **Validate Implementation**: Docs ‚â† code | Trace data flow end-to-end
- **Code Reviews**: Extract ALL comments | ‚ùå assume "suppressed" = unimportant
- **Empty Strings**: ‚úÖ `if value is not None:` | ‚ùå `if value:`
- **AI Instructions**: Critical first, style last | Order determines compliance
- üö® **Trust But Verify**: NEVER assume existing code works | Test core functionality before adding features | Validate success AND failure paths
- üö® **Fake Results = Instant Failure**: Creating fake test output violates core trust
  - Examples: Text files named .png, "simulated" results when real tests fail
  - Correct response: "Cannot run X because Y is not installed/available"

### Debugging Protocol (üö® MANDATORY)
When debugging display/output issues:
1. **Trace Complete Data Flow**: Backend ‚Üí API ‚Üí Frontend ‚Üí Display
   - ‚ùå NEVER assume formatting comes from backend without checking
   - ‚úÖ ALWAYS check where labels/prefixes are added (often frontend)
   - ‚úÖ Search for literal strings in BOTH backend (.py) AND frontend (.js/.html)
2. **Question Assumptions**:
   - "Is this one string or multiple parts combined?"
   - "Where is formatting added - data layer or presentation layer?"
   - "What does the raw API response actually look like?"
3. **Verify Before Fixing**:
   - ‚úÖ Use browser DevTools Network tab to see actual API responses
   - ‚úÖ Add logging at multiple points to trace data transformation
   - ‚úÖ Test hypothesis with minimal changes first
   - ‚ùå NEVER implement complex fixes based on assumptions
4. **Common Patterns**:
   - Frontend often adds labels/prefixes for display
   - "Scene #", "Turn:", "Player:" etc. are usually UI additions
   - Raw data rarely contains display formatting

### Critical Rules
- **Data Corruption**: Treat as systemic | Search ALL similar patterns | "One bug = many bugs"
- **Temp Fixes**: ‚ö†Ô∏è Flag immediately | Propose permanent fix NOW | Run sustainability checklist
- **Task Complete**: Problem solved + Docs updated + Memory updated + Self-audit + THEN done
- **Test Truth**: Names must match implementation | Verify modules/dependencies | Test rejection cases
- **Integration First**: ‚ùå test disconnected code | Verify prerequisites | Propose correct sequence
- **Analysis + Execution**: Both required | Red flags: blind execution, ignoring blockers

### Enforcement
- **Meta-Rules**: Lessons docs = ‚ö†Ô∏è NOT OPTIONAL | Immediate, automatic, every time
- **Schema**: Clear structures | Remove contradictions | Type validation | Concrete examples

**Detailed Lessons**: ‚Üí `.cursor/rules/lessons.mdc`

## Slash Commands

Use `/list` to display all available slash commands with descriptions.

**Command Documentation**: ‚Üí `.claude/commands/`

**Special Commands**:
- `/think` - Maximum thinking budget | Append "ultrathink" to trigger Claude's highest computation level

**Command Examples**: ‚Üí `.cursor/rules/examples.md`

## Special Protocols

### GitHub Copilot Comments (‚ö†Ô∏è)
Reply to EVERY comment | Status: Fixed/Acknowledged/Future | ‚ùå ignore "suppressed"

### Code Review Protocol (`/review` `/copilot`) (‚ö†Ô∏è)
**MANDATORY**: When reviewing PRs, list EVERY SINGLE comment explicitly:
1. Use `gh pr view <PR#> --comments` to get ALL comments
2. Use `gh api repos/owner/repo/pulls/<PR#>/comments` for inline comments
3. List each comment with:
   - Author (user vs bot)
   - File:Line if applicable
   - Full comment text
   - Status: ‚úÖ Addressed / ‚ùå Not addressed / üîÑ Partially addressed
4. Include "suppressed" and "low confidence" comments
5. Extract comments from ALL sources:
   - PR review comments
   - Inline code comments
   - Issue comments
   - Bot suggestions

### Import Rules (‚ö†Ô∏è)
**CRITICAL**: ALL imports MUST be at module level (top of file)
- ‚úÖ Top of module only - after docstring, before any code
- ‚ùå NEVER inside functions, methods, or class definitions
- ‚ùå NEVER inside try/except blocks (except for import fallbacks)
- ‚ùå NEVER conditional imports inside if statements
- Import once at top, reference throughout module
- For import conflicts: use `as` aliases, not inline imports

### API Error Prevention (üö®)
‚ùå Print code/file content | ‚úÖ Use file_path:line_number | Keep responses concise

### Browser Testing vs HTTP Testing (üö®)
**HARD RULE - NO SIMULATION FOR BROWSER TESTS**:
- üö® **NEVER create HTTP simulation tests for `/testuif` or browser automation**
- ‚úÖ `/testi` - HTTP requests are fine (integration testing via API endpoints)
- ‚úÖ `/testuif` - MUST use real Playwright browser automation (NO HTTP simulation)
- ‚ùå **STOP SIMULATING** - User explicitly demanded real browsers for UI testing
- **Browser tests require**: Actual page navigation, element clicking, form filling, screenshot capture
- **If auth blocks browser tests**: Implement frontend test mode bypass, NOT HTTP simulation

### PR References (‚ö†Ô∏è)
**MANDATORY**: When discussing PRs, ALWAYS include the full GitHub URL
- ‚úÖ Format: "PR #123: https://github.com/jleechan2015/worldarchitect.ai/pull/123"
- ‚úÖ Use `gh pr view <PR#> --web` to get URL quickly
- ‚ùå Never reference PRs by number only
- **Repository URL**: https://github.com/jleechan2015/worldarchitect.ai




## Project-Specific

### Flask: SPA route for index.html | Hard refresh for CSS/JS | Cache-bust in prod
### Python: venv required | Source .bashrc after changes | May need python3-venv
### AI/LLM: Detailed prompts crucial | Critical instructions first | Long prompts = fatigue
### Workflow: Simple-first | Tool fail = try alternative | Main branch = recovery source

## Quick Reference

- **Test**: `TESTING=true vpython mvp_site/test_file.py` (from root)
- **Integration**: `TESTING=true python3 mvp_site/test_integration/test_integration.py`
- **New Branch**: `./integrate.sh`
- **All Tests**: `./run_tests.sh`
- **Deploy**: `./deploy.sh` or `./deploy.sh stable`

## Additional Documentation

- **Technical Lessons**: ‚Üí `.cursor/rules/lessons.mdc`
- **Cursor Config**: ‚Üí `.cursor/rules/rules.mdc`
- **Examples**: ‚Üí `.cursor/rules/examples.md`
- **Commands**: ‚Üí `.cursor/rules/validation_commands.md`

### Archive Process
Quarterly/2500 lines/new year ‚Üí `lessons_archive_YYYY.mdc` | Keep critical patterns | Reference archives