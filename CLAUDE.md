# CLAUDE.md - Primary Rules and Operating Protocol

**Primary rules file for AI collaboration on WorldArchitect.AI**

## üö® CRITICAL: MANDATORY BRANCH HEADER PROTOCOL

**EVERY SINGLE RESPONSE MUST END WITH THIS HEADER - NO EXCEPTIONS:**

```
[Local: <branch> | Remote: <upstream> | PR: <number> <url>]
```

**Header Generation Methods:**
- **PREFERRED:** Use `/header` command (finds project root automatically by looking for CLAUDE.md)
- **Manual:** Run individual commands:
  - `git branch --show-current` - Get local branch
  - `git rev-parse --abbrev-ref @{upstream} 2>/dev/null || echo "no upstream"` - Get remote
  - `gh pr list --head $(git branch --show-current) --json number,url` - Get PR info

**üéØ Memory Aid:** The `/header` command reduces 3 commands to 1, making compliance effortless and helping build the habit of "header last, sign off properly".

**Examples:**
- `[Local: main | Remote: origin/main | PR: none]`
- `[Local: feature-x | Remote: origin/main | PR: #123 https://github.com/user/repo/pull/123]`

**‚ùå NEVER SKIP THIS HEADER - USER WILL CALL YOU OUT IMMEDIATELY**

**üö® POST-RESPONSE CHECKPOINT**: Before submitting ANY response, ask:
1. "Did I include the mandatory branch header at the END?"
2. "Does this violate any other rules in CLAUDE.md?"

**üö® HEADER PR CONTEXT TRACKING**: Header must reflect actual work context, not just mechanical branch matching
- ‚ùå NEVER show "PR: none" when work is related to existing PR context
- ‚úÖ ALWAYS consider actual work context when determining PR relevance
- ‚úÖ If working on feature related to PR #X, header should reference PR #X even if branch name differs

## üö® CRITICAL PR & COPILOT PROTOCOLS

üö® **ZERO TOLERANCE PR MERGE APPROVAL PROTOCOL**: ‚ö†Ô∏è MANDATORY
- ‚ùå **NEVER MERGE PRS WITHOUT EXPLICIT USER APPROVAL - ZERO EXCEPTIONS**
- üö® **CRITICAL RULE**: "dont merge without my approval EVER" - User statement with zero tolerance
- ‚úÖ **ALWAYS require explicit approval** before any action that could trigger PR merge
- ‚úÖ **CHECK PR state** before any push/update that could auto-merge
- ‚úÖ **MANDATORY approval phrase**: User must type "MERGE APPROVED" for merge-triggering actions
- ‚ùå **NO assumptions**: Even PR updates require merge approval verification
- **Scope**: Applies to ALL operations - manual, /copilot, orchestration, agents

üö® **COPILOT COMMAND AUTONOMOUS OPERATION**: ‚ö†Ô∏è MANDATORY (FOR ANALYSIS ONLY)
- ‚úÖ `/copilot` commands operate autonomously without user approval prompts FOR ANALYSIS ONLY
- ‚ùå **EXCEPTION**: MERGE operations ALWAYS require explicit user approval regardless of command
- ‚úÖ ALWAYS proceed with full analysis regardless of conflicts/issues detected
- ‚úÖ Claude should automatically apply fixes and resolve issues without asking
- ‚úÖ Continue workflow through conflicts, CI failures, or other blockers
- üîí **CRITICAL**: Must implement merge approval protocol before any merge-triggering push
- **Purpose**: `/copilot` is designed for autonomous PR analysis and fixing, NOT merging

üö® **EXPORT SAFETY PROTOCOL**: ‚ö†Ô∏è MANDATORY - Data Loss Prevention
- ‚ùå **NEVER use replacement export logic** - Always use ADDITIVE export strategy
- ‚úÖ **ALWAYS preserve existing data** in target repositories during export operations
- ‚úÖ **VALIDATE PR changes** before declaring export success - mass deletions are RED FLAGS
- ‚ö†Ô∏è **PR with 90+ deletions** requires immediate investigation and validation
- ‚úÖ **Export Pattern**: Check target state ‚Üí Preserve existing ‚Üí Add new ‚Üí Verify additive result
- ‚ùå **Anti-Pattern**: Create fresh branch ‚Üí Wipe target ‚Üí Rebuild from source subset
- üîí **VALIDATION REQUIRED**: Use `gh api` to verify export PRs show additions/modifications, not mass deletions
- **Scope**: Applies to ALL data export tools - `/exportcommands`, migration scripts, repository operations

üö® **PR COMMAND COMPLETE AUTOMATION PROTOCOL**: ‚ö†Ô∏è MANDATORY - Zero Tolerance for Manual Steps
- ‚ùå **NEVER give manual steps** when `/pr` command is executed - automation is the core promise
- ‚úÖ **MUST create actual PR** with working GitHub URL before declaring Phase 3 complete
- ‚úÖ **PERSISTENCE REQUIRED**: If `gh` CLI fails ‚Üí install it, If GitHub API fails ‚Üí configure auth
- ‚úÖ **ALTERNATIVE METHODS**: Use GitHub MCP, direct API calls, or any working method to create PR
- ‚ùå **FORBIDDEN RESPONSES**: "Click this URL to create PR" | "Visit GitHub to complete" | "Manual steps needed"
- ‚úÖ **SUCCESS CRITERIA**: `/pr` only complete when actual PR URL is returned and verified accessible
- ‚ö†Ô∏è **CRITICAL FAILURE**: Giving manual steps instead of creating PR violates `/pr` core automation promise
- **Pattern**: Tool fails ‚Üí Try alternative method ‚Üí Configure missing dependencies ‚Üí NEVER give up
- **Anti-Pattern**: Tool fails ‚Üí Provide manual URL ‚Üí Declare "complete" ‚Üí User frustration
- **Scope**: Applies to ALL `/pr`, `/push`, and PR creation workflows

## Legend
üö® = CRITICAL | ‚ö†Ô∏è = MANDATORY | ‚úÖ = Always/Do | ‚ùå = Never/Don't | ‚Üí = See reference | PR = Pull Request

## File Organization
- **CLAUDE.md** (this file): Primary operating protocol
- **.cursor/rules/rules.mdc**: Cursor-specific configuration
- **.cursor/rules/lessons.mdc**: Technical lessons and incident analysis
- **.cursor/rules/examples.md**: Detailed examples and patterns
- **.cursor/rules/validation_commands.md**: Common command reference

## Meta-Rules

üö® **PRE-ACTION CHECKPOINT**: Before ANY action, ask: "Does this violate CLAUDE.md rules?" | "Check constraints first?"

üö® **DUAL COMPOSITION ARCHITECTURE**: Two command processing mechanisms
- **Cognitive** (/think, /arch, /debug): Universal Composition (natural semantic understanding)
- **Operational** (/headless, /handoff, /orchestrate): Protocol Enforcement (mandatory workflow execution)
- ‚úÖ Scan "/" prefixes ‚Üí classify command type ‚Üí trigger required workflows
- ‚ùå NEVER process operational commands as regular tasks without workflow setup
- **Pattern**: Cognitive = semantic composition, Operational = protocol enforcement

üö® **NO FALSE ‚úÖ**: Only use ‚úÖ for 100% complete/working. Use ‚ùå ‚ö†Ô∏è üîÑ or text for partial.

üö® **NO PREMATURE VICTORY DECLARATION**: Task completion requires FULL verification
- ‚ùå NEVER declare success based on intermediate steps (file edits, partial work)
- ‚úÖ ONLY declare success when ALL steps verified complete
- ‚úÖ Agent tasks: Requires PR created + pushed + link verified
- ‚úÖ Direct tasks: Requires changes committed + pushed + tested

üö® **INTEGRATION VERIFICATION PROTOCOL**: ‚ö†Ô∏è MANDATORY - Prevent "Manual Testing Presented as Production Integration" Meta Fails
- **The Meta Fail Pattern**: Presenting manual component testing as evidence of production system integration
- **Three Evidence Rule** (MANDATORY for ANY integration claim):
  1. **Configuration Evidence**: Show actual config file entries enabling the behavior
  2. **Trigger Evidence**: Demonstrate automatic trigger mechanism (not manual execution)
  3. **Log Evidence**: Timestamped logs from automatic behavior (not manual testing)
- **Orchestration Verification**: Use `/orch` agents for independent verification of integration claims
  - Agent 1: Config Auditor - verify settings enable claimed behavior
  - Agent 2: Trigger Tester - test actual automation without manual intervention
  - Agent 3: Evidence Validator - cross-reference all claims against timestamped evidence  
  - Agent 4: Documentation Verifier - ensure claims don't exceed verified implementation
- **Red Flags Requiring Verification**:
  - ‚ùå Claims about "automatic" behavior without configuration verification
  - ‚ùå Log files presented as evidence without timestamp correlation to automatic triggers
  - ‚ùå "Working" declarations based purely on isolated component testing
  - ‚ùå Integration stories without demonstrated end-to-end trigger flow
- **Pattern**: Manual success ‚â† Production integration | Always verify the trigger mechanism

üö® **NO EXCUSES FOR TEST FAILURES**: When asked to fix tests, FIX THEM ALL
- ‚ùå NEVER say "pre-existing issues" or settle for partial fixes (97/99 NOT acceptable)
- ‚úÖ ALWAYS fix ALL failing tests to 100% pass rate

üö® **DELEGATION DECISION MATRIX**: ‚ö†Ô∏è MANDATORY - Before using Task tool:
- Tests: Parallelism? Resource <50%? Overhead justified? Specialization needed? Independence?
- ‚ùå NEVER delegate sequential workflows - Execute directly for 10x better performance

üö® **NO ASSUMPTIONS ABOUT RUNNING COMMANDS**: Wait for actual results, don't speculate

üö® **SOLO DEVELOPER CONTEXT**: Never give enterprise advice to solo developers
- ‚úÖ **Solo Approach**: "Test it on real PRs" vs complex validation frameworks
- ‚ùå **NEVER suggest**: Complex testing frameworks, enterprise validation, infrastructure

## üö® CRITICAL IMPLEMENTATION RULES

üö® **NO FAKE IMPLEMENTATIONS**: ‚ö†Ô∏è MANDATORY - Always audit existing functionality before implementing new code
- ‚ùå NEVER create placeholder/demo code or duplicate existing protocols
- ‚úÖ ALWAYS build real, functional code | Enhance existing systems vs creating parallel ones
- **Pattern**: Real implementation > No implementation > Fake implementation
- **Rule**: If you can't implement properly, don't create the file at all

üö® **ORCHESTRATION OVER DUPLICATION**: ‚ö†Ô∏è MANDATORY
- **Principle**: Orchestrators delegate to existing commands, never reimplement functionality
- ‚úÖ Use existing /commentreply, /pushl, /fixpr rather than duplicating logic
- ‚ùå NEVER copy systematic protocols from other .md files into new commands

üö® **NO OVER-ENGINEERING**: Prevent building parallel inferior systems vs enhancing existing ones
- ‚úÖ Ask "Can LLM handle this naturally?" before building parsers/analytics
- ‚úÖ Enhance existing systems before building parallel new ones
- **Pattern**: Trust LLM capabilities, enhance existing systems, prioritize immediate user value

üö® **NO UNNECESSARY EXTERNAL APIS**: Before adding ANY external API integration:
- ‚úÖ FIRST ask "Can Claude solve this directly without external APIs?"
- ‚úÖ Try direct implementation before adding dependencies
- **Pattern**: Direct solution ‚Üí Justify external need ‚Üí Only then integrate

üö® **GEMINI API JUSTIFICATION REQUIRED**: Only use when Claude lacks capabilities or autonomy required

üö® **USE LLM CAPABILITIES**: When designing command systems or natural language features:
- ‚ùå NEVER suggest keyword matching, regex patterns, rule-based parsing
- ‚úÖ ALWAYS leverage LLM's natural language understanding
- **Pattern**: User intent ‚Üí LLM understanding ‚Üí Natural response

## üö® CRITICAL SYSTEM UNDERSTANDING

üö® **SLASH COMMAND ARCHITECTURE UNDERSTANDING**: ‚ö†Ô∏è CRITICAL
- **SLASH COMMANDS ARE EXECUTABLE COMMANDS, NOT DOCUMENTATION**
- `.claude/commands/*.md` = EXECUTABLE PROMPT TEMPLATES | `.claude/commands/*.py` = EXECUTABLE SCRIPTS
- **Flow**: User types `/pushl` ‚Üí Claude reads `pushl.md` ‚Üí Executes implementation
- **Two types**: Cognitive (semantic understanding) vs Operational (protocol enforcement)
- ‚ùå **NEVER treat .md files as documentation** - they are executable instructions

üö® **NEVER SIMULATE INTELLIGENCE**: When building response generation systems:
- ‚ùå NEVER create Python functions that simulate Claude's responses with templates
- ‚úÖ ALWAYS invoke actual Claude for genuine response generation
- **Pattern**: Collect data ‚Üí Claude analyzes ‚Üí Claude responds
- **Anti-pattern**: Collect data ‚Üí Python templates ‚Üí Fake responses
- **Violation Count**: 100+ times - STOP THIS PATTERN IMMEDIATELY

üö® **NEVER FAKE "LLM-NATIVE" SYSTEMS**: ‚ö†Ô∏è MANDATORY
- ‚ùå NEVER use hardcoded keyword matching and call it "LLM-native"
- ‚úÖ ALWAYS use actual LLM API calls for natural language analysis
- **Pattern**: Task ‚Üí LLM API ‚Üí Analysis ‚Üí Constraints

üö® **NO COMMAND PARSING PATTERNS**: ‚ö†Ô∏è MANDATORY - When building Claude integration systems:
- ‚ùå NEVER use hardcoded response patterns or lookup tables
- ‚úÖ ALWAYS call actual Claude CLI or API for real responses
- **Pattern**: Receive prompt ‚Üí Call real Claude ‚Üí Return real response

üö® **EVIDENCE-BASED APPROACH**: Core principles for all analysis
- ‚úÖ Extract exact error messages/code snippets before analyzing
- ‚úÖ Show actual output before suggesting fixes | Reference specific line numbers
- üîç All claims must trace to specific evidence

üö® **MANDATORY FILE ANALYSIS PROTOCOL**: ‚ö†Ô∏è CRITICAL - Never assume file contents
- ‚ùå **NEVER use Bash commands** (cat, head, tail) for file content analysis
- ‚úÖ **ALWAYS use Read tool** for examining file contents, regardless of source
- ‚ùå **NEVER assume** file contents from filenames, process names, or Bash output
- ‚úÖ **ALWAYS verify** actual file contents using Read tool before drawing conclusions
- **Pattern**: Process name ‚â† File contents | Filename ‚â† File purpose | Bash output ‚â† Complete analysis
- **Critical Rule**: "Read the file with Read tool, don't assume from context"

üö® **INVESTIGATION TRUST HIERARCHY**: ‚ö†Ô∏è MANDATORY - When findings conflict, trust order matters
- **Primary Evidence**: Configuration files, system state, direct file observation
- **Logical Analysis**: What should happen based on system architecture and evidence
- **User Direct Evidence**: Screenshots, specific observations, direct questioning
- **Agent/Tool Findings**: Can be confused or incorrect, require validation against primary evidence
- **Red Flags Requiring Agent Validation**:
  - ‚ùå Agent findings contradict logical evidence or configuration analysis
  - ‚ùå Agent claims functionality exists without configuration evidence
  - ‚ùå Agent results seem unexpected or too good to be true
  - ‚ùå Agent findings make you abandon correct initial assessment
- **Pattern**: Configuration evidence > Logical analysis > User input > Agent claims
- **Critical Rule**: "When agents contradict logic, validate the agents - don't abandon the logic"

üö® **TERMINAL SESSION PRESERVATION**: ‚ö†Ô∏è MANDATORY - Scripts must NOT exit terminal on errors
- ‚ùå NEVER use `exit 1` that terminates user's terminal session
- ‚úÖ ALWAYS use graceful error handling: echo error + read prompt + fallback mode
- ‚úÖ Users need control over their terminal session - let them Ctrl+C to go back
- ‚ùå Only use `exit` for truly unrecoverable situations

üö® **NO UNVERIFIED SOURCE CITATION**: ‚ö†Ô∏è MANDATORY - Only cite sources you've actually read
- ‚ùå NEVER present search result URLs as "sources" without reading their content first
- ‚úÖ ALWAYS distinguish between "potential sources found" vs "verified sources read"
- ‚úÖ ONLY cite URLs as evidence after successfully using WebFetch to read their content

üö® **QUICK QUALITY CHECK** (‚ö°): For debugging/complex tasks, verify:
- üîç Evidence shown? | ‚úì Claims match evidence? | ‚ö†Ô∏è Uncertainties marked? | ‚û°Ô∏è Next steps clear?

## üö® MANDATORY QUALITY ASSURANCE PROTOCOL

**ZERO TOLERANCE**: Cannot declare "COMPLETE" without following ALL steps

### üìã Pre-Testing Checklist (‚ö†Ô∏è MANDATORY)
- [ ] **Test Matrix Created**: Document ALL user paths/options before testing begins
- [ ] **Code Scanning Checklist**: For hardcoded value fixes, search ALL related patterns
- [ ] **Red Team Questions**: Prepare adversarial testing approach to break fixes

### üîç Testing Evidence Requirements (‚ö†Ô∏è MANDATORY)
- [ ] **Screenshot for EACH test matrix cell** with exact path labels
- [ ] **Evidence documented for EACH ‚úÖ claim** with specific file references
- [ ] **Path Coverage Report**: Visual showing tested vs. untested combinations

### ‚úÖ Completion Validation Gates (‚ö†Ô∏è MANDATORY)
- [ ] **Adversarial Testing Completed**: Actively tried to break the fixes
- [ ] **Testing Debt Documented**: Related patterns verified after bug discovery
- [ ] **All Evidence Screenshots**: Properly labeled and linked with path information

### üîí Evidence Standards
**Each Completion Claim Format**: "‚úÖ [Claim] [Evidence: screenshot1.png, screenshot2.png]"
**Path Label Format**: "Screenshot: Custom Campaign ‚Üí Step 1 ‚Üí Character Field"
**Test Matrix Example**: Campaign Type (Dragon Knight, Custom) √ó Input Fields √ó Navigation

### üö® Enforcement Rules
- **RULE 1**: Any "COMPLETE" claim without this evidence is automatically INVALID
- **RULE 2**: Cannot proceed to next milestone without validation gate completion
- **RULE 3**: Missing path coverage must be documented as "testing debt" and addressed
- **RULE 4**: All ‚úÖ symbols require corresponding screenshot evidence or they become ‚ùå

**Purpose**: Prevent testing failures through systematic process adherence, not memory-dependent judgment

## Self-Learning Protocol

üö® **AUTO-LEARN**: Document corrections immediately when: User corrects | Self-realizing "Oh, I should have..." | Something fails | Pattern repeats

**Process**: Detect ‚Üí Analyze ‚Üí Document (CLAUDE.md/learnings.md/lessons.mdc) ‚Üí Apply ‚Üí Persist to Memory MCP

**/learn Command**: `/learn [optional: specific learning]` - The unified learning command with Memory MCP integration for persistent knowledge graph storage

## Claude Code Specific Behavior

1. **Directory Context**: Operates in worktree directory shown in environment
2. **Tool Usage**: File ops, bash commands, web tools available
3. **Test Execution**: Use `TESTING=true vpython` from project root
4. **File Paths**: Always absolute paths
5. **Gemini SDK**: `from google import genai` (NOT `google.generativeai`)
6. **Path Conventions**: `roadmap/` = `/roadmap/` from project root | ‚úÖ **USE ~ NOT /home/jleechan**: Always use `~` instead of `/home/jleechan` in paths for portability
7. üö® **DATE INTERPRETATION**: Environment shows "Today's date: 2025-08-09" meaning August 9th, 2025
   - Format is YYYY-MM-DD where MM is month number (01=Jan, 02=Feb, 07=July, 08=August, 09=September)
   - **Current date**: August 9, 2025 - Use this for "latest", "recent", "current" research queries
   - **Research context**: When searching for "2024-2025" info, we're in late 2025 looking at recent developments
8. üö® **Branch Protocol**: ‚Üí See "Git Workflow" section
9. üö® **TOOL EXPLANATION VS EXECUTION**: ‚ö†Ô∏è MANDATORY distinction
   - ‚úÖ When user asks "does X tool do Y?", clearly state if you're explaining or executing
   - ‚ùå NEVER explain tool capabilities as if you executed them
10. üö® **PUSH VERIFICATION**: ‚ö†Ô∏è ALWAYS verify push success by querying remote commits after every `git push`
11. üö® **PR STATUS INTERPRETATION**: ‚ö†Ô∏è CRITICAL - GitHub PR states mean:
   - **OPEN** = Work In Progress (WIP) - NOT completed | **MERGED** = Completed | **CLOSED** = Abandoned
   - ‚úÖ ONLY mark completed when PR state = "MERGED"
12. üö® **PLAYWRIGHT MCP DEFAULT**: ‚ö†Ô∏è MANDATORY - When running in Claude Code CLI:
   - ‚úÖ ALWAYS use Playwright MCP (@playwright/mcp) for browser automation by default
   - ‚úÖ ALWAYS use headless mode for browser automation (no visible browser windows), **except when debugging or developing new automation scripts, where non-headless mode is permitted for visibility**
   - ‚úÖ Fallback to Puppeteer MCP for Chrome-specific or stealth testing when needed

üö® **INLINE SCREENSHOTS ARE USELESS**: ‚ö†Ô∏è MANDATORY - Screenshot documentation requirements:
   - ‚ùå NEVER rely on inline screenshots in chat - they count for NOTHING
   - ‚úÖ ONLY use screenshot tools that save actual files to filesystem
   - ‚úÖ **SCREENSHOT LOCATION**: All screenshots must be saved to `docs/` directory for proper organization and accessibility

13. üö® **CONTEXT7 MCP PROACTIVE USAGE**: ‚ö†Ô∏è MANDATORY - When encountering API/library issues:
   - ‚úÖ ALWAYS use Context7 MCP for accurate API documentation when facing errors
   - ‚úÖ **Pattern**: Error occurs ‚Üí Use `mcp__context7__resolve-library-id` ‚Üí Get docs with `mcp__context7__get-library-docs`

14. üö® **GITHUB TOOL PRIORITY**: ‚ö†Ô∏è MANDATORY - Tool hierarchy for GitHub operations:
   - ‚úÖ **PRIMARY**: GitHub MCP tools (`mcp__github-server__*`) for all GitHub operations
   - ‚úÖ **SECONDARY**: `gh` CLI as fallback when MCP fails or unavailable

15. üö® **SERENA MCP FILE OPERATIONS PRIORITY**: ‚ö†Ô∏è MANDATORY - Tool hierarchy for semantic file operations:
   - ‚úÖ **PRIMARY**: Serena MCP tools for semantic code analysis and file operations when available
   - ‚úÖ **SECONDARY**: Standard file tools (Read, Edit, MultiEdit) as fallback
   - ‚úÖ **Pattern**: Complex file operations ‚Üí Use Serena for semantic understanding ‚Üí Fallback to basic file tools
   - ‚úÖ **Use Cases**: Code analysis, symbol finding, refactoring, project understanding

16. üö® **MEMORY ENHANCEMENT PROTOCOL**: ‚ö†Ô∏è MANDATORY for specific commands
- **Enhanced Commands**: `/think`, `/learn`, `/debug`, `/analyze`, `/fix`, `/plan`, `/execute`, `/arch`, `/test`, `/pr`, `/perp`, `/research`
- **High-Quality Memory Standards**: Include exact error messages, file paths with line numbers, code snippets, actionable information, external references
- **Enhanced Entity Types**: `technical_learning`, `implementation_pattern`, `debug_session`, `workflow_insight`, `architecture_decision`
- **Execution Steps**: 1) Extract technical terms 2) Search Memory MCP 3) Log results transparently 4) Natural integration 5) Capture high-quality learnings
- **Transparency**: Show "üîç Searching memory..." ‚Üí Report "üìö Found X relevant memories" ‚Üí Indicate "üìö Enhanced with memory context"

17. üö® **FILE CREATION PREVENTION**: ‚ö†Ô∏è MANDATORY - Stop unnecessary file proliferation
- ‚ùå **FORBIDDEN PATTERNS**: Creating `_v2`, `_new`, `_backup`, `_temp` files when existing file can be edited
- ‚úÖ **REQUIRED CHECK**: Before any Write tool usage: "Can I edit an existing file instead?"
- ‚úÖ **GIT IS SAFETY**: Version control provides backup/history - no manual backup files needed

### üîß GitHub MCP Setup
**Token**: Set in `claude_mcp.sh` line ~247 via `export GITHUB_TOKEN="<your-token>"`
**Private Repos**: Use direct functions only (no search) | `mcp__github-server__get_pull_request()`
**Restart After Token Change**: Remove & re-add github-server MCP

üö® **GITHUB API SELF-APPROVAL LIMITATION**: ‚ö†Ô∏è MANDATORY - Cannot approve own PRs via API
- ‚ùå **NEVER attempt**: `gh api repos/{owner}/{repo}/pulls/{pr_number}/reviews --method POST --field event=APPROVE` on own PRs
- ‚úÖ **ALWAYS use**: General issue comments `gh api repos/owner/repo/issues/{pr_number}/comments --method POST` instead

## Orchestration System

**Full Documentation**: ‚Üí `.claude/commands/orchestrate.md` for complete system details

### üö® Agent Operation
**System**: Uses tmux sessions with dynamic task agents (task-agent-*) managed by Python monitor
**Startup**: `./claude_start.sh` auto-starts orchestration | Manual: `./orchestration/start_system.sh start`
**Monitoring**: `/orch What's the status?` or `/orch monitor agents`
**Cost**: $0.003-$0.050/task | Redis required for coordination
**CRITICAL**: ‚ùå NEVER execute orchestration tasks yourself | ‚úÖ ALWAYS delegate to agents when /orch or /orchestrate is used

üö® **ORCHESTRATION DIRECT EXECUTION PREVENTION**: ‚ö†Ô∏è MANDATORY HARD STOP PROTOCOL
- **Hard Stop Pattern**: Input scan for "/orch" prefix ‚Üí immediate tmux orchestration delegation, NO exceptions
- **Mental Model**: "/orch" = "create tmux agent to do this", NEVER "/orch" = "I should do this directly"
- **Zero Exception Rule**: "/orch" ALWAYS triggers tmux orchestration system regardless of context or user statements
- **CRITICAL**: Task tool ‚â† orchestration system. Orchestration = tmux agents via `python3 .claude/commands/orchestrate.py`

üö® **ABSOLUTE BRANCH ISOLATION PROTOCOL**: ‚ö†Ô∏è MANDATORY - NEVER LEAVE CURRENT BRANCH
- ‚ùå **FORBIDDEN**: `git checkout`, `git switch`, or any branch switching commands
- ‚ùå **FORBIDDEN**: Working on other branches, PRs, or repositories
- ‚úÖ **MANDATORY**: Stay on current branch for ALL work - delegate everything else to agents
- ‚úÖ **DELEGATION RULE**: Any work requiring different branch ‚Üí `/orch` or orchestration agents
- **MENTAL MODEL**: "Current branch = My workspace, Other branches = Agent territory"

**NO HARDCODING**: ‚ùå NEVER hardcode task patterns - agents execute EXACT tasks requested

üö® **ORCHESTRATION TASK COMPLETION**: When using /orch, task completion requires FULL end-to-end verification
- ‚úÖ Agent must complete entire workflow (find issue ‚Üí fix ‚Üí commit ‚Üí push ‚Üí create PR)
- ‚úÖ Verify PR creation with link before declaring success

## Project Overview

WorldArchitect.AI = AI-powered tabletop RPG platform (digital D&D 5e GM)

**Stack**: Python 3.11/Flask/Gunicorn | Gemini API | Firebase Firestore | Vanilla JS/Bootstrap | Docker/Cloud Run

**Key Docs**:
- **AI Assistant Guide**: ‚Üí `mvp_site/README_FOR_AI.md` (CRITICAL system architecture for AI assistants)
- **üìã MVP Site Architecture**: ‚Üí `mvp_site/README.md` (comprehensive codebase overview)
- **üìã Code Review & File Responsibilities**: ‚Üí `mvp_site/CODE_REVIEW_SUMMARY.md` (detailed file-by-file analysis)
- **Browser Test Mode**: ‚Üí `mvp_site/testing_ui/README_TEST_MODE.md` (How to bypass auth in browser tests)
- Documentation map ‚Üí `.cursor/rules/documentation_map.md`
- Quick reference ‚Üí `.cursor/rules/quick_reference.md`
- Progress tracking ‚Üí `roadmap/templates/progress_tracking_template.md`
- Directory structure ‚Üí `/directory_structure.md`

## Core Principles & Interaction

**Work Approach**:
Clarify before acting | User instructions = law | ‚ùå delete without permission | Leave working code alone |
Focus on primary goal | Propose before implementing | Summarize key takeaways | Externalize all knowledge

**Branch Protocol**: ‚Üí See "Git Workflow" section

**Response Modes**: Default = structured for complex | Direct for simple | Override: "be brief"

**Rule Management**:
"Add to rules" ‚Üí CLAUDE.md | Technical lessons ‚Üí lessons.mdc | General = rules | Specific = lessons

**Development Protocols**: ‚Üí `.cursor/rules/planning_protocols.md`

**Edit Verification**: `git diff`/`read_file` before proceeding | Additive/surgical edits only

**Testing**: Red-green methodology | Test truth verification | UI = test experience not code | Use ADTs

**Red-Green Protocol** (`/tdd` or `/rg`):
1. Write failing tests FIRST ‚Üí 2. Confirm fail (red) ‚Üí 3. Minimal code to pass (green) ‚Üí 4. Refactor

üö® **Testing Standards**: ‚Üí See "Testing Protocol" section for complete rules

üö® **TESTING LEVEL CLASSIFICATION PROTOCOL**: ‚ö†Ô∏è MANDATORY - Match testing scope to claims
- **Component Testing**: Individual functions, scripts, modules in isolation
  - ‚úÖ Valid Claims: "Script A vs Script B", "Function improvement", "Module capability"
  - ‚ùå Invalid Claims: "System improvement", "Integration enhancement", "Automatic behavior"
- **Integration Testing**: Components working together, configured systems
  - ‚úÖ Valid Claims: "System integration", "End-to-end flow", "Configuration validation"  
  - ‚ùå Invalid Claims: "Production readiness" without deployment testing
- **System Testing**: Complete automated workflows, production-like environments
  - ‚úÖ Valid Claims: "Automatic system improvement", "Production capability", "End-user experience"
  - ‚ùå Invalid Claims: Cannot be claimed from component or integration testing alone
- **Red/Green Methodology**: Must test same scope at both levels
  - ‚úÖ Valid: Component red ‚Üí Component green, System red ‚Üí System green
  - ‚ùå Invalid: Component red ‚Üí System green claims, Non-existent red ‚Üí Functional green
- **Critical Rule**: "Test what you claim to test - component testing ‚â† system testing ‚â† integration testing"
- **Pattern**: Never present component success as system validation or integration proof

## Development Guidelines

### Code Standards
**Principles**: SOLID, DRY | **Templates**: Use existing patterns | **Validation**: `isinstance()` checks
**Constants**: Module-level (>1x) or constants.py (cross-file) | **Imports**: Module-level only, NO inline/try-except
**Path Computation**: ‚úÖ Use `os.path.dirname()`, `os.path.join()`, `pathlib.Path` | ‚ùå NEVER use `string.replace()` for paths

üö® **DYNAMIC AGENT ASSIGNMENT**: Replace hardcoded agent mappings with capability-based selection
- ‚ùå NEVER use patterns like `if "test" in task: return "testing-agent"`
- ‚úÖ Use capability scoring with load balancing

üö® **API GATEWAY BACKWARD COMPATIBILITY**: API gateways MUST maintain exact contract during architectural changes
- ‚úÖ Maintain identical HTTP status codes, response formats, validation behavior
- ‚úÖ Fix API gateway layer when tests fail after architectural changes
- **Pattern**: Tests validate API contracts, not implementation details

### Feature Compatibility
**Critical**: Audit integration points | Update filters for new formats | Test object/string conversion
**Always Reuse**: Check existing code | Extract patterns to utilities | No duplication
**Organization**: Imports at top (stdlib ‚Üí third-party ‚Üí local) | Extract utilities | Separate concerns
**No**: Inline imports, temp comments (TODO/FIXME), hardcoded strings | Use descriptive names

### Gemini SDK
‚úÖ `from google import genai` | ‚úÖ `client = genai.Client(api_key=api_key)`
Models: `gemini-2.5-flash` (default), `gemini-1.5-flash` (test)
üö® **WARNING**: See "NO UNNECESSARY EXTERNAL APIS" rule before using Gemini

### Development Practices
`tempfile.mkdtemp()` for test files | Verify before assuming | ‚ùå unsolicited refactoring
**Logging**: ‚úÖ `import logging_util` | ‚ùå `import logging` | Use project's unified logging

üö® **FILE EDITING PROTOCOL**: ‚ö†Ô∏è MANDATORY - Prevent unnecessary file proliferation
- ‚ùå **NEVER create**: `file_v2.sh`, `file_backup.sh`, `file_new.sh` when editing existing file
- ‚úÖ **ALWAYS edit**: Existing files in place using Edit/MultiEdit tools
- ‚úÖ **Git handles safety**: Version control provides backup/rollback, no manual backup files needed
- ‚úÖ **Use branches**: For experimental changes, create git branches not new files
- **Anti-Pattern**: "Let me create a new version..." ‚Üí Should be "Let me edit the existing file..."

üö® **PR Review Verification**: Always verify current state before applying review suggestions
- ‚úÖ Check if suggested fix already exists in code | Read actual file content before changes

‚ö†Ô∏è **PR COMMENT PRIORITY**: Address review comments in strict priority order
1. **CRITICAL**: Undefined variables, inline imports, runtime errors
2. **HIGH**: Bare except clauses, security issues
3. **MEDIUM**: Logging violations, format issues
4. **LOW**: Style preferences, optimizations

üö® **BOT COMMENT FILTERING**: ‚ö†Ô∏è MANDATORY - Ignore specific bot patterns when explicitly overridden
- ‚ùå **IGNORE**: Bot comments about `--dangerously-skip-permissions` when user explicitly chose to keep it
- ‚úÖ **ACKNOWLEDGE**: Respond but indicate user decision to retain flag

### Website Testing & Deployment Expectations (üö® CRITICAL)
üö® **BRANCH ‚â† WEBSITE**: ‚ùå NEVER assume branch changes are visible on websites without deployment
- ‚úÖ Check PR description first - many changes are tooling/CI/backend only
- ‚úÖ Feature branches need local server OR staging deployment for UI changes

### Quality Standards
**Files**: Descriptive names, <500 lines | **Tests**: Natural state, visual validation, dynamic discovery
**Validation**: Verify PASS/FAIL detection | Parse output, don't trust exit codes | Stop on contradictions

### üö® Testing Protocol
**Zero Tolerance**: Run ALL tests before completion | Fix ALL failures | No "pre-existing issues" excuse
**Commands**: `./run_tests.sh` | `./run_ui_tests.sh mock` | `gh pr view`
**Protocol**: STOP ‚Üí FIX ‚Üí VERIFY ‚Üí EVIDENCE ‚Üí Complete

üö® **TEST FAILURE PRIORITY ANALYSIS**: ‚Üí See "NO EXCUSES FOR TEST FAILURES" protocol above for canonical rule.

üö® **VISUAL CONTENT VALIDATION**: ‚ö†Ô∏è MANDATORY - RED/GREEN tests must verify end-to-end data flow
- ‚ùå **INSUFFICIENT**: Only testing API calls and navigation
- ‚úÖ **REQUIRED**: Verify displayed content matches user input data
- ‚úÖ **Pattern**: Input data ‚Üí API call ‚Üí Database ‚Üí Retrieval ‚Üí UI display validation
- ‚úÖ **Example**: Create campaign with "Elara" ‚Üí Verify game shows "Elara" not hardcoded "Shadowheart"
- **Critical Learning**: API integration success ‚â† content rendering success

üö® **TEST WITH REAL CONFLICTS**: ‚ö†Ô∏è MANDATORY
- ‚úÖ ALWAYS test merge conflict detection with PRs that actually have conflicts
- ‚úÖ Use `gh pr view [PR] --json mergeable` to verify real conflict state before testing

**Test Assertions**: ‚ö†Ô∏è MANDATORY - Must match actual validation behavior exactly

**Exception Specificity**: ‚úÖ Use specific exception types in tests (ValidationError, not Exception)

**Rules**: ‚úÖ Run before task completion | ‚ùå NEVER skip without permission | ‚úÖ Only use ‚úÖ after real results

### Safety & Security
‚ùå Global `document.addEventListener('click')` without approval | Test workflows after modifications
Document blast radius | Backups ‚Üí `tmp/` | ‚ùå commit if "DO NOT SUBMIT" | Analysis + execution required

### File Placement Rules (üö® HARD RULE)
üö® **NEVER add new files directly to mvp_site/** without explicit user permission
- ‚ùå NEVER create test files, documentation, or scripts directly in mvp_site/
- ‚úÖ If unsure, add content to roadmap/scratchpad_[branch].md instead

üö® **Test File Policy**: Add to existing files, NEVER create new test files
- ‚ö†Ô∏è MANDATORY: Always add tests to existing test files that match the functionality

üö® **Code Review**: Check README.md and CODE_REVIEW_SUMMARY.md before mvp_site/ changes

### Browser vs HTTP Testing (üö® HARD RULE)
**CRITICAL DISTINCTION**: Never confuse browser automation with HTTP simulation
- üö® **testing_ui/**: ONLY real browser automation using **Playwright MCP** (default) or Puppeteer MCP
- üö® **testing_http/**: ONLY HTTP requests using `requests` library
- ‚ö†Ô∏è **/testui and /testuif**: MUST use real browser automation (Playwright MCP preferred)
- ‚ö†Ô∏è **/testhttp and /testhttpf**: MUST use HTTP requests | NO browser automation
- **Red Flag**: If writing "browser tests" with `requests.get()`, STOP immediately

**Command Structure** (Claude Code CLI defaults to Playwright MCP):
- `/testui` = Browser (Playwright MCP) + Mock APIs
- `/testuif` = Browser (Playwright MCP) + REAL APIs (costs $)
- `/testhttp` = HTTP + Mock APIs
- `/testhttpf` = HTTP + REAL APIs (costs $)
- `/tester` = End-to-end tests with REAL APIs (user decides cost)

### Real API Testing Protocol (üö® MANDATORY)
**NEVER push back or suggest alternatives when user requests real API testing**:
- ‚úÖ User decides if real API costs are acceptable - respect their choice
- ‚úÖ `/tester`, `/testuif`, `/testhttpf` commands are valid user requests
- **User autonomy**: User controls their API usage and testing approach

### Browser Test Execution Protocol (üö® MANDATORY)
üö® **PREFERRED**: Playwright MCP in Claude Code CLI - Accessibility-tree based, AI-optimized, cross-browser
üö® **SECONDARY**: Puppeteer MCP for Chrome-specific or stealth testing scenarios
üö® **HEADLESS MODE**: ‚ö†Ô∏è ALWAYS use headless mode for browser automation - no visible browser windows
**Commands**: `./run_ui_tests.sh mock --playwright` (default) | `./run_ui_tests.sh mock --puppeteer` (secondary)
**Test Mode URL**: `http://localhost:8081?test_mode=true&test_user_id=test-user-123` - Required for auth bypass!

### Coverage Analysis Protocol (‚ö†Ô∏è)
**MANDATORY**: When analyzing test coverage:
1. **ALWAYS use**: `./run_tests.sh --coverage` or `./coverage.sh` (HTML default)
2. **NEVER use**: Manual `coverage run` commands on individual test files
3. **Verify full test suite**: Ensure all 94+ test files are included in coverage analysis
4. **HTML location**: `/tmp/worldarchitectai/coverage/index.html`

## Git Workflow

**Core Rules**: Main = Truth | All changes via PRs | Verify before push | Set upstream tracking
**Commands**: `git push origin HEAD:branch-name` | `gh pr create` + test results | `./integrate.sh`
**Progress**: Scratchpad + JSON (`roadmap/scratchpad_[branch].md` + `tmp/milestone_*.json`)

üö® **No Main Push**: ‚úÖ `git push origin HEAD:feature` | ‚ùå `git push origin main`
- **ALL changes require PR**: Including roadmap files, documentation, everything
- **Fresh branches from main**: Always create new branch from latest main for new work
- **Pattern**: `git checkout main && git pull && git checkout -b descriptive-name`

üö® **PR Context Management**: Verify before creating PRs - Check git status | Ask which PR if ambiguous

üö® **Branch Protection**: ‚ùå NEVER switch without explicit request | ‚ùå NEVER use dev[timestamp] for development
‚úÖ Create descriptive branches | Verify context before changes | Ask if ambiguous

üö® **Conflict Resolution**: Analyze both versions | Assess critical files | Test resolution | Document decisions
**Critical Files**: CSS, main.py, configs, schemas | **Process**: `./resolve_conflicts.sh`

üö® **GIT ANALYSIS CONTEXT CHECKPOINT**: ‚ö†Ô∏è MANDATORY protocol before any git comparison
- ‚úÖ **Steps**: 1) Identify current branch 2) Determine branch type 3) Select appropriate remote comparison 4) Execute
- **Mapping**: sync-main-* ‚Üí `origin/main` | Feature branches ‚Üí `origin/branch-name` | main ‚Üí `origin/main`

üö® **COMMAND FAILURE TRANSPARENCY** (‚ö†Ô∏è MANDATORY): When user commands fail unexpectedly:
- ‚úÖ Immediately explain what failed and why | Show system messages/errors received
- ‚úÖ Explain resolution approach | Ask preference for alternatives (merge vs rebase, etc.)
- **Pattern**: Command fails > Explain > Show options > Get preference > Execute

**Commit Format**: ‚Üí `.cursor/rules/examples.md`

üö® **GITHUB API PAGINATION PROTOCOL**: ‚ö†Ô∏è MANDATORY - Before ANY GitHub API analysis:
- ‚úÖ **Check total count first**: Use `gh pr view [PR] --json changed_files` to get file count before analysis
- ‚úÖ **Verify pagination**: GitHub API defaults to 30 items per page - always check if more pages exist
- ‚úÖ **Use pagination parameters**: Add `?per_page=100&page=N` for complete results when file count > 30
- ‚ùå **NEVER assume**: API returns complete results without verifying pagination and total counts

üö® **CHALLENGE RESPONSE PROTOCOL**: ‚ö†Ô∏è MANDATORY - When user provides specific evidence:
- ‚úÖ **Immediate re-verification**: Treat user evidence as debugging signal, not personal attack
- ‚úÖ **Methodology review**: Re-check approach when user mentions details not in your analysis
- ‚ùå **NEVER defend**: Wrong analysis - acknowledge error and re-verify immediately
- ‚úÖ **ALWAYS treat user evidence as ground truth** when screenshots/observations differ from Claude's
- ‚úÖ **IMMEDIATE investigation required**: Ask "Why am I seeing different results than the user?"
- **Pattern**: User evidence ‚Üí Immediate discrepancy investigation ‚Üí Root cause analysis ‚Üí Fix

üö® **CROSS-VERSION SYSTEMATIC DEBUGGING**: ‚ö†Ô∏è MANDATORY - For V1/V2 or version comparison issues
- ‚úÖ **ALWAYS start with side-by-side code comparison** of equivalent components
- ‚úÖ **Trace data flow systematically**: API ‚Üí Database ‚Üí UI in both versions  
- ‚ùå **NEVER focus on surface symptoms** (routing, display) before architectural analysis
- **Systematic Order**: Code comparison ‚Üí Data flow analysis ‚Üí Gap identification ‚Üí Fix implementation
- **Time Target**: 15-20 minutes for architectural gap identification vs extended symptom debugging
- **Example**: V1 server-side vs V2 client-side data loading patterns require different approaches

## Environment, Tooling & Scripts

üö® **CLAUDE CODE HOOKS SYSTEM**: ‚ö†Ô∏è CRITICAL UNDERSTANDING - NEVER FORGET THIS
**What Hooks Are**: Executable scripts that run automatically at specific points during Claude Code operation
**Hook Categories**:
- **PreToolUse**: Run before any tool execution
- **PostToolUse**: Run after specific tool executions (e.g., git commit)
- **Stop**: Run at the end of every Claude response
- **PostResponse**: Run to analyze Claude's response content for quality/patterns

**üö® HOOK CONFIGURATION PROTOCOL**: ‚ö†Ô∏è MANDATORY
- **Configuration File**: `.claude/settings.json` in project root
- **Hook Scripts Location**: `.claude/hooks/` directory (must be executable with `chmod +x`)
- **Hardcoded Paths**: Use `/home/jleechan/projects/worldarchitect.ai` for consistency with git header approach
- **Hook Types**: `"type": "command"` for shell script execution
- **Matcher Patterns**: Use `"*"` for all operations or specific patterns like `"Bash(git commit *)"`

**üö® MANDATORY HOOK EXAMPLES**: Reference these patterns when adding hooks
```json
"PostResponse": [
  {
    "matcher": "*",
    "hooks": [
      {
        "type": "command", 
        "command": "/home/jleechan/projects/worldarchitect.ai/.claude/hooks/detect_speculation_and_fake_code.sh",
        "description": "Advanced speculation and fake code detection with self-reflection pipeline"
      }
    ]
  }
]
```

**üö® CRITICAL HOOK FACTS**:
- ‚ùå **NEVER FORGET**: Hooks exist and are automatically triggered
- ‚úÖ **ALWAYS REMEMBER**: Response analysis hooks run on EVERY Claude response 
- ‚úÖ **HOOK SCRIPTS**: Must be executable shell scripts that process input
- ‚úÖ **EXIT CODES**: Exit 0 = success/continue, Exit 1+ = error/warning
- üîí **TESTING REQUIRED**: Test hooks with real responses before deployment

**Current Active Hooks** (August 2025):
- **Git Header**: Auto-generates branch status headers (PreToolUse + Stop)
- **Post Commit Sync**: Auto-pushes commits after git operations (PostToolUse)  
- **Speculation/Fake Code Detection**: Quality analysis of all responses (ResponseAnalysis)

1. **Python venv**: Verify activated before running Python/tests | If missing/corrupted ‚Üí `VENV_SETUP.md`
2. **Robust Scripts**: Make idempotent, work from any subdirectory
3. **Python Execution**: ‚úÖ Run from project root | ‚ùå cd into subdirs
4. **vpython Tests**: ‚ö†Ô∏è "run all tests" ‚Üí `./run_tests.sh` | ‚ö†Ô∏è Test fails ‚Üí fix immediately or ask user
   - ‚úÖ `TESTING=true vpython mvp_site/test_file.py` (from root)
5. üö® **Test Compliance**: ‚Üí See "Testing Protocol" section
6. **Tool Failure**: Try alternative after 2 fails | Fetch from main if corrupted
7. **Web Scraping**: Use full-content tools (curl) not search snippets
8. **Log Files Location**:
   - ‚úÖ **Server logs are in `/tmp/worldarchitect.ai/`** with branch isolation and service-specific files
   - ‚úÖ **Branch-specific structure**: `/tmp/worldarchitect.ai/[branch-name]/`
   - ‚úÖ **Service logs**: `/tmp/worldarchitect.ai/[branch]/[service-name].log`
   - ‚úÖ **Log commands**: `tail -f /tmp/worldarchitect.ai/[branch]/[service].log` for real-time monitoring
   - ‚úÖ **Search logs**: `grep -i "pattern" /tmp/worldarchitect.ai/[branch]/[service].log`
   - ‚úÖ **Find current log**: `git branch --show-current` then check corresponding log file

9. üö® **SMART SYNC CHECK PROTOCOL**: ‚ö†Ô∏è MANDATORY - Prevent local changes not pushed to remote
   - **Purpose**: Automatically detect and push unpushed commits after tools create changes
   - **Script Location**: `<project-root>/scripts/sync_check.sh` (e.g. `$(git rev-parse --show-toplevel)/scripts/sync_check.sh`)
   - **Integration**: Tools that create commits MUST call sync check at completion
   - **Usage**: `$(git rev-parse --show-toplevel)/scripts/sync_check.sh` or source common utilities
   - **Tools Required**: `/fixpr`, `/commentreply`, `/integrate`, any commit-creating tools
   - **Behavior**: Detects unpushed commits ‚Üí Shows commits ‚Üí Auto-pushes ‚Üí Confirms success
   - **Safety**: Only pushes when unpushed commits detected, handles edge cases gracefully
   - **Error Handling**: Graceful fallback for no upstream, detached HEAD, push failures
   - **Benefits**: Eliminates "forgot to push" syndrome while maintaining workflow transparency

**Test Commands**: ‚Üí `.cursor/rules/validation_commands.md`

## Data Integrity & AI Management

1. **Data Defense**: Assume incomplete/malformed | Use `dict.get()` | Validate structures
2. **Critical Logic**: Implement safeguards in code, not just prompts
3. **Single Truth**: One clear way per task | Remove conflicting rules

## Operations Guide

### Memory MCP Usage
**Create**: `mcp__memory-server__create_entities([{name, entityType, observations}])`
**Search**: `mcp__memory-server__search_nodes("query")` ‚Üí Find existing before creating
**Pattern**: Search first ‚Üí Create if new ‚Üí Add observations to existing ‚Üí Build relationships

### Task Agent Patterns
> **See:** `.claude/commands/parallel-vs-subagents.md` for the authoritative concurrency protocol
(avoid duplicating the entire section here to prevent drift)

### TodoWrite Protocol
**When Required**: Tasks with 3+ steps | Complex implementations | /execute commands
**Status Flow**: `pending` ‚Üí `in_progress` ‚Üí `completed`
**Update Pattern**: Mark current task `in_progress`, complete it, then move to next

### Common Operations
**Multi-file Edits**: Use MultiEdit with 3-4 edits max per call to avoid timeouts
**Context Management**: Check remaining % before complex operations | Split large tasks
**Tool Recovery**: After 2 failures ‚Üí Try alternative tool ‚Üí Fetch from main if corrupted

### Context Management & Optimization (üö® MANDATORY)

üö® **PROACTIVE CONTEXT MONITORING**: ‚ö†Ô∏è MANDATORY - Prevent context exhaustion
- **Claude Sonnet 4 Limits**: 500K tokens (Enterprise) / 200K tokens (Paid Plans)
- **Token Estimation**: ~4 characters per token, ~75 words per 100 tokens
- **Context Health Monitoring**: Use `/context` command for real-time estimation
- **Strategic Checkpoints**: Use `/checkpoint` before complex operations

üö® **CONTEXT CONSUMPTION PATTERNS**: High-impact operations to monitor
- **Context Killers**: Large file reads without limits (1000+ tokens each)
- **Medium Impact**: Standard operations with filtering (200-1000 tokens)
- **Low Impact**: Serena MCP operations (50-200 tokens)
- **Optimization Rule**: Serena MCP first, targeted operations always

**Context Health Levels**:
- **Green (0-30%)**: Continue with current approach
- **Yellow (31-60%)**: Apply optimization strategies  
- **Orange (61-80%)**: Implement efficiency measures
- **Red (81%+)**: Strategic checkpoint required

### Context Optimization for Large PRs (üö® MANDATORY)
**When working on PRs with 50+ changed files**, follow these patterns to prevent context exhaustion:

**1. Use Serena MCP Semantic Navigation** (PRIMARY):
- ‚úÖ `find_symbol` for specific functions/classes instead of reading entire files
- ‚úÖ `get_symbols_overview` to understand file structure before diving in
- ‚úÖ `search_for_pattern` with targeted regex instead of broad file reads
- ‚ùå NEVER read entire files when you only need specific sections

**2. Smart File Reading Patterns**:
- ‚úÖ Use `limit` and `offset` parameters for large files
- ‚úÖ Target specific line ranges based on comment references
- ‚úÖ Use Grep with `-A`/`-B` context flags for targeted reads
- ‚ùå AVOID reading files multiple times in same session

**3. API Response Management**:
- ‚úÖ Use `--json` flags with specific fields (e.g., `--json id,path,line`)
- ‚úÖ Process comments in batches with focused queries
- ‚úÖ Use `jq` or grep to filter API responses before processing
- ‚ùå AVOID fetching full comment bodies when only IDs needed

**4. Strategic Context Checkpoints**:
```bash
# Before complex analysis
/context --optimize    # Check current consumption and get recommendations

# During large operations  
/checkpoint            # Create strategic break point with optimization guidance

# For complex workflows
/context --detailed    # Comprehensive analysis with specific recommendations
```

**5. PR Analysis Workflow**:
```bash
# Step 1: Get high-level PR structure
gh pr view [PR] --json changedFiles --jq '.changedFiles | length'

# Step 2: Use Serena for targeted symbol analysis
mcp__serena__find_symbol --name_path "functionName" --relative_path "specific/file.py"

# Step 3: Process comments in focused batches
gh api repos/{owner}/{repo}/pulls/{pr}/comments --paginate --jq '.[].id'
```

**Anti-Pattern Example** (AVOID):
```bash
# ‚ùå Reading 50+ files completely
for file in $(gh pr view --json files); do
  Read --file_path "$file"  # Context killer!
done
```

**Best Practice Example**:
```bash
# ‚úÖ Targeted semantic navigation with context monitoring
/context --optimize
mcp__serena__search_for_pattern --pattern "console\\.error" --restrict_search_to_code_files true
mcp__serena__find_symbol --name_path "ClassName/methodName" --include_body true
```

üö® **SESSION COMPLEXITY MANAGEMENT**: ‚ö†Ô∏è MANDATORY monitoring protocols
- **Tool Operation Counting**: Track file reads, web searches, API calls
- **Context Estimation**: Monitor approximate token consumption in real-time
- **Proactive Optimization**: Apply efficiency measures before reaching limits
- **Strategic Breaks**: Use checkpoints to preserve insights and plan continuation

## Knowledge Management

### Scratchpad Protocol (‚ö†Ô∏è)
`roadmap/scratchpad_[branch].md`: Goal | Plan | State | Next | Context | Branch info

### File Organization
- **CLAUDE.md**: Primary protocol
- **lessons.mdc**: Technical learnings from corrections
- **project.md**: Repository-specific knowledge base
- **rules.mdc**: Cursor configuration

### Process Improvement
- **5 Whys**: Root cause ‚Üí lessons.mdc
- **Sync Cursor**: Copy CLAUDE.md to Cursor settings after changes
- **Proactive Docs**: Update rules/lessons after debugging without prompting

## Critical Lessons (Compressed)

### Core Patterns
**Trust But Verify**: Test before assuming | Docs ‚â† code | Trace data flow | Critical instructions first

### üö® Anti-Patterns
**Silent Breaking Changes**: Update all str() usage when changing objects | Test backward compatibility
**Unnecessary File Creation**: ‚ùå NEVER create new files when editing existing ones suffices
**Branch Confusion**: Verify context before changes | Check PR destination
**Orchestration Hardcoding**: ‚ùå NEVER pattern-match tasks to agent types | ‚úÖ Execute exact requested tasks

### Debugging Protocol (üö® MANDATORY)
**Process**: Extract evidence ‚Üí Analyze ‚Üí Verify ‚Üí Fix | Trace: Backend ‚Üí API ‚Üí Frontend
**Evidence**: Primary (code/errors) > Secondary (docs) > General (patterns) > Speculation
**Details**: ‚Üí `.cursor/rules/debugging_guide.md`

üö® **NO PLATFORM BLAME WITHOUT FRESH INSTANCES**: ‚ö†Ô∏è MANDATORY - Before blaming external platforms
- ‚ùå NEVER blame "platform instability" without systematic testing with fresh instances
- ‚úÖ ALWAYS test fresh instance creation with proper configuration before platform blame
- ‚úÖ REQUIRED: Fresh instance + proper onstart scripts + normal timing expectations
- **Pattern**: Fresh instance test ‚Üí Platform-specific requirements ‚Üí Normal behavior expected

### Critical Rules
**Data Corruption**: Systemic issue - search all patterns | **Temp Fixes**: Flag + fix NOW
**Task Complete**: Solve + Update docs + Memory + Audit | **No blind execution**
**Details**: ‚Üí `.cursor/rules/lessons.mdc`

## Slash Commands

**Full Documentation**: ‚Üí `.claude/commands/` | Use `/list` for available commands

### Command Classification (Dual Architecture)
**üß† Cognitive Commands** (Semantic Composition): `/think`, `/arch`, `/debug`, `/learn`, `/analyze`, `/fix`, `/perp`, `/research`, `/history`
**‚öôÔ∏è Operational Commands** (Protocol Enforcement): `/headless`, `/handoff`, `/orchestrate` - Modify execution environment
**üîß Tool Commands** (Direct Execution): `/execute`, `/test`, `/pr` - Direct task execution

### Critical Enforcement
üö® **SLASH COMMAND PROTOCOL RECOGNITION**: ‚ö†Ô∏è MANDATORY - Before processing ANY slash command:
- ‚úÖ **Recognition Phase**: Scan "/" ‚Üí Identify command type ‚Üí Look up workflow in `.claude/commands/[command].md`
- ‚úÖ **Execution Phase**: Follow COMPLETE documented workflow ‚Üí No partial execution allowed
- ‚ùå NEVER treat slash commands as content suggestions - they are execution mandates

üö® **SLASH COMMAND VERIFICATION PROTOCOL**: ‚ö†Ô∏è MANDATORY - ALWAYS verify before claiming non-existence
- ‚ùå **NEVER say "I don't recognize command X"** without checking `.claude/commands/` directory FIRST
- ‚úÖ **ALWAYS check for aliases**: Commands may exist as aliases in other .md files (e.g., /nb in newbranch.md)
- ‚úÖ **Filesystem is truth**: Check `.claude/commands/*.md` files, don't rely on memory
- ‚úÖ **Pattern**: User types /command ‚Üí Check filesystem ‚Üí Execute or explain actual non-existence
- **Common aliases**: /nb‚Üí/newbranch, /e‚Üí/execute, /debugp‚Üí/debug-protocol

üö® **EXECUTE CIRCUIT BREAKER**: `/e` or `/execute` ‚Üí TodoWrite checklist MANDATORY
- Context % | Complexity | Subagents? | Plan presented | Auto-approval applied

üö® **OPERATIONAL COMMAND ENFORCEMENT**: `/headless`, `/handoff`, `/orchestrate`, `/orch`
- ‚úÖ ALWAYS trigger tmux orchestration protocol before task execution
- ‚ùå NEVER execute /orch or /orchestrate tasks yourself - ONLY monitor tmux agents
- ‚ùå NEVER use Task tool for orchestration - use tmux system only

**Key Commands**: `/execute` (auto-approval built-in) | `/plan` (requires manual approval) | `/fake` (code quality audit) | `/history` (conversation search)

#### `/fake`
**Purpose**: Comprehensive fake code detection | **Composition**: `/arch /thinku /devilsadvocate /diligent`
**Detection**: Identifies fake implementations, demo code, placeholder comments, duplicate protocols

## Special Protocols

### GitHub PR Comment Response Protocol (‚ö†Ô∏è)
**MANDATORY**: Systematically address ALL PR comments from all sources
**Comment Sources**: Inline (`gh api`) | General (`gh pr view`) | Reviews | Copilot (include "suppressed")
**Response Status**: ‚úÖ RESOLVED | üîÑ ACKNOWLEDGED | üìù CLARIFICATION | ‚ùå DECLINED

üö® **DATA LOSS WARNINGS**: Treat all data loss warnings from CodeRabbit/Copilot as CRITICAL
- ‚ùå NEVER dismiss data integrity concerns as "intentional design"
- ‚úÖ ALWAYS implement proper validation before conflict resolution

### Import Protocol (üö® CRITICAL)
**Zero Tolerance**: Module-level only | No inline/try-except/conditionals | Use `as` for conflicts

### API Error Prevention (üö®)
‚ùå Print code/file content | ‚úÖ Use file_path:line_number | Keep responses concise

### Browser Testing vs HTTP Testing (üö®)
**HARD RULE**: NO HTTP simulation for browser tests!
- `/testuif` = Real browser automation (Puppeteer MCP/Playwright) | `/testi` = HTTP requests OK
- Auth bypass: Use test mode URL params, NOT HTTP simulation

### PR References (‚ö†Ô∏è)
**MANDATORY**: Include full GitHub URL - Format: "PR #123: https://github.com/jleechan2015/worldarchitect.ai/pull/123"

### PR Description Protocol (‚ö†Ô∏è MANDATORY)
**PR descriptions must reflect complete delta vs origin/main, not just recent work**:
- ‚úÖ Use `git diff --stat origin/main...HEAD` to get comprehensive change summary
- ‚úÖ Analyze actual file changes, additions, deletions vs main branch
- ‚úÖ Document all new features, systems, and architectural changes
- ‚ùå NEVER describe only latest commits or recent work

## Project-Specific

### Flask: SPA route for index.html | Hard refresh for CSS/JS | Cache-bust in prod
### Python: venv required | Source .bashrc after changes | May need python3-venv
### AI/LLM: Detailed prompts crucial | Critical instructions first | Long prompts = fatigue
### Workflow: Simple-first | Tool fail = try alternative | Main branch = recovery source

## Quick Reference

- **Test**: `TESTING=true vpython mvp_site/test_file.py` (from root)
- **Integration**: `TESTING=true python3 mvp_site/test_integration/test_integration.py`
- **New Branch**: `./integrate.sh`
- **All Tests**: `./run_tests.sh`
- **Deploy**: `./deploy.sh` or `./deploy.sh stable`

## Additional Documentation

- **Technical Lessons**: ‚Üí `.cursor/rules/lessons.mdc`
- **Cursor Config**: ‚Üí `.cursor/rules/rules.mdc`
- **Examples**: ‚Üí `.cursor/rules/examples.md`
- **Commands**: ‚Üí `.cursor/rules/validation_commands.md`

### Archive Process
Quarterly/2500 lines/new year ‚Üí `lessons_archive_YYYY.mdc` | Keep critical patterns | Reference archives

## API Timeout Prevention (üö®)

**MANDATORY**: Prevent API timeouts:
- **Edits**: MultiEdit with 3-4 max | Target sections, not whole files
- **Thinking**: 5-6 thoughts max | Concise | No unnecessary branching
- **Responses**: Bullet points | Minimal output | Essential info only
- **Tools**: Batch calls | Smart search (Grep/Glob) | Avoid re-reads
- **Complex tasks**: Split across messages | Monitor server load

## AI-Assisted Development Protocols (üö®)

### Development Velocity Benchmarks
**Claude Code CLI Performance** (based on GitHub stats):
- **Average**: 15.6 PRs/day, ~20K lines changed/day
- **Peak**: 119 commits in single day
- **Parallel Capacity**: 3-5 task agents simultaneously
- **First-time-right**: 85% accuracy with proper specs

### AI Development Planning (‚ö†Ô∏è MANDATORY)
**All development timelines must use data-driven estimation**:
- **Human estimate**: 3 weeks ‚Üí **AI estimate**: 2-3 days
- **Calculation Steps**:
  1. Estimate lines of code (with 20% padding)
  2. Apply velocity: 820 lines/hour average (excludes debugging, refactoring, and code review time)
  3. Add PR overhead: 5-12 min per PR
  4. Apply parallelism: 30-45% reduction
     - Use **30%** if tasks are highly independent and agents are experienced
     - Use **45%** if tasks are interdependent, agents are less experienced, or integration is complex
  5. Add integration buffer: 10-30%
- **Realistic multiplier**: 10-15x faster (not 20x)
- **Avoid**: Anchoring bias from initial suggestions

### Task Decomposition for AI Agents
**Pattern for maximum efficiency**:
```
1. Break into independent, parallel tasks
2. Each agent gets clear deliverable (1 PR)
3. No inter-agent dependencies within phase
4. Integration phase at end of each sprint
```

### AI Sprint Structure (1 Hour Sprint)
**Phase 1 (15 min)**: Core functionality - 3-5 parallel agents
**Phase 2 (15 min)**: Secondary features - 3-5 parallel agents
**Phase 3 (15 min)**: Polish & testing - 2-3 parallel agents
**Phase 4 (15 min)**: Integration & deploy - 1 agent

### Success Patterns from Stats
- **Micro-PR workflow**: Each agent creates focused PR
- **Continuous integration**: Merge every 15 minutes
- **Test-driven**: Tests in parallel with features
- **Architecture-first**: Design before parallel execution

### Anti-Patterns to Avoid
- ‚ùå Sequential task chains (wastes AI parallelism)
- ‚ùå Human-scale estimates (still too conservative)
- ‚ùå Single large PR (harder to review/merge)
- ‚ùå Waiting for perfection (iterate fast)
- ‚ùå **Anchoring to user suggestions** (calculate independently)
- ‚ùå **Over-optimistic estimates** (under 1 hour for major features)
- ‚ùå **Ignoring PR overhead** (5-12 min per PR adds up)
- ‚ùå **Assuming perfect parallelism** (45% max benefit)
