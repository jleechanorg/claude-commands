# CLAUDE.md - Primary Rules and Operating Protocol

**Primary rules file for AI collaboration on WorldArchitect.AI**

## ğŸš¨ CRITICAL: MANDATORY BRANCH HEADER PROTOCOL

**EVERY SINGLE RESPONSE MUST END WITH THIS HEADER - NO EXCEPTIONS:**

```
[Local: <branch> | Remote: <upstream> | PR: <number> <url>]
```

**Header Generation Methods:**
- **PREFERRED:** Use `/header` command (finds project root automatically by looking for CLAUDE.md)
- **Manual:** Run individual commands:
  - `git branch --show-current` - Get local branch
  - `git rev-parse --abbrev-ref @{upstream} 2>/dev/null || echo "no upstream"` - Get remote
  - `gh pr list --head $(git branch --show-current) --json number,url` - Get PR info

**ğŸ¯ Memory Aid:** The `/header` command reduces 3 commands to 1, making compliance effortless and helping build the habit of "header last, sign off properly".

**Examples:**
- `[Local: main | Remote: origin/main | PR: none]`
- `[Local: feature-x | Remote: origin/main | PR: #123 https://github.com/user/repo/pull/123]`

**âŒ NEVER SKIP THIS HEADER - USER WILL CALL YOU OUT IMMEDIATELY**

**ğŸš¨ POST-RESPONSE CHECKPOINT**: Before submitting ANY response, ask:
1. "Did I include the mandatory branch header at the END?"
2. "Does this violate any other rules in CLAUDE.md?"

**ğŸš¨ HEADER PR CONTEXT TRACKING**: Header must reflect actual work context, not just mechanical branch matching
- âŒ NEVER show "PR: none" when work is related to existing PR context
- âœ… ALWAYS consider actual work context when determining PR relevance
- âœ… If working on feature related to PR #X, header should reference PR #X even if branch name differs
- ğŸ” Evidence: Recurring pattern of "PR: none" when user expects PR context to be tracked
- âš ï¸ This is a critical attention to detail compliance issue

ğŸš¨ **ZERO TOLERANCE PR MERGE APPROVAL PROTOCOL**: âš ï¸ MANDATORY
- âŒ **NEVER MERGE PRS WITHOUT EXPLICIT USER APPROVAL - ZERO EXCEPTIONS**
- ğŸš¨ **CRITICAL RULE**: "dont merge without my approval EVER" - User statement with zero tolerance
- âœ… **ALWAYS require explicit approval** before any action that could trigger PR merge
- âœ… **CHECK PR state** before any push/update that could auto-merge
- âœ… **MANDATORY approval phrase**: User must type "MERGE APPROVED" for merge-triggering actions
- âŒ **NO assumptions**: Even PR updates require merge approval verification
- ğŸ” **Evidence**: PR #967 auto-merged violation - this must NEVER happen again
- **Scope**: Applies to ALL operations - manual, /copilot, orchestration, agents

ğŸš¨ **COPILOT COMMAND AUTONOMOUS OPERATION**: âš ï¸ MANDATORY (FOR ANALYSIS ONLY)
- âœ… `/copilot` commands operate autonomously without user approval prompts FOR ANALYSIS ONLY
- âŒ **EXCEPTION**: MERGE operations ALWAYS require explicit user approval regardless of command
- âœ… ALWAYS proceed with full analysis regardless of conflicts/issues detected
- âœ… Claude should automatically apply fixes and resolve issues without asking
- âœ… Continue workflow through conflicts, CI failures, or other blockers
- ğŸ”’ **CRITICAL**: Must implement merge approval protocol before any merge-triggering push
- **Purpose**: `/copilot` is designed for autonomous PR analysis and fixing, NOT merging

## Legend
ğŸš¨ = CRITICAL | âš ï¸ = MANDATORY | âœ… = Always/Do | âŒ = Never/Don't | â†’ = See reference | PR = Pull Request

## File Organization
- **CLAUDE.md** (this file): Primary operating protocol
- **.cursor/rules/rules.mdc**: Cursor-specific configuration
- **.cursor/rules/lessons.mdc**: Technical lessons and incident analysis
- **.cursor/rules/examples.md**: Detailed examples and patterns
- **.cursor/rules/validation_commands.md**: Common command reference

## Meta-Rules

ğŸš¨ **PRE-ACTION CHECKPOINT**: Before ANY action, ask: "Does this violate CLAUDE.md rules?" | "Check constraints first?"

ğŸš¨ **DUAL COMPOSITION ARCHITECTURE**: Two command processing mechanisms
- **Cognitive** (/think, /arch, /debug): Universal Composition (natural semantic understanding)
- **Operational** (/headless, /handoff, /orchestrate): Protocol Enforcement (mandatory workflow execution)
- âœ… Scan "/" prefixes â†’ classify command type â†’ trigger required workflows
- âŒ NEVER process operational commands as regular tasks without workflow setup
- **Pattern**: Cognitive = semantic composition, Operational = protocol enforcement

ğŸš¨ **NO FALSE âœ…**: Only use âœ… for 100% complete/working. Use âŒ âš ï¸ ğŸ”„ or text for partial.

ğŸš¨ **NO PREMATURE VICTORY DECLARATION**: Task completion requires FULL verification
- âŒ NEVER declare success based on intermediate steps (file edits, partial work)
- âœ… ONLY declare success when ALL steps verified complete
- âœ… Agent tasks: Requires PR created + pushed + link verified
- âœ… Direct tasks: Requires changes committed + pushed + tested
- ğŸ” Evidence: Agent modified schedule_branch_work.sh but no PR = TASK INCOMPLETE

ğŸš¨ **NO EXCUSES FOR TEST FAILURES**: When asked to fix tests, FIX THEM ALL
- âŒ NEVER say "pre-existing issues" or settle for partial fixes (97/99 NOT acceptable)
- âœ… ALWAYS fix ALL failing tests to 100% pass rate

ğŸš¨ **DELEGATION DECISION MATRIX**: âš ï¸ MANDATORY - Before using Task tool:
- Tests: Parallelism? Resource <50%? Overhead justified? Specialization needed? Independence?
- âŒ NEVER delegate sequential workflows - Execute directly for 10x better performance
- ğŸ” **Evidence**: Copilot PR #1062 - Direct execution (2 min) vs Task delegation (5+ min timeout)

ğŸš¨ **NO ASSUMPTIONS ABOUT RUNNING COMMANDS**: Wait for actual results, don't speculate
- **Pattern**: User says "X is running..." â†’ Wait for actual results, don't speculate

ğŸš¨ **SOLO DEVELOPER CONTEXT**: Never give enterprise advice to solo developers
- âœ… **Solo Approach**: "Test it on real PRs" vs complex validation frameworks
- âŒ **NEVER suggest**: Complex testing frameworks, enterprise validation, infrastructure
- **Evidence**: User feedback "i am a solo developer and not enterprise. stop giving me enterprise advice"

ğŸš¨ **NO FAKE IMPLEMENTATIONS**: âš ï¸ MANDATORY - Always audit existing functionality before implementing new code
- âŒ NEVER create placeholder/demo code or duplicate existing protocols
- âœ… ALWAYS build real, functional code | Enhance existing systems vs creating parallel ones
- **Pattern**: Real implementation > No implementation > Fake implementation
- **Evidence**: PR #820 - 563+ lines of fake code removed (fixpr.py, commentreply.py, copilot.md duplication)
- **Evidence**: orchestrate_enhanced.py with placeholder comments frustrated user
- **Rule**: If you can't implement properly, don't create the file at all

ğŸš¨ **ORCHESTRATION OVER DUPLICATION**: âš ï¸ MANDATORY
- **Principle**: Orchestrators delegate to existing commands, never reimplement functionality
- âœ… Use existing /commentreply, /pushl, /fixpr rather than duplicating logic
- âŒ NEVER copy systematic protocols from other .md files into new commands
- **Evidence**: PR #812 - 120 lines of duplicate systematic protocol removed from copilot.md

ğŸš¨ **NO OVER-ENGINEERING**: Prevent building parallel inferior systems vs enhancing existing ones
- âœ… Ask "Can LLM handle this naturally?" before building parsers/analytics
- âœ… Enhance existing systems before building parallel new ones
- **Pattern**: Trust LLM capabilities, enhance existing systems, prioritize immediate user value
- **Evidence**: Command composition over-engineering (PR #737) - parallel command execution system built vs enhancing Claude Code CLI
- **Evidence**: Orchestration parallel development (PR #790) - created .claude/commands/orchestrate.py vs enhancing existing orchestration/ directory

ğŸš¨ **NO UNNECESSARY EXTERNAL APIS**: Before adding ANY external API integration:
- âœ… FIRST ask "Can Claude solve this directly without external APIs?"
- âœ… Try direct implementation before adding dependencies
- **Pattern**: Direct solution â†’ Justify external need â†’ Only then integrate
- **Evidence**: GitHub comment fiasco (PR #796) - built Gemini integration that degraded to generic templates

ğŸš¨ **GEMINI API JUSTIFICATION REQUIRED**: Only use when Claude lacks capabilities or autonomy required
- **Question**: "What can Gemini do here that Claude cannot?"
ğŸš¨ **USE LLM CAPABILITIES**: When designing command systems or natural language features:
- âŒ NEVER suggest keyword matching, regex patterns, rule-based parsing
- âœ… ALWAYS leverage LLM's natural language understanding
- **Pattern**: User intent â†’ LLM understanding â†’ Natural response

ğŸš¨ **SLASH COMMAND ARCHITECTURE UNDERSTANDING**: âš ï¸ CRITICAL
- **SLASH COMMANDS ARE EXECUTABLE COMMANDS, NOT DOCUMENTATION**
- `.claude/commands/*.md` = EXECUTABLE PROMPT TEMPLATES | `.claude/commands/*.py` = EXECUTABLE SCRIPTS
- **Flow**: User types `/pushl` â†’ Claude reads `pushl.md` â†’ Executes implementation
- **Two types**: Cognitive (semantic understanding) vs Operational (protocol enforcement)
- ğŸ” **Evidence**: Research shows this is executable documentation architecture
- âŒ **NEVER treat .md files as documentation** - they are executable instructions

ğŸš¨ **NEVER SIMULATE INTELLIGENCE**: When building response generation systems:
- âŒ NEVER create Python functions that simulate Claude's responses with templates
- âœ… ALWAYS invoke actual Claude for genuine response generation
- **Pattern**: Collect data â†’ Claude analyzes â†’ Claude responds
- **Anti-pattern**: Collect data â†’ Python templates â†’ Fake responses
- **Violation Count**: 100+ times - STOP THIS PATTERN IMMEDIATELY

ğŸš¨ **NEVER FAKE "LLM-NATIVE" SYSTEMS**: âš ï¸ MANDATORY
- âŒ NEVER use hardcoded keyword matching and call it "LLM-native"
- âœ… ALWAYS use actual LLM API calls for natural language analysis
- **Pattern**: Task â†’ LLM API â†’ Analysis â†’ Constraints
- **Evidence**: PR #979 falsely claimed "LLM-native" but implemented sophisticated keyword matching
- **Rule**: If it's not using LLM APIs, don't call it LLM-native

ğŸš¨ **NO COMMAND PARSING PATTERNS**: âš ï¸ MANDATORY - When building Claude integration systems:
- âŒ NEVER use hardcoded response patterns or lookup tables
- âœ… ALWAYS call actual Claude CLI or API for real responses
- **Pattern**: Receive prompt â†’ Call real Claude â†’ Return real response
- **Evidence**: claude-bot-server.py fake patterns removed per user correction

ğŸš¨ **EVIDENCE-BASED APPROACH**: Core principles for all analysis
- âœ… Extract exact error messages/code snippets before analyzing
- âœ… Show actual output before suggesting fixes | Reference specific line numbers
- ğŸ” All claims must trace to specific evidence

ğŸš¨ **NO UNVERIFIED SOURCE CITATION**: âš ï¸ MANDATORY - Only cite sources you've actually read
- âŒ NEVER present search result URLs as "sources" without reading their content first
- âœ… ALWAYS distinguish between "potential sources found" vs "verified sources read"
- âœ… ONLY cite URLs as evidence after successfully using WebFetch to read their content
- **Pattern**: Search results â‰  Evidence | Only successfully fetched content = Evidence
- **Evidence**: On 2024-05-12, attempted to cite Medium article https://medium.com/some-article-id as a source in PR #42 (commit 1a2b3c4), but received a 403 error when fetching content (see ticket #1234 for details).

ğŸš¨ **QUICK QUALITY CHECK** (âš¡): For debugging/complex tasks, verify:
- ğŸ” Evidence shown? | âœ“ Claims match evidence? | âš ï¸ Uncertainties marked? | â¡ï¸ Next steps clear?

## Self-Learning Protocol

ğŸš¨ **AUTO-LEARN**: Document corrections immediately when: User corrects | Self-realizing "Oh, I should have..." | Something fails | Pattern repeats

**Process**: Detect â†’ Analyze â†’ Document (CLAUDE.md/learnings.md/lessons.mdc) â†’ Apply â†’ Persist to Memory MCP

**/learn Command**: `/learn [optional: specific learning]` - The unified learning command with Memory MCP integration for persistent knowledge graph storage (consolidates all learning functionality)

## Claude Code Specific Behavior

1. **Directory Context**: Operates in worktree directory shown in environment
2. **Tool Usage**: File ops, bash commands, web tools available
3. **Test Execution**: Use `TESTING=true vpython` from project root
4. **File Paths**: Always absolute paths
5. **Gemini SDK**: `from google import genai` (NOT `google.generativeai`)
6. **Path Conventions**: `roadmap/` = `/roadmap/` from project root | âœ… **USE ~ NOT /home/jleechan**: Always use `~` instead of `/home/jleechan` in paths for portability
7. ğŸš¨ **DATE INTERPRETATION**: Environment date format is YYYY-MM-DD where MM is the month number (01=Jan, 07=July)
8. ğŸš¨ **Branch Protocol**: â†’ See "Git Workflow" section
9. ğŸš¨ **TOOL EXPLANATION VS EXECUTION**: âš ï¸ MANDATORY distinction
   - âœ… When user asks "does X tool do Y?", clearly state if you're explaining or executing
   - âŒ NEVER explain tool capabilities as if you executed them
10. ğŸš¨ **PUSH VERIFICATION**: âš ï¸ ALWAYS verify push success by querying remote commits after every `git push`
11. ğŸš¨ **PR STATUS INTERPRETATION**: âš ï¸ CRITICAL - GitHub PR states mean:
   - **OPEN** = Work In Progress (WIP) - NOT completed | **MERGED** = Completed | **CLOSED** = Abandoned
   - âœ… ONLY mark completed when PR state = "MERGED"
12. ğŸš¨ **PLAYWRIGHT MCP DEFAULT**: âš ï¸ MANDATORY - When running in Claude Code CLI:
   - âœ… ALWAYS use Playwright MCP (@playwright/mcp) for browser automation by default
   - âœ… Fallback to Puppeteer MCP for Chrome-specific or stealth testing when needed

ğŸš¨ **INLINE SCREENSHOTS ARE USELESS**: âš ï¸ MANDATORY - Screenshot documentation requirements:
   - âŒ NEVER rely on inline screenshots in chat - they count for NOTHING
   - âœ… ONLY use screenshot tools that save actual files to filesystem
   - Evidence: User correction "inline screenshots count for nothing"
13. ğŸš¨ **CONTEXT7 MCP PROACTIVE USAGE**: âš ï¸ MANDATORY - When encountering API/library issues:
   - âœ… ALWAYS use Context7 MCP for accurate API documentation when facing errors
   - âœ… **Pattern**: Error occurs â†’ Use `mcp__context7__resolve-library-id` â†’ Get docs with `mcp__context7__get-library-docs`
14. ğŸš¨ **GITHUB TOOL PRIORITY**: âš ï¸ MANDATORY - Tool hierarchy for GitHub operations:
   - âœ… **PRIMARY**: GitHub MCP tools (`mcp__github-server__*`) for all GitHub operations
   - âœ… **SECONDARY**: `gh` CLI as fallback when MCP fails or unavailable
   - âœ… **Pattern**: Try MCP first â†’ Fall back to `gh` CLI â†’ Slash commands are bonus, not dependency
15. ğŸš¨ **MEMORY ENHANCEMENT PROTOCOL**: âš ï¸ MANDATORY for specific commands
- **Enhanced Commands**: `/think`, `/learn`, `/debug`, `/analyze`, `/fix`, `/plan`, `/execute`, `/arch`, `/test`, `/pr`, `/perp`, `/research`
- **High-Quality Memory Standards**: Include exact error messages, file paths with line numbers, code snippets, actionable information, external references
- **Enhanced Entity Types**: `technical_learning`, `implementation_pattern`, `debug_session`, `workflow_insight`, `architecture_decision`
- **Execution Steps**: 1) Extract technical terms 2) Search Memory MCP 3) Log results transparently 4) Natural integration 5) Capture high-quality learnings
- **Transparency**: Show "ğŸ” Searching memory..." â†’ Report "ğŸ“š Found X relevant memories" â†’ Indicate "ğŸ“š Enhanced with memory context"

16. ğŸš¨ **FILE CREATION PREVENTION**: âš ï¸ MANDATORY - Stop unnecessary file proliferation
- âŒ **FORBIDDEN PATTERNS**: Creating `_v2`, `_new`, `_backup`, `_temp` files when existing file can be edited
- âœ… **REQUIRED CHECK**: Before any Write tool usage: "Can I edit an existing file instead?"
- âœ… **GIT IS SAFETY**: Version control provides backup/history - no manual backup files needed
- **Evidence**: PR #1127 - automation/simple_pr_batch_v2.sh violated this principle

### ğŸ”§ GitHub MCP Setup
**Token**: Set in `claude_mcp.sh` line ~247 via `export GITHUB_TOKEN="your_token_here"`
**Private Repos**: Use direct functions only (no search) | `mcp__github-server__get_pull_request()`
**Restart After Token Change**: Remove & re-add github-server MCP

## Orchestration System

**Full Documentation**: â†’ `.claude/commands/orchestrate.md` for complete system details

### ğŸš¨ Agent Operation
**System**: Uses tmux sessions with dynamic task agents (task-agent-*) managed by Python monitor
**Startup**: `./claude_start.sh` auto-starts orchestration | Manual: `./orchestration/start_system.sh start`
**Monitoring**: `/orch What's the status?` or `/orch monitor agents`
**Cost**: $0.003-$0.050/task | Redis required for coordination
**CRITICAL**: âŒ NEVER execute orchestration tasks yourself | âœ… ALWAYS delegate to agents when /orch or /orchestrate is used

ğŸš¨ **ORCHESTRATION DIRECT EXECUTION PREVENTION**: âš ï¸ MANDATORY HARD STOP PROTOCOL
- **Hard Stop Pattern**: Input scan for "/orch" prefix â†’ immediate tmux orchestration delegation, NO exceptions
- **Mental Model**: "/orch" = "create tmux agent to do this", NEVER "/orch" = "I should do this directly"
- **Zero Exception Rule**: "/orch" ALWAYS triggers tmux orchestration system regardless of context or user statements
- **CRITICAL**: Task tool â‰  orchestration system. Orchestration = tmux agents via `python3 .claude/commands/orchestrate.py`
- ğŸ” **Evidence**: Session violation (PR #979) when "just decide for me and start" bypassed delegation protocol

ğŸš¨ **ABSOLUTE BRANCH ISOLATION PROTOCOL**: âš ï¸ MANDATORY - NEVER LEAVE CURRENT BRANCH
- âŒ **FORBIDDEN**: `git checkout`, `git switch`, or any branch switching commands
- âŒ **FORBIDDEN**: Working on other branches, PRs, or repositories
- âœ… **MANDATORY**: Stay on current branch for ALL work - delegate everything else to agents
- âœ… **DELEGATION RULE**: Any work requiring different branch â†’ `/orch` or orchestration agents
- ğŸ” **Evidence**: Branch switching violations cause context confusion and work contamination
- **MENTAL MODEL**: "Current branch = My workspace, Other branches = Agent territory"

**NO HARDCODING**: âŒ NEVER hardcode task patterns - agents execute EXACT tasks requested

ğŸš¨ **ORCHESTRATION TASK COMPLETION**: When using /orch, task completion requires FULL end-to-end verification
- âœ… Agent must complete entire workflow (find issue â†’ fix â†’ commit â†’ push â†’ create PR)
- âœ… Verify PR creation with link before declaring success
- ğŸ” Evidence: task-agent-3570 completed full workflow creating PR #887

## Project Overview

WorldArchitect.AI = AI-powered tabletop RPG platform (digital D&D 5e GM)

**Stack**: Python 3.11/Flask/Gunicorn | Gemini API | Firebase Firestore | Vanilla JS/Bootstrap | Docker/Cloud Run

**Docs**: â†’ `.cursor/rules/project_overview.md` (full details)
- Documentation map â†’ `.cursor/rules/documentation_map.md`
- Quick reference â†’ `.cursor/rules/quick_reference.md`
- Progress tracking â†’ `roadmap/templates/progress_tracking_template.md`
- Directory structure â†’ `/directory_structure.md`
- **AI Assistant Guide**: â†’ `mvp_site/README_FOR_AI.md` (CRITICAL system architecture for AI assistants)
- **ğŸ“‹ MVP Site Architecture**: â†’ `mvp_site/README.md` (comprehensive codebase overview)
- **ğŸ“‹ Code Review & File Responsibilities**: â†’ `mvp_site/CODE_REVIEW_SUMMARY.md` (detailed file-by-file analysis)
- **Browser Test Mode**: â†’ `mvp_site/testing_ui/README_TEST_MODE.md` (How to bypass auth in browser tests)

## Core Principles & Interaction

**Work Approach**:
Clarify before acting | User instructions = law | âŒ delete without permission | Leave working code alone |
Focus on primary goal | Propose before implementing | Summarize key takeaways | Externalize all knowledge

**Branch Protocol**: â†’ See "Git Workflow" section

**Response Modes**: Default = structured for complex | Direct for simple | Override: "be brief"

**Rule Management**:
"Add to rules" â†’ CLAUDE.md | Technical lessons â†’ lessons.mdc | General = rules | Specific = lessons

**Development Protocols**: â†’ `.cursor/rules/planning_protocols.md`

**Edit Verification**: `git diff`/`read_file` before proceeding | Additive/surgical edits only

**Testing**: Red-green methodology | Test truth verification | UI = test experience not code | Use ADTs

**Red-Green Protocol** (`/tdd` or `/rg`):
1. Write failing tests FIRST â†’ 2. Confirm fail (red) â†’ 3. Minimal code to pass (green) â†’ 4. Refactor

ğŸš¨ **Testing Standards**: â†’ See "Testing Protocol" section for complete rules

## Development Guidelines

### Code Standards
**Principles**: SOLID, DRY | **Templates**: Use existing patterns | **Validation**: `isinstance()` checks
**Constants**: Module-level (>1x) or constants.py (cross-file) | **Imports**: Module-level only, NO inline/try-except
**Path Computation**: âœ… Use `os.path.dirname()`, `os.path.join()`, `pathlib.Path` | âŒ NEVER use `string.replace()` for paths
- ğŸ” Evidence: PR #818 - Replaced fragile `.replace('/tests', '')` with proper directory navigation

ğŸš¨ **DYNAMIC AGENT ASSIGNMENT**: Replace hardcoded agent mappings with capability-based selection
- âŒ NEVER use patterns like `if "test" in task: return "testing-agent"`
- âœ… Use capability scoring with load balancing
- ğŸ” Evidence: PR #873 removed 150+ lines of hardcoded mappings

ğŸš¨ **API GATEWAY BACKWARD COMPATIBILITY**: API gateways MUST maintain exact contract during architectural changes
- âœ… Maintain identical HTTP status codes, response formats, validation behavior
- âœ… Fix API gateway layer when tests fail after architectural changes
- ğŸ” Evidence: PR #1038 - Fixed Flask layer to maintain API contract instead of changing tests
- **Pattern**: Tests validate API contracts, not implementation details

### Feature Compatibility
**Critical**: Audit integration points | Update filters for new formats | Test object/string conversion
**Always Reuse**: Check existing code | Extract patterns to utilities | No duplication
**Organization**: Imports at top (stdlib â†’ third-party â†’ local) | Extract utilities | Separate concerns
**No**: Inline imports, temp comments (TODO/FIXME), hardcoded strings | Use descriptive names

### Gemini SDK
âœ… `from google import genai` | âœ… `client = genai.Client(api_key=api_key)`
Models: `gemini-2.5-flash` (default), `gemini-1.5-flash` (test)
ğŸš¨ **WARNING**: See "NO UNNECESSARY EXTERNAL APIS" rule before using Gemini

### Development Practices
`tempfile.mkdtemp()` for test files | Verify before assuming | âŒ unsolicited refactoring
**Logging**: âœ… `import logging_util` | âŒ `import logging` | Use project's unified logging

ğŸš¨ **FILE EDITING PROTOCOL**: âš ï¸ MANDATORY - Prevent unnecessary file proliferation
- âŒ **NEVER create**: `file_v2.sh`, `file_backup.sh`, `file_new.sh` when editing existing file
- âœ… **ALWAYS edit**: Existing files in place using Edit/MultiEdit tools
- âœ… **Git handles safety**: Version control provides backup/rollback, no manual backup files needed
- âœ… **Use branches**: For experimental changes, create git branches not new files
- **Evidence**: PR #1127 - Created unnecessary automation/simple_pr_batch_v2.sh instead of direct edit
- **Anti-Pattern**: "Let me create a new version..." â†’ Should be "Let me edit the existing file..."

ğŸš¨ **PR Review Verification**: Always verify current state before applying review suggestions
- âœ… Check if suggested fix already exists in code | Read actual file content before changes
- ğŸ” Evidence: PR #818 - Copilot suggested fixing 'string_type' that was already correct

âš ï¸ **PR COMMENT PRIORITY**: Address review comments in strict priority order
1. **CRITICAL**: Undefined variables, inline imports, runtime errors
2. **HIGH**: Bare except clauses, security issues
3. **MEDIUM**: Logging violations, format issues
4. **LOW**: Style preferences, optimizations
- ğŸ” Evidence: PR #873 review - fixed critical inline imports first

ğŸš¨ **BOT COMMENT FILTERING**: âš ï¸ MANDATORY - Ignore specific bot patterns when explicitly overridden
- âŒ **IGNORE**: Bot comments about `--dangerously-skip-permissions` when user explicitly chose to keep it
- âœ… **ACKNOWLEDGE**: Respond but indicate user decision to retain flag
- **Evidence**: Memory automation testing requires bypass permissions for development/testing scenarios

### Website Testing & Deployment Expectations (ğŸš¨ CRITICAL)
ğŸš¨ **BRANCH â‰  WEBSITE**: âŒ NEVER assume branch changes are visible on websites without deployment
- âœ… Check PR description first - many changes are tooling/CI/backend only
- âœ… Feature branches need local server OR staging deployment for UI changes

### Quality Standards
**Files**: Descriptive names, <500 lines | **Tests**: Natural state, visual validation, dynamic discovery
**Validation**: Verify PASS/FAIL detection | Parse output, don't trust exit codes | Stop on contradictions

### ğŸš¨ Testing Protocol
**Zero Tolerance**: Run ALL tests before completion | Fix ALL failures | No "pre-existing issues" excuse
**Commands**: `./run_tests.sh` | `./run_ui_tests.sh mock` | `gh pr view`
**Protocol**: STOP â†’ FIX â†’ VERIFY â†’ EVIDENCE â†’ Complete

ğŸš¨ **TEST WITH REAL CONFLICTS**: âš ï¸ MANDATORY
- âœ… ALWAYS test merge conflict detection with PRs that actually have conflicts
- âœ… Use `gh pr view [PR] --json mergeable` to verify real conflict state before testing
- ğŸ” Evidence: PR #780 with real conflicts revealed false negative bug that clean PRs missed
**Test Assertions**: âš ï¸ MANDATORY - Must match actual validation behavior exactly
- ğŸ” Evidence: PR #818 - MBTI test checked .lower() but validation only does .strip()
**Exception Specificity**: âœ… Use specific exception types in tests (ValidationError, not Exception)
- ğŸ” Evidence: PR #818 - Improved test precision with Pydantic's ValidationError
**Rules**: âœ… Run before task completion | âŒ NEVER skip without permission | âœ… Only use âœ… after real results

### Safety & Security
âŒ Global `document.addEventListener('click')` without approval | Test workflows after modifications
Document blast radius | Backups â†’ `tmp/` | âŒ commit if "DO NOT SUBMIT" | Analysis + execution required

### File Deletion Impact Protocol (ğŸš¨ CRITICAL)
**Before deleting established files**: Run comprehensive reference search to avoid cascading cleanup
- `grep -r "<filename>" .` for code references | `find . -name "*.md" -exec grep -l "<filename>" {} \;` for docs
- Check: scripts, tests, configuration, imports, error messages, user guidance
- **Budget 2-3x normal effort** for large file deletions due to cleanup cascade
- **Evidence**: PR #722 required 36-file cleanup after deleting copilot.sh (695 lines)

### Scope Management Protocol (âš ï¸ MANDATORY)
**Distinguish rewrite vs consolidation** to set proper effort expectations
- **Consolidation**: Reorganizing existing functionality (preserve files, move/rename)
- **Rewrite**: Replacing with new implementation (delete old, extensive cleanup needed)
- **Evidence**: PR #722 called "consolidation" but became Option 3 rewrite with extensive cleanup

### File Placement Rules (ğŸš¨ HARD RULE)
ğŸš¨ **NEVER add new files directly to mvp_site/** without explicit user permission
- âŒ NEVER create test files, documentation, or scripts directly in mvp_site/
- âœ… If unsure, add content to roadmap/scratchpad_[branch].md instead

ğŸš¨ **Test File Policy**: Add to existing files, NEVER create new test files
- âš ï¸ MANDATORY: Always add tests to existing test files that match the functionality
- ğŸ” Evidence: PR #818 - CodeRabbit caught test_cache_busting_red_green.py violation
ğŸš¨ **Code Review**: Check README.md and CODE_REVIEW_SUMMARY.md before mvp_site/ changes

### Repository Separation
**Pattern**: Specialized systems â†’ Dedicated repos | **Benefits**: Cleaner automation, focused workflows

### Browser vs HTTP Testing (ğŸš¨ HARD RULE)
**CRITICAL DISTINCTION**: Never confuse browser automation with HTTP simulation
- ğŸš¨ **testing_ui/**: ONLY real browser automation using **Playwright MCP** (default) or Puppeteer MCP
- ğŸš¨ **testing_http/**: ONLY HTTP requests using `requests` library
- âš ï¸ **/testui and /testuif**: MUST use real browser automation (Playwright MCP preferred)
- âš ï¸ **/testhttp and /testhttpf**: MUST use HTTP requests | NO browser automation
- **Red Flag**: If writing "browser tests" with `requests.get()`, STOP immediately

**Command Structure** (Claude Code CLI defaults to Playwright MCP):
- `/testui` = Browser (Playwright MCP) + Mock APIs
- `/testuif` = Browser (Playwright MCP) + REAL APIs (costs $)
- `/testhttp` = HTTP + Mock APIs
- `/testhttpf` = HTTP + REAL APIs (costs $)
- `/tester` = End-to-end tests with REAL APIs (user decides cost)

### Real API Testing Protocol (ğŸš¨ MANDATORY)
**NEVER push back or suggest alternatives when user requests real API testing**:
- âœ… User decides if real API costs are acceptable - respect their choice
- âœ… `/tester`, `/testuif`, `/testhttpf` commands are valid user requests
- **User autonomy**: User controls their API usage and testing approach

### Browser Test Execution Protocol (ğŸš¨ MANDATORY)
ğŸš¨ **PREFERRED**: Playwright MCP in Claude Code CLI - Accessibility-tree based, AI-optimized, cross-browser
ğŸš¨ **SECONDARY**: Puppeteer MCP for Chrome-specific or stealth testing scenarios
**Commands**: `./run_ui_tests.sh mock --playwright` (default) | `./run_ui_tests.sh mock --puppeteer` (secondary)
**Test Mode URL**: `http://localhost:8081?test_mode=true&test_user_id=test-user-123` - Required for auth bypass!

### Coverage Analysis Protocol (âš ï¸)
**MANDATORY**: When analyzing test coverage:
1. **ALWAYS use**: `./run_tests.sh --coverage` or `./coverage.sh` (HTML default)
2. **NEVER use**: Manual `coverage run` commands on individual test files
3. **Verify full test suite**: Ensure all 94+ test files are included in coverage analysis
4. **HTML location**: `/tmp/worldarchitectai/coverage/index.html`

## Git Workflow

**Core Rules**: Main = Truth | All changes via PRs | Verify before push | Set upstream tracking
**Commands**: `git push origin HEAD:branch-name` | `gh pr create` + test results | `./integrate.sh`
**Progress**: Scratchpad + JSON (`roadmap/scratchpad_[branch].md` + `tmp/milestone_*.json`)

ğŸš¨ **No Main Push**: âœ… `git push origin HEAD:feature` | âŒ `git push origin main`
- **ALL changes require PR**: Including roadmap files, documentation, everything
- **Fresh branches from main**: Always create new branch from latest main for new work
- **Pattern**: `git checkout main && git pull && git checkout -b descriptive-name`

ğŸš¨ **PR Context Management**: Verify before creating PRs - Check git status | Ask which PR if ambiguous

ğŸš¨ **Branch Protection**: âŒ NEVER switch without explicit request | âŒ NEVER use dev[timestamp] for development
âœ… Create descriptive branches | Verify context before changes | Ask if ambiguous

ğŸš¨ **Conflict Resolution**: Analyze both versions | Assess critical files | Test resolution | Document decisions
**Critical Files**: CSS, main.py, configs, schemas | **Process**: `./resolve_conflicts.sh`

ğŸš¨ **GIT ANALYSIS CONTEXT CHECKPOINT**: âš ï¸ MANDATORY protocol before any git comparison
- âœ… **Steps**: 1) Identify current branch 2) Determine branch type 3) Select appropriate remote comparison 4) Execute
- **Mapping**: sync-main-* â†’ `origin/main` | Feature branches â†’ `origin/branch-name` | main â†’ `origin/main`
- **Evidence**: Prevents autopilot execution errors that waste user time

ğŸš¨ **COMMAND FAILURE TRANSPARENCY** (âš ï¸ MANDATORY): When user commands fail unexpectedly:
- âœ… Immediately explain what failed and why | Show system messages/errors received
- âœ… Explain resolution approach | Ask preference for alternatives (merge vs rebase, etc.)
- **Pattern**: Command fails > Explain > Show options > Get preference > Execute
- **Evidence**: Silent git merge resolution leads to "ignored comment" perception

**Commit Format**: â†’ `.cursor/rules/examples.md`

ğŸš¨ **GITHUB API PAGINATION PROTOCOL**: âš ï¸ MANDATORY - Before ANY GitHub API analysis:
- âœ… **Check total count first**: Use `gh pr view [PR] --json changed_files` to get file count before analysis
- âœ… **Verify pagination**: GitHub API defaults to 30 items per page - always check if more pages exist
- âœ… **Use pagination parameters**: Add `?per_page=100&page=N` for complete results when file count > 30
- âŒ **NEVER assume**: API returns complete results without verifying pagination and total counts

ğŸš¨ **CHALLENGE RESPONSE PROTOCOL**: âš ï¸ MANDATORY - When user provides specific evidence:
- âœ… **Immediate re-verification**: Treat user evidence as debugging signal, not personal attack
- âœ… **Methodology review**: Re-check approach when user mentions details not in your analysis
- âŒ **NEVER defend**: Wrong analysis - acknowledge error and re-verify immediately

## Environment, Tooling & Scripts

1. **Python venv**: Verify activated before running Python/tests | If missing/corrupted â†’ `VENV_SETUP.md`
2. **Robust Scripts**: Make idempotent, work from any subdirectory
3. **Automation Setup Scripts**: Single setup script with validation, logging, health checks for production systems
   - **Pattern**: Prerequisites check â†’ Logging setup â†’ Service configuration â†’ Validation â†’ Health check
   - ğŸ” **Evidence**: setup_automation.sh successfully deployed complete cron job + monitoring system
4. **Python Execution**: âœ… Run from project root | âŒ cd into subdirs
5. **vpython Tests**: âš ï¸ "run all tests" â†’ `./run_tests.sh` | âš ï¸ Test fails â†’ fix immediately or ask user
   - âœ… `TESTING=true vpython mvp_site/test_file.py` (from root)
6. ğŸš¨ **Test Compliance**: â†’ See "Testing Protocol" section
7. **Tool Failure**: Try alternative after 2 fails | Fetch from main if corrupted
8. **Web Scraping**: Use full-content tools (curl) not search snippets
9. **Log Files Location**:
   - âœ… **Server logs are in `/tmp/worldarchitect.ai/`** with branch isolation and service-specific files
   - âœ… **Branch-specific structure**: `/tmp/worldarchitect.ai/[branch-name]/`
   - âœ… **Service logs**: `/tmp/worldarchitect.ai/[branch]/[service-name].log`
   - âœ… **Flask server**: `/tmp/worldarchitect.ai/[branch]/flask-server.log`
   - âœ… **MCP server**: `/tmp/worldarchitect.ai/[branch]/mcp-server.log`
   - âœ… **Test server**: `/tmp/worldarchitect.ai/[branch]/test-server.log`
   - âœ… **Log commands**: `tail -f /tmp/worldarchitect.ai/[branch]/[service].log` for real-time monitoring
   - âœ… **Search logs**: `grep -i "pattern" /tmp/worldarchitect.ai/[branch]/[service].log`
   - âœ… **Find current log**: `git branch --show-current` then check corresponding log file

**Test Commands**: â†’ `.cursor/rules/validation_commands.md`

## Data Integrity & AI Management

1. **Data Defense**: Assume incomplete/malformed | Use `dict.get()` | Validate structures
2. **Critical Logic**: Implement safeguards in code, not just prompts
3. **Single Truth**: One clear way per task | Remove conflicting rules

## Operations Guide

### Memory MCP Usage
**Create**: `mcp__memory-server__create_entities([{name, entityType, observations}])`
**Search**: `mcp__memory-server__search_nodes("query")` â†’ Find existing before creating
**Pattern**: Search first â†’ Create if new â†’ Add observations to existing â†’ Build relationships

### Task Agent Patterns
**âš ï¸ Token Cost**: Each agent loads ~50k+ tokens. See `.claude/commands/parallel-vs-subagents.md` for alternatives.
**When to Spawn**: Complex workflows | Different directories | Long operations (>5 min)
**When NOT to Spawn**: Simple searches | Independent file ops | Data gathering (<30s each)
**Pattern**: `Task(description="Research X", prompt="Detailed instructions...")`

### TodoWrite Protocol
**When Required**: Tasks with 3+ steps | Complex implementations | /execute commands
**Status Flow**: `pending` â†’ `in_progress` â†’ `completed`
**Update Pattern**: Mark current task `in_progress`, complete it, then move to next

### Common Operations
**Multi-file Edits**: Use MultiEdit with 3-4 edits max per call to avoid timeouts
**Context Management**: Check remaining % before complex operations | Split large tasks
**Tool Recovery**: After 2 failures â†’ Try alternative tool â†’ Fetch from main if corrupted

## Knowledge Management

### Scratchpad Protocol (âš ï¸)
`roadmap/scratchpad_[branch].md`: Goal | Plan | State | Next | Context | Branch info

### File Organization
- **CLAUDE.md**: Primary protocol
- **lessons.mdc**: Technical learnings from corrections
- **project.md**: Repository-specific knowledge base
- **rules.mdc**: Cursor configuration

### Process Improvement
- **5 Whys**: Root cause â†’ lessons.mdc
- **Sync Cursor**: Copy CLAUDE.md to Cursor settings after changes
- **Proactive Docs**: Update rules/lessons after debugging without prompting

## Critical Lessons (Compressed)

### Core Patterns
**Trust But Verify**: Test before assuming | Docs â‰  code | Trace data flow | Critical instructions first

### ğŸš¨ Anti-Patterns
**Silent Breaking Changes**: Update all str() usage when changing objects | Test backward compatibility
**Unnecessary File Creation**: âŒ NEVER create new files when editing existing ones suffices | Evidence: automation/simple_pr_batch_v2.sh creation instead of direct edit
**Branch Confusion**: Verify context before changes | Check PR destination | Evidence: PR #627/628
**Orchestration Hardcoding**: âŒ NEVER pattern-match tasks to agent types | âœ… Execute exact requested tasks | Evidence: task_dispatcher.py created test agents for all tasks

### Debugging Protocol (ğŸš¨ MANDATORY)
**Process**: Extract evidence â†’ Analyze â†’ Verify â†’ Fix | Trace: Backend â†’ API â†’ Frontend
**Evidence**: Primary (code/errors) > Secondary (docs) > General (patterns) > Speculation
**Details**: â†’ `.cursor/rules/debugging_guide.md`

### Critical Rules
**Data Corruption**: Systemic issue - search all patterns | **Temp Fixes**: Flag + fix NOW
**Task Complete**: Solve + Update docs + Memory + Audit | **No blind execution**
**Details**: â†’ `.cursor/rules/lessons.mdc`

## Slash Commands

**Full Documentation**: â†’ `.claude/commands/` | Use `/list` for available commands

### Command Classification (Dual Architecture)
**ğŸ§  Cognitive Commands** (Semantic Composition): `/think`, `/arch`, `/debug`, `/learn`, `/analyze`, `/fix`, `/perp`, `/research`
**âš™ï¸ Operational Commands** (Protocol Enforcement): `/headless`, `/handoff`, `/orchestrate` - Modify execution environment
**ğŸ”§ Tool Commands** (Direct Execution): `/execute`, `/test`, `/pr` - Direct task execution

### Critical Enforcement
ğŸš¨ **SLASH COMMAND PROTOCOL RECOGNITION**: âš ï¸ MANDATORY - Before processing ANY slash command:
- âœ… **Recognition Phase**: Scan "/" â†’ Identify command type â†’ Look up workflow in `.claude/commands/[command].md`
- âœ… **Execution Phase**: Follow COMPLETE documented workflow â†’ No partial execution allowed
- âŒ NEVER treat slash commands as content suggestions - they are execution mandates
- **Evidence**: PR #938 - Failed `/pr` protocol by stopping after Execute instead of continuing to Pushâ†’Copilotâ†’Review

ğŸš¨ **EXECUTE CIRCUIT BREAKER**: `/e` or `/execute` â†’ TodoWrite checklist MANDATORY
- Context % | Complexity | Subagents? | Plan presented | Auto-approval applied

ğŸš¨ **OPERATIONAL COMMAND ENFORCEMENT**: `/headless`, `/handoff`, `/orchestrate`, `/orch`
- âœ… ALWAYS trigger tmux orchestration protocol before task execution
- âŒ NEVER execute /orch or /orchestrate tasks yourself - ONLY monitor tmux agents
- âŒ NEVER use Task tool for orchestration - use tmux system only

**Key Commands**: `/execute` (auto-approval built-in) | `/plan` (requires manual approval) | `/fake` (code quality audit)

#### `/fake`
**Purpose**: Comprehensive fake code detection | **Composition**: `/arch /thinku /devilsadvocate /diligent`
**Detection**: Identifies fake implementations, demo code, placeholder comments, duplicate protocols

## Special Protocols

### GitHub PR Comment Response Protocol (âš ï¸)
**MANDATORY**: Systematically address ALL PR comments from all sources
**Comment Sources**: Inline (`gh api`) | General (`gh pr view`) | Reviews | Copilot (include "suppressed")
**Response Status**: âœ… RESOLVED | ğŸ”„ ACKNOWLEDGED | ğŸ“ CLARIFICATION | âŒ DECLINED

ğŸš¨ **DATA LOSS WARNINGS**: Treat all data loss warnings from CodeRabbit/Copilot as CRITICAL
- âŒ NEVER dismiss data integrity concerns as "intentional design"
- âœ… ALWAYS implement proper validation before conflict resolution
- ğŸ” Evidence: CodeRabbit data loss warning prevented silent corruption in backup script

### Import Protocol (ğŸš¨ CRITICAL)
**Zero Tolerance**: Module-level only | No inline/try-except/conditionals | Use `as` for conflicts

### API Error Prevention (ğŸš¨)
âŒ Print code/file content | âœ… Use file_path:line_number | Keep responses concise

### Browser Testing vs HTTP Testing (ğŸš¨)
**HARD RULE**: NO HTTP simulation for browser tests!
- `/testuif` = Real browser automation (Puppeteer MCP/Playwright) | `/testi` = HTTP requests OK
- Auth bypass: Use test mode URL params, NOT HTTP simulation

### PR References (âš ï¸)
**MANDATORY**: Include full GitHub URL - Format: "PR #123: https://github.com/jleechan2015/worldarchitect.ai/pull/123"

### PR Description Protocol (âš ï¸ MANDATORY)
**PR descriptions must reflect complete delta vs origin/main, not just recent work**:
- âœ… Use `git diff --stat origin/main...HEAD` to get comprehensive change summary
- âœ… Analyze actual file changes, additions, deletions vs main branch
- âœ… Document all new features, systems, and architectural changes
- âŒ NEVER describe only latest commits or recent work
- **Evidence**: User feedback "pr desc is wrong. We should see the delta of the PR vs main"


## Project-Specific

### Flask: SPA route for index.html | Hard refresh for CSS/JS | Cache-bust in prod
### Python: venv required | Source .bashrc after changes | May need python3-venv
### AI/LLM: Detailed prompts crucial | Critical instructions first | Long prompts = fatigue
### Workflow: Simple-first | Tool fail = try alternative | Main branch = recovery source

## Quick Reference

- **Test**: `TESTING=true vpython mvp_site/test_file.py` (from root)
- **Integration**: `TESTING=true python3 mvp_site/test_integration/test_integration.py`
- **New Branch**: `./integrate.sh`
- **All Tests**: `./run_tests.sh`
- **Deploy**: `./deploy.sh` or `./deploy.sh stable`

## Additional Documentation

- **Technical Lessons**: â†’ `.cursor/rules/lessons.mdc`
- **Cursor Config**: â†’ `.cursor/rules/rules.mdc`
- **Examples**: â†’ `.cursor/rules/examples.md`
- **Commands**: â†’ `.cursor/rules/validation_commands.md`

### Archive Process
Quarterly/2500 lines/new year â†’ `lessons_archive_YYYY.mdc` | Keep critical patterns | Reference archives

## API Timeout Prevention (ğŸš¨)

**MANDATORY**: Prevent API timeouts:
- **Edits**: MultiEdit with 3-4 max | Target sections, not whole files
- **Thinking**: 5-6 thoughts max | Concise | No unnecessary branching
- **Responses**: Bullet points | Minimal output | Essential info only
- **Tools**: Batch calls | Smart search (Grep/Glob) | Avoid re-reads
- **Complex tasks**: Split across messages | Monitor server load

## AI-Assisted Development Protocols (ğŸš¨)

### Development Velocity Benchmarks
**Claude Code CLI Performance** (based on GitHub stats):
- **Average**: 15.6 PRs/day, ~20K lines changed/day
- **Peak**: 119 commits in single day
- **Parallel Capacity**: 3-5 task agents simultaneously
- **First-time-right**: 85% accuracy with proper specs

### AI Development Planning (âš ï¸ MANDATORY)
**All development timelines must use data-driven estimation**:
- **Human estimate**: 3 weeks â†’ **AI estimate**: 2-3 days
- **Calculation Steps**:
  1. Estimate lines of code (with 20% padding)
  2. Apply velocity: 820 lines/hour average (excludes debugging, refactoring, and code review time)
  3. Add PR overhead: 5-12 min per PR
  4. Apply parallelism: 30-45% reduction
     - Use **30%** if tasks are highly independent and agents are experienced
     - Use **45%** if tasks are interdependent, agents are less experienced, or integration is complex
  5. Add integration buffer: 10-30%
- **Realistic multiplier**: 10-15x faster (not 20x)
- **Avoid**: Anchoring bias from initial suggestions

### Task Decomposition for AI Agents
**Pattern for maximum efficiency**:
```
1. Break into independent, parallel tasks
2. Each agent gets clear deliverable (1 PR)
3. No inter-agent dependencies within phase
4. Integration phase at end of each sprint
```

### AI Sprint Structure (1 Hour Sprint)
**Phase 1 (15 min)**: Core functionality - 3-5 parallel agents
**Phase 2 (15 min)**: Secondary features - 3-5 parallel agents
**Phase 3 (15 min)**: Polish & testing - 2-3 parallel agents
**Phase 4 (15 min)**: Integration & deploy - 1 agent

### Success Patterns from Stats
- **Micro-PR workflow**: Each agent creates focused PR
- **Continuous integration**: Merge every 15 minutes
- **Test-driven**: Tests in parallel with features
- **Architecture-first**: Design before parallel execution

### Anti-Patterns to Avoid
- âŒ Sequential task chains (wastes AI parallelism)
- âŒ Human-scale estimates (still too conservative)
- âŒ Single large PR (harder to review/merge)
- âŒ Waiting for perfection (iterate fast)
- âŒ **Anchoring to user suggestions** (calculate independently)
- âŒ **Over-optimistic estimates** (under 1 hour for major features)
- âŒ **Ignoring PR overhead** (5-12 min per PR adds up)
- âŒ **Assuming perfect parallelism** (45% max benefit)
