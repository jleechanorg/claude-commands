# Meta-Rules Detailed Documentation

Detailed explanations and evidence for core meta-rules referenced in CLAUDE.md.

## NO FAKE IMPLEMENTATIONS (üö® MANDATORY)

**CRITICAL ANTI-PATTERN**: Always audit existing functionality before implementing new code

### Specific Violations to Avoid:
- ‚ùå NEVER create files with "# Note: In the real implementation" comments
- ‚ùå NEVER write placeholder code that doesn't actually work  
- ‚ùå NEVER create demonstration files instead of working implementations
- ‚ùå NEVER create Python intelligence files when .md files handle the logic
- ‚ùå NEVER duplicate systematic protocols that already exist in other .md files
- ‚ùå NEVER reimplement existing command functionality (use orchestration instead)

### Required Practices:
- ‚úÖ ALWAYS audit existing commands and .md files before writing new implementations
- ‚úÖ ALWAYS build real, functional code that works immediately
- ‚úÖ ALWAYS enhance existing systems rather than creating fake parallel ones
- ‚úÖ ALWAYS check if functionality exists: Read existing commands, Grep for patterns

### Evidence and Examples:
- **Pattern**: Real implementation > No implementation > Fake implementation
- **Evidence**: PR #820 - 563+ lines of fake code removed (fixpr.py, commentreply.py, copilot.md duplication)
- **Evidence**: orchestrate_enhanced.py with placeholder comments frustrated user
- **Rule**: If you can't implement it properly, don't create the file at all

## ORCHESTRATION OVER DUPLICATION (üö® MANDATORY)

### Core Principle:
Orchestrators delegate to existing commands, never reimplement their functionality

### Implementation Pattern:
- ‚úÖ Pattern: New commands should be orchestrators, not implementers
- ‚úÖ Use existing /commentreply, /pushl, /fixpr rather than duplicating their logic
- ‚úÖ Add command summary at top of orchestrator .md files to prevent confusion
- ‚ùå NEVER copy systematic protocols from other .md files into new commands
- ‚ùå NEVER duplicate GitHub API commands that already exist in other commands

### Evidence:
- **Evidence**: PR #812 (https://github.com/WorldArchitectAI/repo/pull/812) - 120 lines of duplicate systematic protocol removed from copilot.md
- **Architecture**: copilot = orchestrator, not implementer

## NO OVER-ENGINEERING

### Core Prevention Strategy:
Prevent building parallel inferior systems vs enhancing existing ones

### Key Questions to Ask:
- ‚úÖ ALWAYS ask "Can the LLM handle this naturally?" before building parsers/analytics systems
- ‚úÖ ALWAYS try enhancing existing systems before building parallel new ones  
- ‚úÖ ALWAYS prioritize user workflow integration over technical sophistication

### Specific Prohibitions:
- ‚ùå NEVER build parallel command execution systems - enhance Claude Code CLI instead
- ‚ùå NEVER build complex parsing when LLM can understand intent naturally
- ‚ùå NEVER add analytics/tracking beyond core functionality needs

### Pattern and Evidence:
- **Pattern**: Trust LLM capabilities, enhance existing systems, prioritize immediate user value
- **Evidence**: Command composition over-engineering (PR #737) - a parallel command execution system was built instead of enhancing the existing Claude Code CLI. This led to unnecessary complexity, duplication of functionality, and reduced maintainability.
- **Evidence**: Orchestration parallel development (PR #790) - created .claude/commands/orchestrate.py instead of enhancing existing orchestration/ directory with Redis infrastructure. Fixed by migrating LLM features TO the mature system and deleting parallel implementation.
- **Root Causes**: LLM capability underestimation, perfectionist engineering, integration avoidance, demo-driven development, insufficient analysis of existing infrastructure

## NO UNNECESSARY EXTERNAL APIS

### Decision Process:
Before adding ANY external API integration:
- ‚úÖ FIRST ask "Can Claude solve this directly without external APIs?"
- ‚úÖ ALWAYS try direct implementation before adding dependencies
- ‚úÖ TEST the direct solution - if it works, STOP there
- ‚ùå NEVER default to Gemini API just because it exists in codebase
- ‚ùå NEVER add external LLM calls when Claude can generate responses directly

### Pattern Recognition:
- **Pattern**: Direct solution ‚Üí Justify external need ‚Üí Only then integrate
- **Anti-pattern**: See AI task ‚Üí Immediately reach for Gemini API
- **Evidence**: GitHub comment fiasco (PR #796) - built Gemini integration that degraded to useless generic templates when Claude could have generated responses directly

## GEMINI API JUSTIFICATION REQUIREMENTS

### Valid Use Cases Only:
Gemini should ONLY be used when:
- ‚úÖ The task requires capabilities Claude doesn't have (e.g., image generation)
- ‚úÖ The system needs to work autonomously without Claude present
- ‚úÖ Specific model features are required (e.g., specific Gemini models)
- ‚úÖ User explicitly requests Gemini integration

### Prohibited Uses:
- ‚ùå NEVER use Gemini just for text generation that Claude can do
- ‚ùå NEVER add complexity without clear unique value

### Key Question:
"What can Gemini do here that Claude cannot?"

## NEVER SIMULATE INTELLIGENCE

### Core Prohibition:
When building response generation systems:
- ‚ùå NEVER create Python functions that simulate Claude's responses with templates
- ‚ùå NEVER use pattern matching to generate "intelligent" responses  
- ‚ùå NEVER build `_create_contextual_response()` methods that fake understanding
- ‚ùå NEVER generate generic replies like "I'll fix the issue" or "Thanks for the suggestion"

### Required Approach:
- ‚úÖ ALWAYS invoke actual Claude for genuine response generation
- ‚úÖ ALWAYS pass full comment context to Claude for analysis
- ‚úÖ ALWAYS ensure responses address specific technical points, not patterns

### Pattern Recognition:
- **Pattern**: Collect data ‚Üí Claude analyzes ‚Üí Claude responds
- **Anti-pattern**: Collect data ‚Üí Python templates ‚Üí Fake responses
- **Violation Count**: 100+ times - STOP THIS PATTERN IMMEDIATELY

## USE LLM CAPABILITIES

### Natural Language Processing:
When designing command systems or natural language features:
- ‚ùå NEVER suggest keyword matching, regex patterns, or rule-based parsing
- ‚ùå NEVER propose "if word in text" simplistic approaches
- ‚úÖ ALWAYS leverage LLM's natural language understanding
- ‚úÖ ALWAYS trust the LLM to understand context, nuance, and intent

### Pattern Recognition:
- **Pattern**: User intent ‚Üí LLM understanding ‚Üí Natural response
- **Anti-pattern**: Keywords ‚Üí Rules ‚Üí Rigid behavior