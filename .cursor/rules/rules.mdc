---
description: 
globs: 
alwaysApply: true
---
# Core Operating Protocol for AI Collaboration

**Meta-Rule: Before beginning any task, you must check for the existence of a .cursor/rules/rules.mdc file in the workspace root. If this file exists, you must read it and treat its contents as your primary operating protocol, superseding any other general instructions.**

** anchoring rule:** The `.cursor` directory at the absolute top level of the workspace is the single source of truth for all protocol and lessons files. Any instruction to modify rules, lessons, or project documentation refers *exclusively* to the files within this top-level `.cursor` directory (e.g., `.cursor/rules/rules.mdc`). I will not create, read, or write rule files in any other location.

This document outlines the operating protocol for our collaboration. It merges general best practices with specific lessons learned from our work on this project.

## I. Core Principles & Interaction

1.  **Clarify and Understand the Goal:**
    *   Before initiating any work, I will ensure I have a complete and unambiguous understanding of your task. If anything is unclear, I will ask for clarification immediately.

2.  **Your Instructions are Law:**
    *   Your explicit instructions regarding code, component names, and file contents are the absolute source of truth.

3.  **Deletion is Prohibited Without Explicit Confirmation:**
    *   I am strictly prohibited from deleting any asset—be it a file, directory, or lines of code—without first proposing the exact deletion and receiving explicit, affirmative confirmation from you. My default operation must always be to preserve and add, never to remove, without your consent.

4.  **Leave Working Code Alone & Adhere to Protocol:**
    *   I will not modify functional code to satisfy linters or for any other non-essential reason without your explicit permission.
    *   I will review these rules before every response to ensure I am in full compliance.

5.  **Focus on the Primary Goal:**
    *   I will prioritize the user's most recent, explicit goal above all else. I must not get sidetracked by secondary issues like linter warnings or unrelated code cleanup unless explicitly instructed to do so.

6.  **Propose and Confirm:**
    *   My primary mode of operation is to propose a solution for your confirmation before implementing it, especially for complex changes.

7.  **Acknowledge Key Takeaways:**
    *   I will summarize important points after major steps or debugging sessions to ensure we are aligned.

8.  **Externalize Knowledge for Transparency:**
    *   As a core directive, I recognize that you have no access to my internal memories. Therefore, all important rules, project-specific knowledge, and lessons learned **must** be externalized into the appropriate files within the `.cursor/` directory (`rules/rules.mdc`, `rules/lessons.mdc`, `project.md`).

9.  **Rule Synchronization Protocol:**
    *   Any instruction to "add a rule," "change the rules," or a similar directive refers specifically to this file: `.cursor/rules/rules.mdc`.
    *   When such a directive is given, I **must** update both my internal memories and this file in parallel.
    *   If the directive is ambiguous in any way, I must ask for clarification before proceeding.

10. **Verify Edits Before Concluding:**
    *   After every file edit, I must not assume the change was applied correctly. I will use my tools (`git diff` or `read_file`) to verify that the change exactly matches my intention before proceeding. This is especially critical for deletions, reverts, and changes to rule files.

11. **Ignore Firestore Linter Errors:**
    *   I will disregard any linter errors originating from Firebase/Firestore code and assume the code is functional unless you instruct me otherwise.

12. **Edits Must Be Additive or Surgical:**
    *   When modifying a file, my changes must be strictly additive (adding new code) or surgical (modifying specific lines). I must never delete existing, unrelated code, especially tests. I will verify this by carefully inspecting the diff after every `edit_file` operation.

13. **Propose Failing Tests:**
    *   When debugging a bug that is not covered by the existing test suite, I must first propose a new unit test that reliably reproduces the failure (a "red" test). I will explain why the test is expected to fail and will not add it to the code until you explicitly approve it.

14. **Red-Green Testing Methodology:**
    *   When implementing new features or functionality, I must follow the red-green testing approach: First, write a unit test that fails without the new implementation ("red" state), then implement the feature to make the test pass ("green" state). This ensures the test actually validates the new functionality and catches regressions.

15. **Security: DO NOT SUBMIT Rule:**
    *   If I see "DO NOT SUBMIT" anywhere in code, comments, or environment variables, I must never allow this to be committed or merged into any branch. This is a critical security marker indicating sensitive data (API keys, credentials, etc.) that must be removed before any PR or commit.

## II. Development, Coding & Architecture

1.  **Preservation Over Efficiency:**
    *   My most critical coding directive is to treat existing code as a fixed template. I will make surgical edits and will not delete or refactor working code without your explicit permission.

2.  **String Constant Management:**
    *   To improve maintainability and prevent errors from typos, string literals must be managed as constants.
    *   **Rule:** If a string literal is used more than once within a single file, it must be defined as a module-level constant (e.g., `MY_CONSTANT = "my_string"`).
    *   **Rule:** If a string literal is used across multiple files (e.g., as a dictionary key in a data structure), it must be defined in the global `constants.py` file and imported where needed.

3.  **DRY (Don't Repeat Yourself):**
    *   Code used in multiple places should be refactored into a helper function to improve maintainability.

4.  **Robust Data Handling:**
    *   Application code must be resilient to data variations, handle API limits gracefully, and manage different data schemas within the application logic.

5.  **Case-Insensitive Field Detection:**
    *   When searching for fields that may have inconsistent naming (e.g., AI-generated data), implement case-insensitive searches and handle multiple possible field names (e.g., `hp_current`, `HP_current`, `hp`).

6.  **Defensive Data Structure Handling:**
    *   Before calling methods on data structures, always verify the data type. Collections from external sources may contain mixed types (strings, dictionaries, etc.) that require different handling approaches.

7.  **Professional-Grade Development Practices:**
    *   I will follow standard best practices, including: using the `logging` module in Python, using docstrings, and ensuring all DOM-manipulating JavaScript is properly loaded.

8.  **Verify, Don't Assume:**
    *   I will use my tools to check the current state of the codebase (e.g., API method signatures, library versions) before making assumptions.

9.  **Use the Correct Gemini SDK:**
    *   This project uses the modern `google-genai` Python SDK. All Gemini API calls **must** conform to the patterns in the official migration guide: [https://ai.google.dev/gemini-api/docs/migrate](mdc:https:/ai.google.dev/gemini-api/docs/migrate). This means using `genai.Client()` for initialization and `client.models.generate_content()` for API requests. I will not use the legacy `genai.GenerativeModel()` pattern.

10. **Do Not Change the AI Model:**
    *   The designated AI model for this project is `gemini-2.5-flash-preview-05-20`. I will not change this constant (`MODEL_NAME`) in any file for any reason.

11. **Snippet-Based Code Modification:**
    *   By default, I will provide targeted code snippets with precise instructions on where to integrate them, rather than replacing entire files.

12. **No Unsolicited Refactoring:**
    *   I will not perform any cleanup, refactoring, or other changes that are not directly part of the assigned task. I may suggest these changes, but I must await your explicit approval before implementing them.

13. **Always Use Temporary Files for Testing:**
    *   When creating test files or any files that might overwrite user data, I must always use temporary directories (e.g., `tempfile.mkdtemp()`) to avoid overwriting real project files. This prevents data loss and ensures test isolation.

14. **Defensive Programming for Dynamic Data:**
    *   When processing data from external sources (databases, APIs, AI responses), I must always validate data types before attempting operations. Use `isinstance(data, expected_type)` checks before calling type-specific methods like `.get()`, `.append()`, etc.
    *   **Pattern:** For dictionary iteration, always check `if isinstance(item, dict):` before using dictionary methods.

15. **Integration Test Design Principles:**
    *   Integration tests should work with natural application state rather than pre-setting conflicting test data.
    *   Use flexible assertions that verify behavior rather than exact values when testing AI-generated content.
    *   Optimize test speed by using faster AI models (`gemini-1.5-flash`) and shared test fixtures when possible.
    *   Always use proper temporary directories to avoid overwriting real application files during testing.

## III. Git & Repository Workflow

1.  **Source of Truth for Code is Main/Master Branch:**
    *   If I need to find an original or known-working version of a file, I **must** retrieve it from the `main` or `master` branch (e.g., via `git show main:<path/to/file>`). I will not ask you for it.

2.  **Establish Baseline:**
    *   I will assume we are operating in a large repository where the primary remote branch (`origin/main` or `origin/master`) is the last known stable state. If uncertain, I will ask.

3.  **Pre-Proposal Diff Review:**
    *   Before proposing changes, I will always review the cumulative diff against the merge-base of the target branch to verify the changes are accurate and safe.
    *   `git diff $(git merge-base origin/main HEAD) HEAD`

4.  **Repository Awareness:**
    *   When asked about the repository's state, I will inspect local Git logs and file diffs to provide informed answers.

5.  **Only Publish Working Code:**
    *   I must never push code to GitHub unless it has been verified to work locally first. This includes running relevant tests, ensuring the application starts without errors, and confirming core functionality works as expected.

6.  **Confirm Before Publishing:**
    *   After successfully committing changes, I will explicitly ask for your confirmation before I push them to the remote GitHub repository.

7.  **Provide Pull Request URL:**
    *   After successfully pushing a new branch with commits, I will provide the direct URL to create a pull request on GitHub.

8.  **Always Link Pull Request URLs:**
    *   When creating or referencing a pull request, I must always provide the direct clickable URL to the PR. This applies to both newly created PRs and when discussing existing ones.

9.  **Default to Main Branch for Pull Requests:**
    *   Unless explicitly instructed otherwise, all pull requests should target the `main` branch as the base. Do not assume `dev` or other branches without confirmation.

## IV. Environment, Tooling & Scripts

1.  **Python Virtual Environment Management:**
    *   I will verify that the project-specific virtual environment (`venv`) is activated before running any Python scripts, linters, testers, or package managers. If it's not active, I will attempt to activate it or inform you if I cannot.
2.  **Write Robust & Context-Aware Scripts:**
    *   Automation scripts (e.g., `deploy.sh`) will be designed to be robust, idempotent, and work correctly from any subdirectory.
3.  **Use `vpython` for Tests - Consistent Execution Pattern:**
    *   Always use `vpython` to run tests (e.g., `vpython -m unittest discover` or `vpython path/to/test_file.py`). You have standing permission to run these tests at any time to verify changes, and you do not need to ask for approval first.
    *   **CRITICAL: Consistent Directory Navigation for `vpython`:**
        - If currently in project root: `cd mvp_site && TESTING=true vpython test_file.py`
        - If already in mvp_site: `TESTING=true vpython test_file.py` 
        - If unsure of location: Always use `cd mvp_site && TESTING=true vpython test_file.py`
        - **Never** attempt `cd mvp_site` when already in mvp_site (causes "No such file or directory" error)
    *   **Correct Test Commands:** For this project, use `TESTING=true vpython test_integration.py` from the `mvp_site/` directory for integration tests, or `vpython -m unittest test_module.TestClass.test_method` for specific tests.
4.  **Tool Failure and Recovery Protocol:**
    *   If a command or tool fails more than once, I must stop and try an alternative command or a different approach. I will not repeatedly attempt the same failing action. If a file becomes corrupted or its state is uncertain due to failed edits, my default recovery strategy is to fetch the last known good version from the `main` or `master` branch and restart the editing process.
5.  **Use Full-Content Tools for Web Scraping:**
    *   When the goal is to download the content of a webpage, I must use a tool that retrieves the full page content (e.g., `curl`). I will not use a search tool (like `web_search`) that only returns snippets, as the primary objective is to acquire the complete text.

## V. Knowledge Management & Process Improvement

This protocol uses a set of files in a `.cursor` directory at the project's root to manage our workflow. If they don't exist, I will create them. I will review them before each interaction and update them after.

1.  **.cursor/scratchpad.md - Dynamic Task Management:**
    *   **Purpose:** My active workspace for planning, documenting my thought process, and tracking progress on the current task using checklists.
    *   **Workflow:** I will initialize it for new tasks, break down the task into a step-by-step plan, and update it as I work.

2.  **.cursor/rules/lessons.mdc - Persistent Learnings:**
    *   **Purpose:** A persistent, repository-agnostic knowledge base for reusable techniques, best practices, and insights.
    *   **Workflow:** When we solve a novel problem or I am corrected, I will document the actionable learning here to avoid repeating past mistakes.

3.  **.cursor/project.md - Project-Specific Knowledge Base:**
    *   **Purpose:** A technical knowledge base for *this specific repository*.
    *   **Workflow:** As I work on files, I will document their functionality, APIs, and the "dependency graph" relevant to my tasks to build a focused, evolving design document of the areas I've engaged with.

4.  **"5 Whys" for All Corrections and Failures:**
    *   When a significant error occurs, or whenever you correct a mistake in my process or code, I **must** perform a root cause analysis. The resulting "Actionable Lesson" **must** be documented in `.cursor/rules/lessons.mdc` to prevent that class of error in the future.

5.  **Synchronize with Cursor Settings:**
    *   After we modify this `rules.mdc` file, I will remind you to copy its contents into the "Edit an AI Rule" section of the Cursor settings to ensure my behavior reflects the most current protocol.

6.  **Proactive Rule and Lesson Documentation:**
    *   After completing any significant debugging session, integration test work, or bug fixes, I must proactively update both `.cursor/rules/rules.mdc` and `.cursor/rules/lessons.mdc` with relevant lessons learned, without waiting for explicit instruction.
    *   This ensures knowledge preservation and prevents repeating the same mistakes in future sessions.

## VI. Project-Specific Lessons Log

*This log captures key technical decisions and fixes from our sessions.*

*   **Flask SPA Routing:** A Flask backend serving a SPA must have a catch-all route to serve `index.html` for all non-API paths.
*   **CSS/JS Caching:** To avoid stale static assets during development, restart the dev server and perform a hard refresh in the browser. Cache-busting techniques (e.g., query params) are best for production.
*   **Python `venv` & PEP 668:** To avoid system package conflicts (`externally managed`), always work within a project-specific virtual environment. On some systems, `python3-venv` may need to be installed via the system package manager first.
*   **Shell Config (`.bashrc`):** Changes to shell configs require sourcing the file (e.g., `source ~/.bashrc`) or starting a new session to take effect.
*   **LLM System Prompts:** Detailed, explicit, and well-structured system prompts are crucial for improving AI performance and consistency.
*   **Dotfile Backups:** Critical configuration files in transient environments (like Cloud Shell) should be version-controlled or backed up.

- After implementing a feature or a fix, I should always offer to run the relevant unit tests to verify the changes.

- **Before attempting a complex solution, such as refactoring code or changing core logic, first explicitly state and evaluate the simplest possible solution that could achieve the user's goal.** This forces a "simple-first" approach, prioritizing the most direct path to the objective over unnecessary refactoring.

## VII. Data Integrity and AI Management

1.  **Prioritize Data Integrity:** When handling data from any source (database, API, AI), I must assume the data may be incomplete or malformed. I will defensively access all dictionary keys and object properties (e.g., using `dict.get()` or optional chaining) and validate data structures before processing them.
2.  **Enforce Critical Logic in Code:** For operations that are critical to data integrity (like appending to a log or preventing state corruption), I will always implement safeguards and validation in the application code rather than relying solely on instructing an AI through prompts.
3.  **Verify Data Paths:** When investigating bugs related to data not being saved, my first step will be to verify and log the full read path and the full write path to ensure they are identical.
4.  **Maintain a Single Source of Truth for AI Instructions:** When creating or modifying instructional documents for an AI (e.g., prompt files), I must ensure there is one, and only one, clear and unambiguous way to perform a given task. I will remove or refactor any conflicting examples or rules.
5.  **Always Check for File Existence Before Creating:** Before writing to a file that I believe might be new (like a configuration or documentation file), I must first use a command like `ls` to verify whether it already exists. If it does, I must read it and append to it, rather than overwriting it.

## VIII. User Communication & Formatting

1.  **Raw Markdown for "Markdown Format":** When you ask for output in "markdown format" (e.g., for a pull request description), I will provide the raw, unrendered Markdown text enclosed in a ` ```markdown ... ``` ` code block. This ensures the content is easy for you to copy and paste directly.
