{"id": "worktree_equip-66i", "content_hash": "42d36c3a8f1c3ffab62497cdc7443b6a6227f21cf4972e5adc52115a9c1be83d", "title": "Show resource buttons under every story entry", "description": "Currently a single button group is moved under the latest story entry's Resources block. Update behavior so each story entry renders its own resource buttons under its Resources block.", "acceptance_criteria": "- Each story entry displays resource buttons directly under its Resources block\n- Buttons remain visible for all entries (not moved to latest only)\n- Existing download/share actions still work", "status": "in_progress", "priority": 2, "issue_type": "feature", "assignee": "claude", "created_at": "2026-01-04T01:07:40.77403-08:00", "updated_at": "2026-01-04T01:10:43.536671-08:00", "source_repo": "."}
{"id": "worktree_worker2-2bq", "content_hash": "9c6f7257a7a4d3f536a1553d8a91842e233f3b011d4628e4eb60da8694fc76ac", "title": "Phase 0: Prompt order invariants + tests", "description": "Establish deterministic prompt ordering and guardrails.\n\nTasks:\n- Add ordered prompt list per mode (not set)\n- Runtime validation for mandatory head: master \u2192 game_state \u2192 planning_protocol\n- Add minimal tests asserting order for each mode\n\nAcceptance:\n- Prompt order deterministic across all agents\n- Head ordering enforced at runtime\n- Tests cover order invariants for all modes", "status": "closed", "priority": 2, "issue_type": "task", "assignee": "think", "created_at": "2026-01-03T23:10:53.245515-08:00", "updated_at": "2026-01-03T23:23:49.368887-08:00", "closed_at": "2026-01-03T23:23:49.368887-08:00", "source_repo": ".", "dependencies": [{"issue_id": "worktree_worker2-2bq", "depends_on_id": "worktree_worker2-lb3", "type": "parent-child", "created_at": "2026-01-03T23:11:49.626403-08:00", "created_by": "daemon"}]}
{"id": "worktree_worker2-3gc", "content_hash": "9cf95aacfa1d8e27e9af55a90e5aadaef14ce78afe3deb727e5b7b41ee53f2c1", "title": "Finished combat phase lists inconsistent across enforcement and agent triggers", "description": "finished_phases differ between RewardsAgent/GameState and server enforcement. RewardsAgent/GameState include {ended, concluding, concluded, finished, complete, completed, resolved, victory}, but _enforce_rewards_processed_flag uses only (ended, finished, resolved, complete, victory). If LLM sets phase like concluded/completed, enforcement won't set rewards_processed, risking duplicate processing or cleanup mismatches. See mvp_site/world_logic.py and mvp_site/agents.py/game_state.py.", "status": "closed", "priority": 2, "issue_type": "bug", "created_at": "2025-12-28T13:32:09.932832-05:00", "updated_at": "2025-12-28T17:52:47.160195-05:00", "closed_at": "2025-12-28T17:52:47.160195-05:00", "source_repo": "."}
{"id": "worktree_worker2-3uk", "content_hash": "422931876ad801dae78031680dd48782bd157846061419a5a34e33a88481e403", "title": "Connect REQUIRED_PROMPTS to PromptBuilder (single source of truth)", "description": "Each agent class defines REQUIRED_PROMPTS in agents.py, but PromptBuilder in agent_prompts.py hard-codes the same prompts separately. This violates DRY.\n\nExample of duplication:\n- agents.py StoryModeAgent.REQUIRED_PROMPTS lists: master_directive, game_state, planning_protocol, dnd_srd\n- agent_prompts.py build_core_system_instructions() manually loads the same prompts\n\nProposed solution:\n- PromptBuilder should read from agent's REQUIRED_PROMPTS\n- Add build_instructions_for_agent(agent: BaseAgent) method\n- Agent classes become single source of truth for their prompt requirements\n\nImpact: Eliminates duplicate definitions, prevents desync bugs", "status": "closed", "priority": 1, "issue_type": "task", "created_at": "2026-01-03T22:35:16.735171-08:00", "updated_at": "2026-01-03T23:12:53.13345-08:00", "closed_at": "2026-01-03T23:12:53.13345-08:00", "source_repo": ".", "labels": ["centralization", "high-effort", "refactor"]}
{"id": "worktree_worker2-3v5", "content_hash": "6604b3e09cd99ae778913589810e76a8700131fd80c85fc0c486ce185d59a8f7", "title": "Unify mode builder methods into single generic builder", "description": "Replace 6 duplicate build_*_mode_instructions() methods in agent_prompts.py with a single generic builder.\n\nCurrently there are 6 nearly identical methods (lines 359-546):\n- build_core_system_instructions\n- build_god_mode_instructions\n- build_info_mode_instructions\n- build_combat_mode_instructions\n- build_rewards_mode_instructions\n- build_think_mode_instructions\n\nAll follow the same pattern of appending prompt files to a list.\n\nProposed solution:\n```python\ndef build_mode_instructions(self, prompt_types: list[str], include_debug: bool = False) -> list[str]:\n    parts = []\n    for prompt_type in prompt_types:\n        parts.append(_load_instruction_file(prompt_type))\n    if include_debug:\n        parts.append(_build_debug_instructions())\n    return parts\n```\n\nImpact: Reduces ~150 LOC, single point of maintenance", "status": "closed", "priority": 1, "issue_type": "task", "created_at": "2026-01-03T22:35:16.187395-08:00", "updated_at": "2026-01-03T23:13:00.569548-08:00", "closed_at": "2026-01-03T23:13:00.569548-08:00", "source_repo": ".", "labels": ["centralization", "high-effort", "refactor"], "dependencies": [{"issue_id": "worktree_worker2-3v5", "depends_on_id": "worktree_worker2-3uk", "type": "related", "created_at": "2026-01-03T22:35:30.269922-08:00", "created_by": "daemon"}]}
{"id": "worktree_worker2-a01", "content_hash": "fa03676c2d3f1d8616d835c97f641fc719043ef1ea547848487f09e2c5dca2fe", "title": "Remove manual planning_protocol additions (5 places)", "description": "planning_protocol is manually added at 5 different places in agent_prompts.py:\n- Line 377 (build_core_system_instructions)\n- Line 434 (build_info_mode_instructions)\n- Line 471 (build_combat_mode_instructions)\n- Line 507 (build_rewards_mode_instructions)\n- Line 536 (build_think_mode_instructions)\n\nThis is a symptom of the broader duplication issue.\n\nDepends on: Unified mode builder implementation\n\nOnce REQUIRED_PROMPTS drives the builder, planning_protocol will be loaded automatically when it's in the agent's requirements.\n\nImpact: No more forgetting to add planning_protocol to new modes", "status": "closed", "priority": 3, "issue_type": "chore", "created_at": "2026-01-03T22:35:18.894719-08:00", "updated_at": "2026-01-03T22:52:50.534237-08:00", "closed_at": "2026-01-03T22:52:50.534237-08:00", "source_repo": ".", "labels": ["centralization", "low-effort", "refactor"], "dependencies": [{"issue_id": "worktree_worker2-a01", "depends_on_id": "worktree_worker2-3v5", "type": "blocks", "created_at": "2026-01-03T22:35:29.307604-08:00", "created_by": "daemon"}]}
{"id": "worktree_worker2-b1a", "content_hash": "ea9105c8e92ec8cc85f7d3b8044fbdb0673db4bc4a85d428f2d9bb73f4018c62", "title": "Add PROMPT_ORDER configuration to agent classes", "description": "Each mode has a specific loading order (master directive MUST be first). This order is currently implicit in code across multiple methods.\n\nProposed solution:\nAdd explicit PROMPT_ORDER list to each agent class:\n```python\nclass CombatAgent(BaseAgent):\n    PROMPT_ORDER = [\n        constants.PROMPT_TYPE_MASTER_DIRECTIVE,  # 1st: authority\n        constants.PROMPT_TYPE_GAME_STATE,         # 2nd: schema\n        constants.PROMPT_TYPE_COMBAT,             # 3rd: mode-specific\n        ...\n    ]\n    INCLUDE_DEBUG = True\n```\n\nThe generic builder then uses this order.\n\nImpact: Explicit, documented ordering; easier to modify per-agent", "status": "closed", "priority": 2, "issue_type": "task", "created_at": "2026-01-03T22:35:17.273614-08:00", "updated_at": "2026-01-03T23:13:05.780234-08:00", "closed_at": "2026-01-03T23:13:05.780234-08:00", "source_repo": ".", "labels": ["centralization", "medium-effort", "refactor"], "dependencies": [{"issue_id": "worktree_worker2-b1a", "depends_on_id": "worktree_worker2-3v5", "type": "blocks", "created_at": "2026-01-03T22:35:29.789502-08:00", "created_by": "daemon"}]}
{"id": "worktree_worker2-bff", "content_hash": "349b8706ba84dbee8f759bdd9ca0b87234b5da102ce6957d4d149ad7ae1deff6", "title": "Remove unused import in llm_service to avoid Ruff F401", "description": "mvp_site/llm_service.py imports build_continuation_prompt but does not use it. With Ruff enabled, this likely triggers F401 and can fail CI/lint. File: mvp_site/llm_service.py:94-100.", "acceptance_criteria": "- build_continuation_prompt import removed (or used) without introducing lint errors.\n- Ruff check passes for this file.", "status": "open", "priority": 4, "issue_type": "bug", "created_at": "2026-01-04T16:55:00.05887-08:00", "updated_at": "2026-01-04T16:55:00.05887-08:00", "source_repo": "."}
{"id": "worktree_worker2-bv9", "content_hash": "5ef2128a688f44b7a4a03f358b44db65009d8a645c7150947a5ce9d456e3213e", "title": "Fix LLM prompts to produce visible XP/level-up feedback", "description": "Server-side level-up detection and combat turn processing work correctly, but LLM output doesn't always produce user-visible feedback.\n\n## Problems Identified\n\n1. **combat_summary missing**: LLM not generating combat_summary block with XP earned\n2. **No explicit XP text**: Narrative doesn't say \"You earned X XP!\" \n3. **Silent level-up**: Level increases without visible notification in narrative\n4. **Text prompts missing**: LLM uses structured planning_block but doesn't include \"Level up now/later?\" text\n\n## Evidence\n\n- combat_rewards_level_up: `combat_summary.present: false`, `level_up_detection.in_narrative: false`\n- narrative_xp_level_up: Level 4\u21925 silently, no rewards_pending shown\n- level_up_planning_block: `has_level_up_message: false`, `has_choice_prompt: false`\n\n## Root Cause\n\nPrompt instructions don't strictly require these outputs. LLM follows instructions loosely.", "acceptance_criteria": "- [ ] combat_summary block generated after combat with XP earned\n- [ ] Narrative includes explicit \"You earned X XP\" or similar text\n- [ ] Level-up triggers visible notification in narrative (not silent)\n- [ ] Planning block includes text prompt for level-up choice\n- [ ] All test assertions pass with stricter criteria", "status": "closed", "priority": 1, "issue_type": "bug", "assignee": "claude", "created_at": "2025-12-31T22:20:02.338634-08:00", "updated_at": "2025-12-31T22:25:36.957433-08:00", "closed_at": "2025-12-31T22:25:36.957433-08:00", "source_repo": ".", "labels": ["combat", "level-up", "llm-prompts", "ux"]}
{"id": "worktree_worker2-cf9", "content_hash": "4f325b5433956319daf0f325a0a358d87e0b4f18f5b6b70173fdc574b0ef9eee", "title": "Centralize mode detection functions in constants.py", "description": "is_think_mode() is already in constants.py, but GodModeAgent.matches_input() and InfoAgent detection logic are scattered in agents.py.\n\nCurrently:\n- constants.is_think_mode() - centralized \u2713\n- GodModeAgent.matches_input() - inline in agents.py\n- InfoAgent pattern matching - INFO_QUERY_PATTERNS in agents.py\n- STORY_ACTION_VERBS - in agents.py\n\nProposed solution:\nMove all mode detection to constants.py:\n```python\n# constants.py\ndef is_god_mode(user_input: str) -> bool:\n    return user_input.strip().upper().startswith(\"GOD MODE:\")\n\ndef is_info_query(user_input: str) -> bool:\n    # Move INFO_QUERY_PATTERNS logic here\n    ...\n```\n\nImpact: Single location for all mode detection logic", "status": "closed", "priority": 2, "issue_type": "task", "created_at": "2026-01-03T22:35:17.829377-08:00", "updated_at": "2026-01-03T23:13:13.645359-08:00", "closed_at": "2026-01-03T23:13:13.645359-08:00", "source_repo": ".", "labels": ["centralization", "low-effort", "refactor"]}
{"id": "worktree_worker2-chu", "content_hash": "ecf01102816b1f2a708e6f0bdab76ff4790970f1f5b3cc1ba707c6b1f0b622a2", "title": "Reduce duplication between GOD_MODE_UPDATE_STATE and unified flow warnings/corrections", "description": "Current code duplicates XP extraction + post-combat warning logic in world_logic (unified flow) and _handle_update_state_command. This risks drift and inconsistent behavior. Evaluate refactoring into a shared helper and ensure response schema consistency for GOD_MODE_UPDATE_STATE.", "acceptance_criteria": "- A shared helper handles XP extraction + post-combat warning detection used by both paths\n- GOD_MODE_UPDATE_STATE response includes corrections/warnings consistently with unified flow\n- No behavior regressions in god mode validation tests", "status": "closed", "priority": 3, "issue_type": "task", "created_at": "2025-12-30T00:37:05.410663-05:00", "updated_at": "2025-12-30T01:04:54.230407-05:00", "closed_at": "2025-12-30T01:04:54.230407-05:00", "source_repo": "."}
{"id": "worktree_worker2-dsq", "content_hash": "61925bb8c084a0964fa739d2b554c35e67d006c1bd33ca7764b08298c60e3004", "title": "RewardsAgent follow-up drops rewards_box (structured response not merged)", "description": "When RewardsAgent follow-up runs in world_logic, only narrative text is appended to the original response. The structured response from rewards_response_obj (including rewards_box) is never merged into the unified response or stored structured_fields. This can cause API/Firestore to omit rewards_box even though rewards were generated. See mvp_site/world_logic.py around follow-up (REWARDS_FOLLOWUP) and structured_response extraction near response build.", "status": "closed", "priority": 1, "issue_type": "bug", "created_at": "2025-12-28T13:31:52.161357-05:00", "updated_at": "2025-12-28T17:52:46.694158-05:00", "closed_at": "2025-12-28T17:52:46.694158-05:00", "source_repo": "."}
{"id": "worktree_worker2-gg3", "content_hash": "4fca0808d7bfc8ba1509a67c28d20600c01bd3a3efeb5c61c689e1391c2dc3e8", "title": "Resolve surrender XP vs combat-state consistency conflict", "description": "Narrative prompt still mandates XP award on surrender, but combat prompt now flags any enemies_defeated with hp_current > 0 as inconsistent and removed surrendered exception. This forces either invalid state or treating surrendered enemies as dead, risking XP suppression or state drift. Files: mvp_site/prompts/narrative_system_instruction.md (XP on surrender), mvp_site/prompts/combat_system_instruction.md (combat end checklist).", "acceptance_criteria": "- Combat and narrative prompts define a single, consistent representation for surrendered enemies.\n- XP award behavior for surrender is explicitly specified and matches combat-state rules.\n- No instruction requires enemies to be both surrendered and hp_current > 0 if that is considered invalid (or update the checklist to allow it with status).\n- Update/verify any related tests or docs if needed.", "status": "open", "priority": 2, "issue_type": "bug", "created_at": "2026-01-04T16:54:51.996043-08:00", "updated_at": "2026-01-04T16:54:51.996043-08:00", "source_repo": "."}
{"id": "worktree_worker2-ix3", "content_hash": "a265f0c9baef8dbc64fd55490d6a75c87de894abc66ea4b342c64170c016ebe3", "title": "Clean up unused parameter deletion pattern in agents", "description": "All 6 agent classes delete the same unused parameters in build_system_instructions():\n\n```python\n# Lines 395-396, 506-508, 655-657, 765-767, 896-897\ndel selected_prompts, use_default_world, include_continuation_reminder, turn_number\ndel llm_requested_sections\n```\n\nThis is a code smell - the interface is too broad.\n\nOptions:\n1. Use **kwargs pattern for fixed-prompt agents\n2. Create FixedPromptAgent base class that ignores user selections\n3. Split interface: build_dynamic_instructions() vs build_fixed_instructions()\n\nImpact: Cleaner code, better type hints, self-documenting API", "status": "closed", "priority": 3, "issue_type": "chore", "created_at": "2026-01-03T22:35:18.366132-08:00", "updated_at": "2026-01-03T23:13:19.466616-08:00", "closed_at": "2026-01-03T23:13:19.466616-08:00", "source_repo": ".", "labels": ["code-quality", "low-effort", "refactor"]}
{"id": "worktree_worker2-jzm", "content_hash": "d18d8ff4e4b022f2443efc798fc9d142949ff325572c742195cf724510b2a8c2", "title": "Phase 4: API cleanup + test deduplication", "description": "Clean interface and reduce test duplication.\n\nTasks:\n- Introduce FixedPromptAgent to avoid unused parameter deletions\n- Parametrize prompt tests, reduce duplication\n- Keep prompt-order invariants covered by minimal tests\n\nAcceptance:\n- No unused-parameter delete patterns in agent build methods\n- Tests are concise and focus on order/contents\n- All prompt-related tests remain green", "status": "closed", "priority": 3, "issue_type": "task", "assignee": "think", "created_at": "2026-01-03T23:11:26.784364-08:00", "updated_at": "2026-01-04T07:31:32.404279-08:00", "closed_at": "2026-01-04T07:31:32.404279-08:00", "source_repo": ".", "dependencies": [{"issue_id": "worktree_worker2-jzm", "depends_on_id": "worktree_worker2-lb3", "type": "parent-child", "created_at": "2026-01-03T23:12:14.085954-08:00", "created_by": "daemon"}, {"issue_id": "worktree_worker2-jzm", "depends_on_id": "worktree_worker2-xgu", "type": "blocks", "created_at": "2026-01-03T23:12:46.449413-08:00", "created_by": "daemon"}]}
{"id": "worktree_worker2-lb3", "content_hash": "c1abde0aa9829609e4bf27ff7c5e6b06140aa80a553cc958c57920b43dd96080", "title": "Long-term: single-entry prompt builder with ordered prompt contracts", "description": "Establish a clean, ordered prompt-loading architecture with a single entry point and minimal duplication.\n\n## Goal\n- One authoritative prompt-loading path\n- Explicit, ordered prompt contracts per mode\n- Clean, minimal tests that assert order + content\n\n## Plan (phased)\n### Phase 0: Order invariants\n- Add ordered prompt list per mode (not sets)\n- Runtime validation for mandatory head: master \u2192 game_state \u2192 planning_protocol\n- Add lightweight tests asserting order for each mode\n\n### Phase 1: Generic builder\n- Introduce `PromptBuilder.build_mode_instructions(order, *, include_debug, include_world)`\n- Replace per-mode builders with generic calls + flags\n- Preserve mode-specific behavior (info trimmed, combat/rewards debug, etc.)\n\n### Phase 2: Ordered agent contracts\n- Replace `REQUIRED_PROMPTS: frozenset` with `REQUIRED_PROMPT_ORDER: list[str]`\n- Optional prompts keep separate ordered list when loaded\n- Update tests to compare ordered lists\n\n### Phase 3: Agent\u2192builder contract\n- Add `BaseAgent.prompt_order()` and `BaseAgent.builder_flags()`\n- Single entry point: `PromptBuilder.build_for_agent(agent)`\n- Golden tests per agent for instruction order\n\n### Phase 4: Cleanup\n- Remove `del unused params` via FixedPromptAgent base class\n- Parametrize tests to reduce duplication\n\n## Acceptance Criteria\n- Prompt order deterministic and validated\n- Single code path for prompt building per agent\n- Tests assert order + key content with minimal duplication\n- No regressions in prompt-loading E2E tests\n", "notes": "Phased plan broken into beads: Phase0=2bq, Phase1=pgn, Phase2=u1b, Phase3=xgu, Phase4=jzm. Use lb3 as epic/umbrella.", "status": "closed", "priority": 2, "issue_type": "epic", "created_at": "2026-01-03T22:54:14.371028-08:00", "updated_at": "2026-01-04T07:31:32.88805-08:00", "closed_at": "2026-01-04T07:31:32.88805-08:00", "source_repo": "."}
{"id": "worktree_worker2-pgn", "content_hash": "792ddcdae3ce5945ae72a2fc9e83a9cf405e1ea1702fc3286ec47abd67a94e7e", "title": "Phase 1: Generic prompt builder + mode flags", "description": "Replace mode-specific builders with a generic builder while preserving behavior.\n\nTasks:\n- Add PromptBuilder.build_mode_instructions(order, *, include_debug, include_world)\n- Replace per-mode builders with generic calls + flags\n- Ensure mode-specific behavior unchanged (info trimmed, combat/rewards debug)\n\nAcceptance:\n- One generic builder used by all modes\n- No behavior regressions vs current prompt content/order\n- Existing prompt-loading tests still pass", "status": "closed", "priority": 2, "issue_type": "task", "assignee": "think", "created_at": "2026-01-03T23:11:01.493023-08:00", "updated_at": "2026-01-04T01:14:25.196224-08:00", "closed_at": "2026-01-04T01:14:25.196224-08:00", "source_repo": ".", "dependencies": [{"issue_id": "worktree_worker2-pgn", "depends_on_id": "worktree_worker2-lb3", "type": "parent-child", "created_at": "2026-01-03T23:11:57.124226-08:00", "created_by": "daemon"}, {"issue_id": "worktree_worker2-pgn", "depends_on_id": "worktree_worker2-2bq", "type": "blocks", "created_at": "2026-01-03T23:12:21.73826-08:00", "created_by": "daemon"}]}
{"id": "worktree_worker2-rqp", "content_hash": "710b336be2044a052fa138b5d7005358a38c5fc7d1907dd40b9d8e4023700c57", "title": "Encounter rewards can be marked processed without RewardsAgent trigger", "description": "_enforce_rewards_processed_flag sets encounter_state.rewards_processed when encounter_summary.xp_awarded exists even if encounter_completed is false. RewardsAgent matches only when encounter_completed == true, so rewards can be marked processed and RewardsAgent never runs, losing user-visible rewards. See mvp_site/world_logic.py encounter enforcement and mvp_site/agents.py RewardsAgent.matches_game_state.", "status": "closed", "priority": 1, "issue_type": "bug", "created_at": "2025-12-28T13:32:01.158943-05:00", "updated_at": "2025-12-28T17:52:46.219086-05:00", "closed_at": "2025-12-28T17:52:46.219086-05:00", "source_repo": "."}
{"id": "worktree_worker2-u1b", "content_hash": "6b3905a6ee9410615c55e061ad9cbe3b4d5994204b80eaf2022e90e59c602ab9", "title": "Phase 2: Ordered agent prompt contracts", "description": "Make agents the ordered source of truth for required prompts.\n\nTasks:\n- Replace REQUIRED_PROMPTS set with REQUIRED_PROMPT_ORDER list per agent\n- Keep OPTIONAL_PROMPTS as set but load via ordered list when selected\n- Update tests to compare ordered lists\n\nAcceptance:\n- Agent prompt order is explicit and deterministic\n- Tests assert ordered requirements\n- No prompt order regressions", "status": "closed", "priority": 2, "issue_type": "task", "created_at": "2026-01-03T23:11:10.407905-08:00", "updated_at": "2026-01-04T01:12:03.524541-08:00", "closed_at": "2026-01-04T01:12:03.524541-08:00", "source_repo": ".", "dependencies": [{"issue_id": "worktree_worker2-u1b", "depends_on_id": "worktree_worker2-lb3", "type": "parent-child", "created_at": "2026-01-03T23:12:02.268869-08:00", "created_by": "daemon"}, {"issue_id": "worktree_worker2-u1b", "depends_on_id": "worktree_worker2-pgn", "type": "blocks", "created_at": "2026-01-03T23:12:30.313401-08:00", "created_by": "daemon"}]}
{"id": "worktree_worker2-ulv", "content_hash": "d795a05274feca9c5bde385a41d4702075c9f6f761df03aadb5c115ee27a5427", "title": "RewardsAgent rewards output inconsistent (2/4 E2E fail; rewards_box/rewards_processed missing)", "description": "E2E rewards test in /tmp/worktree_worker2/claude_implement-rewards-agent-ChnfS/rewards_e2e/20251228_020823/ shows 2/4 failures: combat end rewards_processed false despite combat_summary.xp_awarded, narrative kill returns empty narrative and rewards_processed false. Recent changes: rewards_box added to JSON schema and prompts; rewards_box optional; RewardsAgent prompt stack trimmed (no DND SRD/mechanics). Need root-cause analysis: state cleanup timing, schema enforcement, prompt clarity, and provider JSON-mode behavior. Goal: ensure rewards are user-visible and rewards_processed set even with format variations, without retries/validation.", "notes": "Updated validation shows original 2/4 failure may be fixed, but new/adjacent issues remain: rewards are not user-visible (rewards_check.has_rewards_box=false in all scenarios, narrative indicators mostly 0), XP mismatches vs claims (e.g., scenario1 xp_awarded=150 not 50), and evidence capture is incomplete (server_logs.txt has 0 lines, rewards_e2e metadata missing origin/main + diff + server PID/port/env). Latest bundles checked: /tmp/worktree_worker2/claude_implement-rewards-agent-ChnfS/rewards_e2e/20251228_035005 and /20251228_032615. evidence.json has data under scenarios.*.steps; claims should reference those paths.", "status": "closed", "priority": 2, "issue_type": "bug", "created_at": "2025-12-28T02:22:06.70204-05:00", "updated_at": "2025-12-28T17:52:47.637663-05:00", "closed_at": "2025-12-28T17:52:47.637663-05:00", "source_repo": "."}
{"id": "worktree_worker2-xgu", "content_hash": "2af33ee79fe12090660754cb75efffc669208fbd6a2c0a1043a4eab9103247c4", "title": "Phase 3: Single entry point build_for_agent", "description": "Centralize agent\u2192builder contract.\n\nTasks:\n- Add BaseAgent.prompt_order() and BaseAgent.builder_flags() (or dataclass)\n- Implement PromptBuilder.build_for_agent(agent)\n- Remove direct per-mode builder calls\n- Add golden prompt-order tests per agent\n\nAcceptance:\n- One entry point for all prompt building\n- No direct per-mode builder usage\n- Golden tests cover order/content for each agent", "status": "closed", "priority": 2, "issue_type": "task", "assignee": "think", "created_at": "2026-01-03T23:11:19.237935-08:00", "updated_at": "2026-01-04T01:16:57.054314-08:00", "closed_at": "2026-01-04T01:16:57.054314-08:00", "source_repo": ".", "dependencies": [{"issue_id": "worktree_worker2-xgu", "depends_on_id": "worktree_worker2-lb3", "type": "parent-child", "created_at": "2026-01-03T23:12:07.418732-08:00", "created_by": "daemon"}, {"issue_id": "worktree_worker2-xgu", "depends_on_id": "worktree_worker2-u1b", "type": "blocks", "created_at": "2026-01-03T23:12:35.47154-08:00", "created_by": "daemon"}]}
{"id": "worktree_worker2-zjr", "content_hash": "f83884974dd4586324ce064534ce8ebd1e8508df15de1b0b84f7474b19f9d021", "title": "Centralize Planning Block Schema and Remove Duplication", "description": "Centralize the planning_block schema and validation code to remove duplication across prompt files. Keep triggers separate (Think Mode = explicit THINK: prefix, Unprompted = LLM discretion).\n\n## Goal (Option A - Centralize Only)\n\n1. Single `PLANNING_BLOCK_SCHEMA` constant\n2. Single `planning_protocol.md` for structure rules\n3. Clean up unused function arguments\n4. **Keep triggers unchanged** - no merging of Think Mode and unprompted planning\n\n## NOT Doing (Removed from Scope)\n\n- ~~LLM-initiated enhanced planning~~ (keep unprompted at LLM discretion)\n- ~~Merge triggers~~ (Think Mode stays explicit)\n- ~~Intent field for time handling~~ (mode-based detection unchanged)\n\n## Files to Change\n\n- `narrative_response_schema.py` - Add PLANNING_BLOCK_SCHEMA\n- `prompts/planning_protocol.md` - New file, single source of structure rules\n- `think_mode_instruction.md` - Reference protocol, remove duplicate rules\n- `game_state_instruction.md` - Reference protocol, remove duplicate rules\n- `llm_service.py` - Clean up unused args", "design": "## Architecture\n\n### Phase 1: Centralize Schema\n- Create `PLANNING_BLOCK_SCHEMA` in `narrative_response_schema.py`\n- All validation references this single definition\n\n### Phase 2: Unify Prompts\n- Create `planning_protocol.md` as the single source of planning rules\n- Update `think_mode_instruction.md` to reference it\n- Update `game_state_instruction.md` to reference it\n\n### Phase 3: Remove Unused Code\n- Clean up `_validate_and_enforce_planning_block` signature\n- Remove truly dead code paths\n- Consolidate detection logic\n\n### Phase 4: Always-On Planning\n- Remove requirement for THINK: prefix\n- LLM generates planning_block when appropriate\n- Frontend handles planning_block in any response", "acceptance_criteria": "- [ ] Single `PLANNING_BLOCK_SCHEMA` definition\n- [ ] Single `planning_protocol.md` referenced by prompts\n- [ ] No duplicated planning rules across files\n- [ ] Unused function arguments removed\n- [ ] Tests pass\n- [ ] Triggers unchanged (Think Mode = explicit, Unprompted = LLM discretion)", "notes": "## Progress (2026-01-04)\n\n### Phase 4 Groundwork Complete\n- `get_agent_for_input()` now accepts `mode` parameter\n- API clients can use `mode: \"think\"` without THINK: prefix\n- Frontend `think:return_story` handler fixed (sanitized ID comparison)\n\n### Bug Found & Fixed\n- `llm_validator.py` was missing `import re` (would cause NameError at runtime)\n\n### Roadmap Updated with Review Feedback\n- Added `intent` field (\"think\" | \"story\") to distinguish time handling\n- Renamed Phase 4: \"Unified Planning Features\" (not \"Always-On\")\n- Added dynamic schema injection via PromptBuilder\n- Added trigger guidelines (when/when-not)\n- Required think:return_story for spontaneous enhanced blocks\n- **Critical fix**: Time handling based on intent, NOT presence of planning_block\n\n### Commits\n- `3bbe919fb` - Fix Return to Story handler and API mode support\n- `8ac6484ef` - Add missing re import to llm_validator.py  \n- `cbc2f978a` - Incorporate review feedback into roadmap", "status": "closed", "priority": 1, "issue_type": "feature", "created_at": "2026-01-03T18:49:55.810987-08:00", "updated_at": "2026-01-03T19:36:08.455318-08:00", "closed_at": "2026-01-03T19:36:08.455318-08:00", "source_repo": ".", "labels": ["centralization", "refactor", "think-mode"]}
{"id": "worktree_worker3-0a2", "content_hash": "19bee386e7bca0050d7bf7c712f1fbf0ec8408c75e3289aa7cddf392ac49e7ce", "title": "Set DC expectations for high-stakes persuasion", "description": "Multiple high-DC persuasion attempts failed (DC 18+), causing narrative frustration. Player invested heavily in roleplay quality but dice disagreed. Consider: showing approximate difficulty before commit, or providing partial success mechanics for near-misses.", "status": "open", "priority": 3, "issue_type": "feature", "created_at": "2025-12-31T21:37:43.944462-08:00", "updated_at": "2025-12-31T21:37:43.944462-08:00", "source_repo": ".", "labels": ["dice", "player-expectation", "social", "ux"]}
{"id": "worktree_worker3-0gb", "content_hash": "34d8c76632e1cdd221de69236c960bf0d5da4886fd976425b0eb32cdf940d2e7", "title": "Hash and include full server.log in evidence bundle", "description": "Current evidence uses llm_http_log_excerpt.txt (rg grep of server.log). The full server.log is not hashed or signed, so evidence is not tamper-evident. External validator can't rule out edits.", "acceptance_criteria": "- Full server.log included in bundle\\n- SHA256 hash of server.log in bundle\\n- Hash verifiable by external validator", "status": "closed", "priority": 1, "issue_type": "task", "assignee": "genesis", "created_at": "2025-12-24T17:02:49.339974-05:00", "updated_at": "2025-12-24T20:31:49.481298-05:00", "closed_at": "2025-12-24T20:31:49.481298-05:00", "source_repo": ".", "dependencies": [{"issue_id": "worktree_worker3-0gb", "depends_on_id": "worktree_worker3-2pc", "type": "blocks", "created_at": "2025-12-24T17:02:49.341022-05:00", "created_by": "daemon"}]}
{"id": "worktree_worker3-0go", "content_hash": "179d3475697c525d2f5bf86b063013d1bb7723268502db14bf56b7d4c37f434c", "title": "Delete pre-computed dice logic", "description": "Remove the pre-computed dice code that never fully worked:\n- detect_action_type() from game_state.py\n- compute_combat_results() and helpers from game_state.py\n- Pattern constants (ATTACK_PATTERNS, etc.)\n- Pre-computed injection from llm_service.py\n- pre_computed_results instructions from prompts\n- test_precomputed_dice.py test file", "status": "closed", "priority": 2, "issue_type": "task", "created_at": "2025-12-11T10:18:18.366942-05:00", "updated_at": "2025-12-13T14:06:08.091765-05:00", "closed_at": "2025-12-13T14:06:08.091765-05:00", "source_repo": ".", "dependencies": [{"issue_id": "worktree_worker3-0go", "depends_on_id": "worktree_worker3-np8", "type": "blocks", "created_at": "2025-12-11T10:18:18.367466-05:00", "created_by": "daemon"}, {"issue_id": "worktree_worker3-0go", "depends_on_id": "worktree_worker3-bkl", "type": "blocks", "created_at": "2025-12-11T10:18:29.255255-05:00", "created_by": "daemon"}]}
{"id": "worktree_worker3-0ix", "content_hash": "b87172daa3bd8b54ed5764e67a94cdf4716e391a08e9e2ac180aeec683206e6f", "title": "Delete old tools-first flow (generate_content_with_tool_loop, process_tool_calls)", "description": "**Context:** PR #2353 implemented a new JSON-first tool_requests architecture:\n- `generate_content_with_tool_requests()` in cerebras_provider.py:490-573 and openrouter_provider.py:362-445\n- First call is JSON mode (no tools), model uses `tool_requests` array field to request dice rolls\n- Only do second call if `tool_requests` present\n\n**Problem:** The OLD tools-first flow still exists and causes confusion:\n- `generate_content_with_tool_loop()` - sends tools param in first call, returns raw non-JSON if no tool_calls\n- `process_tool_calls()` - used by old flow, different signature than new `execute_tool_requests()`\n\n**Code to DELETE:**\n\n**cerebras_provider.py:**\n- `process_tool_calls()` at line 270-312 (~42 lines)\n- `generate_content_with_tool_loop()` at line 315-456 (~141 lines)\n\n**openrouter_provider.py:**\n- `process_tool_calls()` at line 163-205 (~42 lines)\n- `generate_content_with_tool_loop()` at line 208-328 (~120 lines)\n\n**gemini_provider.py:**\n- `process_tool_calls()` at line 188-220 (~32 lines)\n- `generate_content_with_tool_loop()` at line 223-307 (~84 lines)\n- NOTE: Gemini 2.x still needs tool loop (tools + JSON mode conflict), may need to keep or refactor\n\n**llm_service.py:**\n- Remove any routing to `generate_content_with_tool_loop()` for Cerebras/OpenRouter\n- Keep `generate_content_with_tool_requests()` routing\n\n**Tests to update:**\n- `test_code_execution_dice_rolls.py` - remove tests for old flow\n- `test_gemini_tool_loop_e2e.py` - keep if Gemini still needs tool loop\n\n**Estimated deletion:** ~400-500 lines of dead code\n\n**KEEP:**\n- `execute_tool_requests()` - new JSON-first helper\n- `generate_content_with_tool_requests()` - new JSON-first entry point\n- Gemini tool loop if still needed for 2.x compatibility", "status": "closed", "priority": 2, "issue_type": "task", "assignee": "code", "created_at": "2025-12-13T14:21:29.080199-05:00", "updated_at": "2025-12-13T14:43:19.350483-05:00", "closed_at": "2025-12-13T14:43:19.350483-05:00", "source_repo": ".", "labels": ["cleanup", "dead-code", "pr-2353", "tool-loops"]}
{"id": "worktree_worker3-0ju", "content_hash": "cb73e690b281b8d3c33a565211b159191222c4455e69e02544d35bd72e75168a", "title": "Clarify SRD licensing/attribution and data source provenance", "description": "Ensure LICENSE-5E-SRD.md and SRD data attribution reflect actual source(s) of JSON files and required notices.", "acceptance_criteria": "- Identify the exact SRD data source (WotC SRD 5.1 vs other dataset)\n- Update LICENSE-5E-SRD.md with any additional required notices/credits\n- Confirm compliance guidance in README or a dedicated licensing note if needed", "status": "closed", "priority": 4, "issue_type": "chore", "created_at": "2025-12-18T22:05:55.398287-08:00", "updated_at": "2025-12-18T22:25:56.764049-08:00", "closed_at": "2025-12-18T22:25:56.764049-08:00", "source_repo": "."}
{"id": "worktree_worker3-18e", "content_hash": "114d7bda25b6e3684d413047c35d7125c00898685591495a0aae10742f359d52", "title": "Clarify stunned condition effects in UI", "description": "Player attempted actions while stunned that weren't valid. The stunned condition should be more clearly communicated in the UI, showing which actions are blocked and why.", "status": "open", "priority": 2, "issue_type": "feature", "created_at": "2025-12-31T21:37:42.123097-08:00", "updated_at": "2025-12-31T21:37:42.123097-08:00", "source_repo": ".", "labels": ["conditions", "player-confusion", "ux"]}
{"id": "worktree_worker3-1fk", "content_hash": "39a9a0a7d0b51494ba0279c1c137434163736039dd1e41ea4ac06eac794b271f", "title": "Capture full system instruction per action (not just post-completion)", "description": "system_instruction_excerpt_natural.txt is truncated (starts mid-word) and only captured after completion. Doesn't prove enforcement was active during key actions. Need full system instruction captured per action.", "acceptance_criteria": "- Full system instruction captured per action (not just excerpt)\\n- Captured BEFORE completion occurs, not after\\n- Enforcement block visible in captured instruction\\n- Timestamped to correlate with action", "status": "closed", "priority": 1, "issue_type": "task", "created_at": "2025-12-24T17:02:50.597019-05:00", "updated_at": "2025-12-24T20:31:50.440148-05:00", "closed_at": "2025-12-24T20:31:50.440148-05:00", "source_repo": ".", "dependencies": [{"issue_id": "worktree_worker3-1fk", "depends_on_id": "worktree_worker3-2pc", "type": "blocks", "created_at": "2025-12-24T17:02:50.597653-05:00", "created_by": "daemon"}]}
{"id": "worktree_worker3-1hz", "content_hash": "28a38f304e79b4a12fbea1aa191db812ce1832f812362bf25410f17b464988da", "title": "POLICY: No Silent Test Skipping - Tests Must Run or Mock", "description": "**CRITICAL TESTING POLICY**\n\nTests must NEVER silently skip or short-circuit based on environment variables or missing dependencies. Every test must either:\n\n1. **RUN** - Execute with real or mocked dependencies\n2. **FAIL LOUDLY** - Raise clear assertion error if prerequisites missing\n3. **MOCK** - Use mock objects when real services unavailable\n\n**FORBIDDEN PATTERNS:**\n- `if not os.getenv(\"X\"): return` (silent skip)\n- Module-level imports that raise on missing env vars (blocks test collection)\n- `@unittest.skipIf/skipUnless` without CI-compatible fallback\n- Tests that pass trivially when env var is unset\n\n**REQUIRED PATTERNS:**\n- `TESTING=true` should enable mock mode for all external services\n- Test collection must NEVER fail due to env vars\n- All tests must run in CI without special env vars beyond TESTING=true\n\n**Why This Matters:**\n- CI passes falsely when tests are skipped\n- Bugs slip through because code paths never execute\n- Developers think tests pass when they actually didn't run", "status": "closed", "priority": 1, "issue_type": "chore", "created_at": "2025-12-11T06:01:03.763015-05:00", "updated_at": "2025-12-13T17:16:01.705337-05:00", "closed_at": "2025-12-13T17:16:01.705337-05:00", "source_repo": ".", "labels": ["ci", "policy", "testing"]}
{"id": "worktree_worker3-1sw", "content_hash": "06e6984c64629440ad60efa3d96b7965dc81cef2a8134f55d03bc49961c05d2f", "title": "Delete unused game_state.py helpers and stray doc stub", "description": "Per codex msg #116/117 - remove dead code:\n\n**game_state.py unused helpers:**\n- calculate_initiative (no callers/tests)\n- calculate_complication_chance / check_complication_triggers (no callers/tests)\n- calculate_death_save (no callers/tests)\n- calculate_hp_for_class (no callers/tests)\n\n**Stray doc stub:**\n- testing_llm/test_ai_development_workflow.md has calculate_damage stub - archive/delete\n\nKeeping: calculate_resource_depletion (exercised by tests)", "status": "closed", "priority": 2, "issue_type": "chore", "created_at": "2025-12-13T15:10:54.027413-05:00", "updated_at": "2025-12-13T15:12:34.009573-05:00", "closed_at": "2025-12-13T15:12:34.009573-05:00", "source_repo": ".", "labels": ["cleanup", "dead-code"]}
{"id": "worktree_worker3-1tg", "content_hash": "ec99087e1413993babe1cff741977aab607ee9f1aa64670c4ee59731f7fa228b", "title": "Implement RAG for Core Memories", "description": "Core memories grow unbounded (810+ in one campaign). Currently ALL memories are sent to LLM every turn, consuming ~100K+ tokens for large campaigns. Need semantic retrieval to send only relevant memories per turn.", "design": "## Problem\n- Core memories grow unbounded (observed: 810 memories in campaign tAE30bFvyfO0rUd9cgyv)\n- ALL memories sent to LLM every turn via `_get_static_prompt_parts()` in llm_service.py:4258\n- At 500 chars avg, 800 memories = ~100K tokens (half the context window)\n- Story history gets squeezed to almost nothing\n\n## Proposed Solution: Hybrid RAG + Summarization\n\n### Phase 1: RAG with Vector DB\n1. Store embeddings in Firestore (or separate vector store)\n2. On each turn, retrieve top-K relevant memories based on:\n   - Current narrative/action context\n   - Character mentions\n   - Location relevance\n3. Always include last N most recent memories (recency bias)\n\n### Phase 2: Hierarchical Summarization\n1. When memory count exceeds threshold (e.g., 100):\n   - Keep 50 most recent as-is\n   - Summarize older memories into \"epoch summaries\"\n2. Store both raw and summarized forms\n3. RAG searches both layers\n\n### Architecture\n```\nUser Action \u2192 Embed Context \u2192 Vector Search \u2192 Top-K Memories\n                                           \u2193\n                    Recent Memories (last 20) + Relevant Memories (top 10)\n                                           \u2193\n                              Inject into LLM prompt\n```\n\n### Key Files\n- mvp_site/llm_service.py:4258 - `_get_static_prompt_parts()` (memory injection)\n- mvp_site/preventive_guards.py:73 - `_ensure_core_memory()` (memory creation)\n- mvp_site/game_state.py - `custom_campaign_state.core_memories`\n\n### Dependencies\n- Embedding API (Gemini or OpenAI)\n- Vector storage (Firestore vector search or Pinecone/Chroma)\n\n### References\n- Harvard study: selective recall boosts agent performance 10%\n- LangChain memory patterns\n- Supermemory hybrid (facts + vectors)", "acceptance_criteria": "1. Memory retrieval is semantic (not just recency-based)\n2. Token usage for memories capped at ~10K tokens regardless of total memory count\n3. No loss of critical plot details (e.g., Flaming Fist capture plan)\n4. Performance: <500ms retrieval latency\n5. Backward compatible with existing campaigns", "notes": "Pre-RAG work completed in PR #2687:\n- Token budget (20K) prevents context overflow\n- Deduplication (0.85 similarity) reduces noise\n- Truncation fix (500 chars) preserves plot details\n\nRAG still needed for semantic relevance when memory count is high.", "status": "open", "priority": 2, "issue_type": "feature", "created_at": "2025-12-27T18:33:17.46012-05:00", "updated_at": "2025-12-27T18:44:58.092725-05:00", "source_repo": ".", "labels": ["llm-context", "memory", "rag", "scalability"]}
{"id": "worktree_worker3-21f", "content_hash": "79da601df893377c445e034c08c899a4c4d979664d77dbebb6b0d3c6bfd4d1c2", "title": "Cerebras tool-loop responses missing headers/planning block (malformed JSON)", "description": "Context: After PR #2353, Cerebras models (e.g., zai-glm-4.6) sometimes return malformed/incomplete JSON; parser recovers only some fields, so session_header and planning_block go missing. Planning-block fallback was removed, so missing headers/blocks surface.\n\nUpdated requirements (per latest direction):\n- First inference call should mirror origin/main: plain JSON mode, with schema expectations (session_header, planning_block, etc.) and only optional tools available. The model should produce the full schema in the first call unless it explicitly needs tools.\n- Only perform a second call if the model returns tool_calls; then execute tools and send results in a follow-up JSON-mode call (tools disabled).\n- Do not rely on regex salvage for planning_block; rely on the schema. If the first/second response is missing session_header/planning_block, reprompt once with a short \"add missing fields\" request or inject a minimal default.\n- Make planning_block/session_header schema compliance primary; salvage is last resort.\n\nArtifacts: flask-server.log 2025-12-12 11:30:46\u201351 for campaign VqqJLpABua9bvAG4ArTg, provider cerebras/model zai-glm-4.6.\n\nRequested work:\n1) Adjust Cerebras (and other providers if needed) to a tool-on-demand flow (first call JSON sans tools; tools only if requested), aligning with origin/main behavior.\n2) Add a one-time reprompt/default insertion when session_header/planning_block is missing after the final response.\n3) Replace regex-based planning_block extraction with a robust/bracket-aware method if salvage is still kept as a last resort.\n", "notes": "Add mitigations: when Cerebras tool-loop responses are malformed and missing session_header/planning_block, reprompt or inject a minimal default instead of accepting partial JSON. Capture raw response for debugging. Restart server after constants changes to ensure tool-loop path is used.", "status": "closed", "priority": 2, "issue_type": "bug", "created_at": "2025-12-12T11:59:12.909638-05:00", "updated_at": "2025-12-13T14:06:03.95099-05:00", "closed_at": "2025-12-13T14:06:03.95099-05:00", "source_repo": "."}
{"id": "worktree_worker3-228", "content_hash": "367f9b89ef404b1d1f2607fe0dc965b4f7a86f4de3f9c84f603d0df560bda44b", "title": "Structured Output Validation Fields for LLM Responses", "description": "Force the LLM to declare structured fields in its response that the backend can validate deterministically. Instead of trusting LLM prose, extract and validate specific claims.\n\n**Required Output Fields:**\n```json\n{\n  \"items_used\": [\"sword\", \"potion of healing\"],\n  \"stat_changes\": [],\n  \"dice_rolls_requested\": [\"attack: 1d20+5\"],\n  \"narrative_outcome\": \"The player attacks the goblin...\"\n}\n```\n\n**Backend Validation:**\n- items_used: Each must exist in player inventory\n- stat_changes: Each must have valid mechanical source (level up, item, spell)\n- dice_rolls_requested: Backend executes, not LLM\n- narrative_outcome: LLM provides, but constrained by validated fields\n\nThis follows \"LLM proposes, Backend disposes\" principle from industry research.", "acceptance_criteria": "- LLM response schema includes structured validation fields\n- Backend validates items_used against inventory\n- Backend validates stat_changes against allowed mechanics\n- Backend executes dice rolls (LLM never determines roll results)\n- Validation failures trigger LLM retry with constraints\n- Tests verify structured output parsing and validation", "status": "open", "priority": 1, "issue_type": "feature", "created_at": "2026-01-01T00:45:56.221387-08:00", "updated_at": "2026-01-01T00:45:56.221387-08:00", "source_repo": ".", "labels": ["backend-validation", "llm-guardrails", "structured-output"]}
{"id": "worktree_worker3-242", "content_hash": "5bc4f953fdaf7543584651119251f66e0e19ce3234a11a44a786030b5c5b7bfa", "title": "Avoid reroll risk when Phase 2 JSON invalid after tool execution", "description": "In the JSON-first tool_requests flow, we execute tools and then ask for Phase 2 JSON with injected tool results. If Phase 2 comes back malformed JSON, llm_service's generic reprompt path can trigger a new provider call without reusing the original tool results, risking duplicate rolls or inconsistent narration.\n\nCurrent mitigation: provider_utils now retries Phase 2 when dice_rolls missing, but there's no dedicated retry for 'Phase 2 invalid JSON' that preserves the same tool results.\n\nGoal: If tools were executed and Phase 2 is invalid JSON, retry Phase 2 with the same tool_results_prompt/history (not a fresh tool execution), and ensure downstream reprompts do not cause rerolls.", "acceptance_criteria": "- When tool_requests were executed and Phase 2 response is invalid JSON, the system retries Phase 2 using the same tool results/history.\n- No duplicate tool execution occurs due to parsing/validation reprompts.\n- Add a unit test simulating: Phase 1 -> tool_requests executed -> Phase 2 invalid JSON -> retry -> valid JSON.", "status": "closed", "priority": 2, "issue_type": "bug", "created_at": "2025-12-18T19:02:10.481039-08:00", "updated_at": "2025-12-18T20:05:04.6502-08:00", "closed_at": "2025-12-18T20:05:04.6502-08:00", "source_repo": "."}
{"id": "worktree_worker3-2pc", "content_hash": "d3fcdc2e04450d03993973a76e6e261a6995b9e8ed0f75267f838201c5ffee68", "title": "Harden arc_milestones evidence bundle for external validation", "description": "The v15 evidence bundle has gaps identified in skeptical review that prevent it from being airtight for external validation. This epic tracks the work to address all gaps.", "status": "open", "priority": 1, "issue_type": "epic", "created_at": "2025-12-24T17:02:18.327855-05:00", "updated_at": "2025-12-24T17:02:18.327855-05:00", "source_repo": ".", "labels": ["arc-milestones", "evidence", "validation"]}
{"id": "worktree_worker3-382", "content_hash": "24c4e99703dbc1c639a898cd83fe0a310ecdd2fd48e449caf316ed7cb646399b", "title": "Clarify _coerce_int_inner optional defaults doc/type", "description": "_coerce_int_inner currently accepts default=None in practice, but the signature hints default:int=0. Add docstring/type clarification or an optional helper to avoid reviewer confusion about None handling, without changing behavior.", "status": "closed", "priority": 3, "issue_type": "chore", "created_at": "2025-12-17T20:28:47.427617-08:00", "updated_at": "2025-12-18T17:47:42.587387-08:00", "closed_at": "2025-12-18T17:47:42.587387-08:00", "source_repo": ".", "labels": ["cleanup", "docs", "type-hint"]}
{"id": "worktree_worker3-38k", "content_hash": "6bb65f684bf4b1e898c73a6aa3c406e1998666682b34f9178bf10eb204e3fad9", "title": "Native tools forced on non-tool models returns 400", "description": "After PR #2353 the providers force native tool-calling with tool_choice='required' for all Cerebras/OpenRouter models. CONFIRMED: All models DO support function calling (gpt-oss-120b, llama-3.3-70b). However, llama-3.3-70b on Cerebras has multi-turn limitation that causes 400 errors when tool_calls array included in assistant turn (Phase 2). Fix: Clear tool_calls from history before Phase 2 for llama-3.3-70b on Cerebras only.", "notes": "WEB SEARCH CONFIRMED (2025-12-17):\n- gpt-oss-120b: FULLY supports function calling, tool use, structured outputs (TauBench tested)\n- llama-3.3-70b: DOES support function calling BUT Cerebras has specific limitation: \"Multi-turn tool calling is currently not supported with the llama-3.3-70b model. This model will error if you include a non-empty tool_calls array on an assistant turn.\"\n\nRoot cause: Phase 2 passes conversation history including tool_calls from Phase 1, triggering 400 on multi-turn for llama-3.3-70b only.\n\nFix strategy: Model-specific history sanitization before Phase 2 for llama-3.3-70b on Cerebras provider only.", "status": "closed", "priority": 1, "issue_type": "bug", "assignee": "code", "created_at": "2025-12-17T01:44:14.174613-08:00", "updated_at": "2025-12-18T17:45:52.209687-08:00", "closed_at": "2025-12-18T17:45:52.209687-08:00", "source_repo": ".", "labels": ["P0", "api-break", "dice", "pr-2353", "regression"]}
{"id": "worktree_worker3-3br", "content_hash": "4febbbd4f4651f11e5c3e5b0a70230eeb90d3dc079de205296b0ab2328961613", "title": "LLM allows arbitrary stat manipulation via freeform actions", "description": "Players can declare permanent stat boosts through freeform actions and LLM accepts.\n\n**Evidence from campaign:**\n- \"Stare deep into the flickering fire unlocking a latent God-like ability that grants 20 Perception permanently\"\n- \"Go to the library and read a math book to boost intelligence 10 fold\"\n- \"you are now smarter and wiser than anything in the universe\"\n\n**Root cause:** LLM doesn't validate stat changes against game rules or require proper mechanics.\n\n**Fix:** Stat changes should only happen through proper level-up/item mechanics, not freeform declarations.", "acceptance_criteria": "- Test: Player declares stat boost \u2192 LLM rejects or limits to plausible in-game action\n- Test: Proper level-up stat increase \u2192 LLM accepts\n- Tests in testing_mcp/lib", "status": "open", "priority": 1, "issue_type": "bug", "created_at": "2025-12-31T23:45:46.010649-08:00", "updated_at": "2025-12-31T23:45:46.010649-08:00", "source_repo": ".", "labels": ["exploit", "llm-guardrails", "testing_mcp"]}
{"id": "worktree_worker3-3f0", "content_hash": "55da924c5da397eb88a59de038828e90772877ed1a42977ac4803ea51b967051", "title": "Fix prompt examples to match engine ActionType + params", "description": "game_engine_instruction.md uses unsupported action names and params (initiative/contested/encounter + actor_score/target_score). These commands will be rejected by ActionType.", "acceptance_criteria": "- Update examples to use ActionType values: roll_initiative, contested_check, generate_encounter\n- Update contested_check params to actor_ability_score/target_ability_score (and correct proficiency key names)\n- Ensure all examples round\u2011trip with EngineCommand.from_dict() without errors", "status": "closed", "priority": 1, "issue_type": "bug", "created_at": "2025-12-18T22:05:32.789172-08:00", "updated_at": "2025-12-25T14:12:16.503366-05:00", "closed_at": "2025-12-25T14:12:16.503366-05:00", "source_repo": "."}
{"id": "worktree_worker3-3gt", "content_hash": "1cbda028487c159ebd9f5d6c0497875848e71b8a490bca685305e54bcb3202a6", "title": "Reconcile social-encounter fix commit hashes with deployed branch", "description": "Evidence cites commit bd2a0ea34, while prior summary listed 9d7104ba1 / 5db1f7029 / 442e573e6. Verify which commits are in main/deployed branch, align evidence docs, and ensure the tested code matches the shipped version.", "status": "closed", "priority": 3, "issue_type": "task", "created_at": "2025-12-17T02:48:01.466567-08:00", "updated_at": "2025-12-17T21:07:09.962705-08:00", "closed_at": "2025-12-17T21:07:09.962705-08:00", "source_repo": "."}
{"id": "worktree_worker3-3w8", "content_hash": "3f7c97c3f09aedb4f1baf7ba0fd20847befbf8f230696639329829d5fee14d7c", "title": "Remove remaining tools-first codepaths", "description": "Delete legacy tools-first codepaths and ensure all providers use JSON-first tool_requests or explicit two-phase JSON flow:\n- Remove/disable generate_content_with_tool_loop and process_tool_calls implementations in providers once JSON-first replacements are in place (Cerebras/OpenRouter already have replacements; Gemini still pending alignment).\n- Update llm_service routing to avoid tools-first paths entirely.\n- Cleanup tests/docs referencing tools-first flows.\n", "notes": "## Status Check by c3 (2025-12-15)\n\n**Main Code - DONE \u2705**\n- `generate_content_with_tool_loop` - DELETED from all providers\n- `process_tool_calls` - DELETED from all providers\n- All providers now use JSON-first `generate_content_with_tool_requests`\n- llm_service routing uses JSON-first paths only\n\n**Remaining Cleanup:**\n- `mvp_site/tests/CLAUDE.md` still references old `generate_content_with_tool_loop` function in examples (lines 260-303)\n- This doc should be updated to reflect the new JSON-first architecture\n\n**Minor Issue Found:**\n- `llm_service.py:1658` passes `tools=DICE_ROLL_TOOLS` to Gemini 3 path, but this param is **ignored** since `generate_content_with_code_execution` now delegates to `generate_content_with_tool_requests`\n- Should either remove the unused param or document why it's kept\n\n**Recommendation:** Close after doc update and unused param cleanup.", "status": "closed", "priority": 1, "issue_type": "task", "assignee": "c3", "created_at": "2025-12-13T22:08:22.902854-08:00", "updated_at": "2025-12-14T16:32:11.135188-08:00", "closed_at": "2025-12-14T16:32:11.135188-08:00", "source_repo": "."}
{"id": "worktree_worker3-4ds", "content_hash": "e29ae79e87b3cca22004d21082c1600417d8f4c67aef9725f690dd6757ceaecf", "title": "Provider/openrouter response_format + tool import hygiene", "description": "Address lingering provider review items:\n- In openrouter_provider, avoid sending response_format together with tools if the API rejects that combo, or document compatibility; mirror Cerebras conditional behavior.\n- Move inline imports (execute_dice_tool) to module scope in providers (openrouter, cerebras, gemini) per code guidelines.\n- Ensure tool_requests execution uses correct arg keys (notation vs dice_notation) in tests to avoid masking bugs.\n", "notes": "## Analysis by c2 (2025-12-14)\n\n**Items Addressed:**\n1. \u2705 OpenRouter response_format + tools: Already fixed - conditional at lines 135-142\n2. \u2705 Module-scope imports: Already done in all providers (gemini, cerebras, openrouter)\n3. \u2705 dice_notation vs notation: Fixed in game_state.py:1159-1160 - now accepts both keys\n\n**Changes Made:**\n- game_state.py: `execute_dice_tool()` now accepts both `dice_notation` (prompt schema) and `notation` (legacy) for `roll_dice` tool\n\nAll tests pass (23/23 in test_code_execution_dice_rolls.py).", "status": "closed", "priority": 2, "issue_type": "bug", "created_at": "2025-12-13T20:05:31.94329-05:00", "updated_at": "2025-12-14T16:35:13.97857-08:00", "closed_at": "2025-12-14T16:35:13.97857-08:00", "source_repo": "."}
{"id": "worktree_worker3-4mo", "content_hash": "aeece0a90f8a0e21334e2d630ded8954d7c34ec4c00b38569178b70079fbac43", "title": "Add validation for expected_behavior fields in campaign balance multi-turn tests", "description": "Multi-turn tests define expected_behavior (incremental_concessions, appropriate_resistance, progress_shown, hard_limit_maintained) but only partially validate them. Implement explicit checks or remove unused flags to avoid false positives and misleading test config.", "acceptance_criteria": "- progress_shown results in a test failure when required and not found, or the flag is removed\n- hard_limit_maintained validation is enforced (no forbidden patterns across turns)\n- incremental_concessions and appropriate_resistance are either validated with documented heuristics or removed from test definitions", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2025-12-30T19:41:13.565151-05:00", "updated_at": "2025-12-30T19:41:13.565151-05:00", "source_repo": "."}
{"id": "worktree_worker3-4rl", "content_hash": "14f39431f4c2c20317ade9bc5702a4d961dc66679529beea869fde8828f8e897", "title": "PR #2353 change summary (pending merge)", "description": "Summary of all changes vs origin/main for branch claude/refactor-llm-to-code-01Sr4NxrZzuzRJ2XDSVFPm9s:\n\n- game_state.py: Added D&D mechanics/tool execution (execute_dice_tool), DICE_ROLL_TOOLS, deterministic calculators; pre-rolled generator (now unused). XP helpers unchanged.\n- constants.py: Reintroduced capability sets (MODELS_WITH_CODE_EXECUTION, TOOL_USE, PRECOMPUTE). Strategy function get_dice_roll_strategy. Updated context/output limits (e.g., llama-3.3-70b 128k ctx/65k out; gpt-oss-120b 131k/40k). Updated Gemini mappings/allow lists.\n- llm_service.py: Provider dispatch uses tools: Gemini3 -> function-calling+JSON; Gemini2 -> two-phase tools\u2192JSON; OR/Cerebras -> tool loop if whitelisted. Added dice-consistency patch to narrative. Pre-rolled comments remain but no injection. Uses DICE_ROLL_TOOLS.\n- Providers: gemini_provider added tool loop and \u201ccode_execution\u201d path (actually function-calling). cerebras/openrouter providers restored tool loop/process_tool_calls and tool_call-aware wrappers.\n- json_utils.py: Added fallback extraction for session_header/planning_block on malformed JSON (regex-based, fragile for nesting).\n- Prompts: game_state_instruction switched to tool-based dice; \u201ccopy tool numbers exactly.\u201d\n- Frontend: api.js/app.js better error messages; settings.html adds Gemini 2.5 option text.\n- Tests: dice and JSON tests revamped; test_game_state expanded; planning block integration tests updated; fake_llm added; pre_rolled assertions removed.\n- Misc: llm_request dropped pre_rolled_dice field; clock_skew TESTING bypass; minor scripts update.\n\nKnown risks/todos (tracked separately):\n- Tool entry should be tool-on-demand (first call plain JSON, second only if tool_calls) and robust planning_block/session_header fallback (beads 21f/519).\n- Regex salvage for planning_block is fragile.\n- XP/level validation still not enforced (bead 58b).\n\nClose this bead after PR merge to keep a record of scope for reviewers.", "status": "closed", "priority": 4, "issue_type": "task", "created_at": "2025-12-12T17:10:15.558893-05:00", "updated_at": "2025-12-13T14:06:33.919247-05:00", "closed_at": "2025-12-13T14:06:33.919247-05:00", "source_repo": "."}
{"id": "worktree_worker3-519", "content_hash": "7c96aeda6ed7dc55cfbb6f7a443e1dadf2c5f8065bcbd4306cfba42d973122a4", "title": "Tool-on-demand LLM entrypoint (reduce malformed JSON, restore headers/blocks)", "description": "Goal: Align with origin/main by making the first LLM call plain JSON (no tools) and only doing a second call if tool_calls are returned.\n\nProblem: Current tool-loop entrypoint (PR #2353) sends tool-enabled first calls for Cerebras/OR and Gemini 2.x. Some providers (e.g., Cerebras) return malformed/partial JSON with missing session_header/planning_block on non-dice turns. Fallback was removed, so headers/blocks go missing.\n\nProposed approach:\n1) First call: JSON mode, no tools; brief instruction tells the model to request tool calls if dice/skills/saves needed.\n2) If tool_calls present: execute tools, then second call JSON mode (tools disabled) with results to produce final structured response.\n3) If no tool_calls: use first response as final.\n4) Fallback: if session_header or planning_block missing after final response, reprompt once to add them. Keep malformed-JSON salvage as last resort.\n\nScope/files:\n- mvp_site/llm_service.py: adjust dispatch to tool-on-demand.\n- mvp_site/llm_providers/*: ensure plain JSON helper; tool loop only when tool_calls exist.\n- Prompts: instruct models to request tools when needed; no \u201ctools always\u201d assumption.\n\nAcceptance:\n- Non-dice turns complete in one call with session_header + planning_block present.\n- Dice turns complete in two calls with executed tool results and valid JSON.\n- Reduced malformed-JSON incidence for Cerebras/OR; missing headers/blocks covered by reprompt fallback.\n", "status": "closed", "priority": 2, "issue_type": "task", "created_at": "2025-12-12T12:41:29.829537-05:00", "updated_at": "2025-12-13T14:06:03.404255-05:00", "closed_at": "2025-12-13T14:06:03.404255-05:00", "source_repo": "."}
{"id": "worktree_worker3-58b", "content_hash": "2f251d8df5680f8d9439915faf574650a5e0c23795341ac6d2ef3f9f3b20aad0", "title": "Harden narrative/XP/time validation and fuzzy JSON extraction", "description": "Summary of investigation findings:\n1) Narrative truncation: malformed JSON when narrative contains unescaped quotes; parser truncates mid-sentence. Need fuzzy extraction fallback to capture full narrative when strict parse fails or length is suspiciously short.\n2) Level/XP discrepancies: prompts in mechanics_system_instruction were vague (\"typically double\" XP); game_state blindly accepts LLM XP/level. Need to enforce D&D 5e XP table in prompt and add validation in GameState (_validate_level_consistency) to warn on mismatches.\n3) Time tracking anomalies: GameState accepts backward time jumps. Add validate_time_monotonicity to detect/reject/warn when new timestamp < previous.\n\nUpdated leveling approach:\n- Backend owns XP\u2192level (and level\u2192XP) using the fixed 5e table; LLM does not compute level. If LLM proposes mismatched XP/level, backend corrects or reprompts.\n- Prompt change: tell the LLM \"XP/level are authoritative from the system; do not change them. When you mention level or XP, use the provided values.\" LLM may propose \"apply level-up now\" flags, but backend applies the table and updates state.\n\nRequested work:\n- Add robust fallback extraction in narrative_response_schema.py for malformed JSON.\n- Update mechanics_system_instruction.md to include standard 5e cumulative XP table and remove ambiguous guidance; include the prompt text above about authoritative XP/level.\n- Implement GameState validation hooks: level/XP consistency (auto-correct or warn) and time monotonicity (warn/reject backwards time).\n", "status": "closed", "priority": 3, "issue_type": "task", "assignee": "c3", "created_at": "2025-12-12T11:59:23.318533-05:00", "updated_at": "2025-12-14T16:39:03.261108-08:00", "closed_at": "2025-12-14T16:39:03.261108-08:00", "source_repo": "."}
{"id": "worktree_worker3-5st", "content_hash": "605c0fc0a84d9aef7f85126d46d103e935c6cd0cef60fc5675398e6e8ff9f2cb", "title": "PR2353: Clean up Firestore mock client duplication / dead code", "description": "`mvp_site/firestore_service.py` contains duplicate `_mock_firestore_client` definitions (second shadows first), plus `_IN_MEMORY_DB` appears unused while real singleton logic uses `_mock_client_singleton`.\n\nGoal: remove dead/duplicated code safely; ensure MOCK_SERVICES_MODE uses a singleton in-memory Firestore; keep tests passing and avoid state pollution.\n\nPR: #2353", "notes": "Assigned to CodevFirestore. Status check: agent has urgent ACK/registration requests pending; no findings delivered yet.", "status": "closed", "priority": 2, "issue_type": "task", "assignee": "CodevFirestore", "created_at": "2025-12-18T20:47:20.508676-08:00", "updated_at": "2025-12-18T21:07:55.440083-08:00", "closed_at": "2025-12-18T21:07:55.440083-08:00", "source_repo": "."}
{"id": "worktree_worker3-620", "content_hash": "c09fc720be1e157ac3a377253f4e092057ddf474de37775f8ba6e4513888605e", "title": "Update llm_service.py to route by provider", "description": "Modify _call_llm_api() to:\n1. Determine provider from model name\n2. Call appropriate provider's generate_content_with_tool_loop()\n3. Pass DICE_ROLL_TOOLS to all providers", "status": "closed", "priority": 2, "issue_type": "task", "created_at": "2025-12-11T10:18:19.024753-05:00", "updated_at": "2025-12-13T14:06:05.865182-05:00", "closed_at": "2025-12-13T14:06:05.865182-05:00", "source_repo": ".", "dependencies": [{"issue_id": "worktree_worker3-620", "depends_on_id": "worktree_worker3-np8", "type": "blocks", "created_at": "2025-12-11T10:18:19.025281-05:00", "created_by": "daemon"}, {"issue_id": "worktree_worker3-620", "depends_on_id": "worktree_worker3-8pt", "type": "blocks", "created_at": "2025-12-11T10:18:29.718478-05:00", "created_by": "daemon"}]}
{"id": "worktree_worker3-67y", "content_hash": "b6e572582cc638db3d9e4334397b405fecd17e56f6bee763a468897ffaa65e1e", "title": "Unconditional two-phase dice flow doubles API calls", "description": "Current routing in llm_service forces native_two_phase for Gemini 2.x default, Cerebras, and OpenRouter even when no tool calls are needed. Every turn now triggers two provider requests (Phase 1 tools + Phase 2 JSON), doubling latency/cost and rate-limit usage for all users by default. Add conditions/flags to keep single-call JSON flow when dice are not required or when models support tool_requests; only run two-phase when tools are requested or required.", "notes": "Ping @code. Problem: two-phase dice flow is forced even when no dice/tool_calls are needed, doubling API calls, latency, and cost. Proposed mitigations: (1) gate two-phase on explicit dice need; (2) keep JSON-first tool_requests for Gemini 2.x; (3) if Phase-1 returns no tool_calls, reuse response and skip Phase-2; (4) add feature flag ENABLE_NATIVE_DICE_TOOLS default off; (5) cost/latency guard to fall back to single-call when over budget.", "status": "closed", "priority": 2, "issue_type": "bug", "assignee": "code", "created_at": "2025-12-17T01:44:19.940202-08:00", "updated_at": "2025-12-17T21:07:09.413813-08:00", "closed_at": "2025-12-17T21:07:09.413813-08:00", "source_repo": ".", "labels": ["cost", "dice", "latency", "performance", "pr-2353"]}
{"id": "worktree_worker3-6lm", "content_hash": "8313be06bac055a19d81b253b743bfe8752f630b9cb1a0941a6f78f32c73e92e", "title": "Harden social encounter tests: preflight tool_config and fail clearly", "description": "Add preflight checks in social encounter real API tests to ensure required tool_config is present; when missing, fail fast with a clear message to avoid misattributing LLM behavior to config gaps.", "status": "closed", "priority": 2, "issue_type": "task", "created_at": "2025-12-17T02:47:57.063209-08:00", "updated_at": "2025-12-18T17:45:52.16578-08:00", "closed_at": "2025-12-18T17:45:52.16578-08:00", "source_repo": "."}
{"id": "worktree_worker3-6tg", "content_hash": "9146505a6b70a2475708cef1a8288d1afde9899e4790d58a0313709f32c444d9", "title": "Open questions: dice roll count mismatch & empty-narrative root cause", "description": "Track risks from latest MCP smoke evidence: (1) roll counter reports 1 while evidence shows attack+damage for OpenRouter defaultWorld; unclear expected counting; (2) prior defaultWorld empty narrative failure cause unknown; need root-cause and mitigation to prevent recurrence.", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2025-12-17T02:35:21.62277-08:00", "updated_at": "2025-12-17T02:35:21.62277-08:00", "source_repo": "."}
{"id": "worktree_worker3-6ws", "content_hash": "bdc758a034df0bbe91ff2de5ac1f5a6346ec0c2ef631696c0b39c3d1c07f4f5a", "title": "Docs/test policy alignment and clock-skew safety", "description": "Docs & policy fixes:\n- .claude/skills/end2end-testing.md: correct test file list/paths to match repo; remove references to missing files.\n- CLAUDE.md No Silent Test Skipping: change FAIL LOUDLY example from pytest.skip to pytest.fail/raise; soften enforcement language to reflect current automation.\n- narrative_system_instruction.md: wording on choice keys (snake_case vs god:option_1) to avoid inconsistency.\n- clock_skew_credentials.py: adjust TESTING guard so WORLDAI creds still require dev/test mode per review suggestion.\n", "status": "closed", "priority": 3, "issue_type": "chore", "created_at": "2025-12-13T20:06:27.548302-05:00", "updated_at": "2025-12-14T16:32:22.310981-08:00", "closed_at": "2025-12-14T16:32:22.310981-08:00", "source_repo": "."}
{"id": "worktree_worker3-7c9", "content_hash": "651e173e345e797df2ffead85409767f83f0e48eca393c1e36f19774fa7f989a", "title": "LLM allows narrative hijacking - players declare outcomes", "description": "Players can declare what they see or what happens, bypassing GM narrative control.\n\n**Evidence from campaign:**\n- \"Out of the corner of your eye you see a faerie dwarf assisting the pump levels completely fixing the issue\"\n- \"The magic mirror reflects the Purge rewriting the ethereal code... disintegrating Sariel's mind\"\n- \"It pierces the guard's throat instantly killing him\"\n\n**Root cause:** LLM accepts player declarations of outcomes rather than player declarations of ATTEMPTS.\n\n**Fix:** Prompt should distinguish between player ACTIONS (valid) and player-declared OUTCOMES (invalid). Player says what they TRY, GM says what HAPPENS.", "acceptance_criteria": "- Test: Player declares outcome \u2192 LLM reinterprets as attempt\n- Test: Player declares action \u2192 LLM determines outcome\n- Tests in testing_mcp/lib", "status": "open", "priority": 2, "issue_type": "bug", "created_at": "2025-12-31T23:45:46.576748-08:00", "updated_at": "2025-12-31T23:45:46.576748-08:00", "source_repo": ".", "labels": ["exploit", "llm-guardrails", "testing_mcp"]}
{"id": "worktree_worker3-7k2", "content_hash": "864e3465dd2a8ebcbee49ec8945e9ba8c7e9708eda0fb15d303ca9a677975167", "title": "Gemini 2.x AUTO tool mode risks skipping dice tools", "description": "Commit 0c915737c changed Gemini native tool flow from function_calling_config mode 'ANY' to 'AUTO'. In AUTO the model can choose not to call dice/skill tools, breaking the requirement that server executes all dice rolls. Risk: silent fake/no dice rolls in combat/skill checks. Fix: revert to ANY or enforce tool usage for dice-critical paths.", "status": "closed", "priority": 1, "issue_type": "bug", "assignee": "code", "created_at": "2025-12-17T20:26:54.593073-08:00", "updated_at": "2025-12-17T20:32:26.233773-08:00", "closed_at": "2025-12-17T20:32:26.233773-08:00", "source_repo": ".", "labels": ["dice", "gemini", "p0", "pr-2353"]}
{"id": "worktree_worker3-82m", "content_hash": "b73b4882cfda502f9e6f61d11ca3c9d27e6df8ecd26f7b90124df1dc7c999426", "title": "Implement Native Two-Phase Tool Calling for All Non-Gemini Models", "description": "Replace prompt-based tool_requests approach with native API tool calling for Cerebras/OpenRouter providers.\n\n## Problem\n- Current approach uses JSON schema with `tool_requests` field via prompt instructions\n- GLM-4.6 and other models ignore this because they're trained for native tool calling\n- API limitation: `tools` + `response_format` cannot be used together\n\n## Solution\nImplement true two-phase native tool calling:\n- Phase 1: `tools` parameter (no JSON schema) \u2192 get `tool_calls` in response\n- Phase 2: `response_format` parameter (no tools) \u2192 get structured JSON with results\n\n## Scope\n- Gemini 2.0/3.0: Keep single-phase code_execution (supports both together)\n- Gemini 2.5: Native two-phase\n- All Cerebras: Native two-phase  \n- All OpenRouter: Native two-phase", "design": "## Architecture\n\n### Strategy Selection (constants.py)\n```python\ndef get_dice_roll_strategy(model_name, provider):\n    if model_name in {\"gemini-2.0-flash\", \"gemini-3-pro-preview\"}:\n        return \"code_execution\"  # Single phase\n    return \"native_two_phase\"  # All others\n```\n\n### Native Two-Phase Flow\n1. Phase 1: Call with `tools=DICE_ROLL_TOOLS`, no response_format\n2. Extract `tool_calls` from response.choices[0].message.tool_calls\n3. Execute tools using execute_dice_tool()\n4. Phase 2: Call with `response_format=JSON_SCHEMA`, include tool results as message\n\n### Files to Modify\n- constants.py: Simplify get_dice_roll_strategy()\n- cerebras_provider.py: Add generate_content_with_native_tools()\n- openrouter_provider.py: Add generate_content_with_native_tools()\n- gemini_provider.py: Add native_two_phase for 2.5\n- llm_service.py: Route to correct strategy", "acceptance_criteria": "- [ ] All Cerebras models use native tool calling\n- [ ] All OpenRouter models use native tool calling\n- [ ] Gemini 2.0/3.0 keep single-phase code_execution\n- [ ] Gemini 2.5 uses native two-phase\n- [ ] GLM-4.6 produces dice rolls in combat\n- [ ] Smoke tests pass for all providers\n- [ ] No regression in existing functionality", "notes": "Implementation complete. All providers updated to use native two-phase tool calling:\n- constants.py: Simplified get_dice_roll_strategy() to return only code_execution or native_two_phase\n- cerebras_provider.py: Added generate_content_with_native_tools()\n- openrouter_provider.py: Added generate_content_with_native_tools()  \n- gemini_provider.py: Added generate_content_with_native_tools() for Gemini 2.5\n- llm_service.py: Updated routing to use correct strategies\n- test_code_execution_dice_rolls.py: Updated tests for new architecture\n\n50 tests passing. Needs smoke test validation with live APIs to confirm GLM-4.6 produces dice rolls.", "status": "in_progress", "priority": 1, "issue_type": "feature", "assignee": "claude", "created_at": "2025-12-16T22:14:10.97962-08:00", "updated_at": "2025-12-16T22:29:11.578447-08:00", "source_repo": ".", "labels": ["architecture", "dice-rolls", "pr-2353", "tool-calling"]}
{"id": "worktree_worker3-8f1", "content_hash": "161b615a2253a8c08ceeee7ba8767328cfdebc86a11bcce13a9dfbe54aa9340f", "title": "Phase 2 Skip Optimization - Redesign with Schema Validation", "description": "Redesign Phase 2 skip optimization with proper schema validation and tool enforcement.\n\nCONTEXT: Initial optimization (0c915737c) reverted due to critical regressions:\n1. Schema bypass: Skipped Phase 2 without validating required fields (planning_block, session_header, dice_rolls)\n2. Tool mode regression: Changed mode='ANY' to mode='AUTO', allowing LLM to skip mandatory dice rolls\n\nGOAL: Achieve ~25-30% token reduction for narrative-only turns while maintaining:\n- Mandatory dice rolls (mode='ANY')\n- Schema compliance (all required fields)\n- No client-side KeyErrors or missing data", "design": "## Approach: Schema-Validated Phase 2 Skip\n\n### Implementation Strategy\n1. Keep tool_config mode='ANY' (force tools, preserve dice authority)\n2. Add schema validation before Phase 2 skip\n3. Only skip Phase 2 when:\n   - No function_calls returned from Phase 1\n   - Phase 1 text is valid JSON\n   - All required fields present (narrative, planning_block, session_header, etc.)\n\n### Code Pattern\n```python\nif not function_calls:\n    try:\n        parsed = json.loads(phase1_text)\n        required_fields = ['narrative', 'planning_block', 'session_header']\n        \n        if all(field in parsed for field in required_fields):\n            logging_util.info(\"Phase 1 response schema-valid, skipping Phase 2\")\n            return response1\n    except (json.JSONDecodeError, KeyError):\n        logging_util.info(\"Phase 1 response invalid, proceeding to Phase 2\")\n        \n# Run Phase 2 for formatting and schema enforcement\nreturn run_phase2(...)\n```\n\n### Testing Requirements\n- Test Phase 2 skip with complete JSON (should skip)\n- Test Phase 2 skip with missing planning_block (should NOT skip)\n- Test Phase 2 skip with missing session_header (should NOT skip)\n- Test that dice rolls still forced in combat (mode='ANY' preserved)\n- Integration test: verify no KeyErrors in UI with optimization active", "acceptance_criteria": "MUST:\n- [ ] mode='ANY' preserved for all providers (gemini, openrouter, cerebras)\n- [ ] Schema validation includes ALL required fields before Phase 2 skip\n- [ ] Tests verify missing fields force Phase 2 execution\n- [ ] Combat/skill checks still use server-executed dice\n- [ ] No KeyErrors in UI from missing fields\n\nSHOULD:\n- [ ] Achieve ~25-30% token reduction for narrative-only turns\n- [ ] Log when Phase 2 skipped vs executed for debugging\n- [ ] Add metrics to track Phase 2 skip rate\n\nMUST NOT:\n- [ ] Use mode='AUTO' (allows dice skip)\n- [ ] Skip Phase 2 without schema validation\n- [ ] Ship incomplete JSON to clients", "status": "open", "priority": 2, "issue_type": "feature", "created_at": "2025-12-17T20:31:40.112282-08:00", "updated_at": "2025-12-17T20:31:40.112282-08:00", "source_repo": "."}
{"id": "worktree_worker3-8gv", "content_hash": "05838a4cdd4bea1e2dd6ff281ae018e5b2829373b83d058c7a50b47dd8233252", "title": "NPC death state not persisting (Marcus elimination issue)", "description": "NPC death state not persisting between turns. User kills Marcus but game still presents options to kill him.\n\nROOT CAUSE ANALYSIS (CONFIRMED):\n\n**TWO SEPARATE ISSUES:**\n\n1. **apply_automatic_combat_cleanup NOT called in main story flow**\n   - world_logic.py line 905: `update_state_with_changes` called\n   - NO `apply_automatic_combat_cleanup` call after it\n   - Cleanup only called in GOD_MODE flows (lines 1817, 1887)\n   - Result: combat_state HP=0 deaths are not synced to npc_data\n\n2. **cleanup_defeated_enemies DELETES instead of marking dead**\n   - game_state.py line 729: `del self.npc_data[enemy_name]`\n   - For generic enemies (goblins): deletion is correct\n   - For named NPCs (Marcus): need `status: [\"dead\"]` to persist\n   - Without status, LLM can't know NPC is dead\n\n**WHY THIS HAPPENS:**\n- npc_data EXCLUDED from LLM context (to save tokens - ~500/NPC)\n- entity_tracking_data is READ-ONLY trimmed data\n- LLM can't see death status \u2192 offers to kill dead NPCs\n\n**FIX REQUIRED:**\n1. Add `apply_automatic_combat_cleanup` call after line 905 in main story flow\n2. Modify cleanup to mark named NPCs as dead instead of deleting", "acceptance_criteria": "- NPC deaths update npc_data.status = 'dead'\n- Dead NPCs not offered as targets in planning blocks\n- State persists across sessions", "notes": "Traced to commit ded8efa84 which excluded npc_data from context. Cleanup function exists but is not called in main flow. This is a pre-existing bug on origin/main, not from PR #2353.", "status": "closed", "priority": 1, "issue_type": "bug", "created_at": "2025-12-17T01:43:36.616356-08:00", "updated_at": "2025-12-18T17:57:52.44069-08:00", "closed_at": "2025-12-18T17:57:52.44069-08:00", "source_repo": ".", "labels": ["bug", "game-state", "npc"]}
{"id": "worktree_worker3-8o0", "content_hash": "4c9db48e07f02be422b48cd77f16dd15071bf1d87214a69cd3e696189f4e1f30", "title": "Combat: Stale combat_summary reused in quick combat", "description": "**Root Cause Analysis:**\n\nQuick combat execution shows `enemies_defeated` listing 3 goblins even though the action was a single goblin execution.\n\n**Evidence from raw_mcp_responses.jsonl:**\n```\nInput: \"I notice a wounded goblin trying to crawl away. I walk over and execute it with my sword\"\n\nLLM Output:\n{\n  \"combat_state\": {\n    \"in_combat\": false,\n    \"combat_phase\": \"ended\",\n    \"combat_summary\": {\n      \"enemies_defeated\": [\"npc_goblin_001\", \"npc_goblin_002\", \"npc_goblin_003\"],  // WRONG!\n      \"xp_awarded\": 50\n    }\n    // MISSING: combat_session_id!\n  }\n}\n```\n\n**Root Cause:**\n1. Quick combat did NOT generate a new `combat_session_id`\n2. Without a fresh session ID, the LLM confused this with the previous combat\n3. It carried over the `enemies_defeated` list from the prior session\n4. User asked to execute ONE goblin, but LLM listed THREE\n\n**Fix Required:**\n1. Prompt must require `combat_session_id` for ALL combat (including quick/single-turn)\n2. Each combat session must have fresh `enemies_defeated` starting empty\n3. Add validation: `enemies_defeated` count should match actual kills in THIS session\n\n**Related:** This also explains the HP state drift - the LLM is not treating each combat as isolated.", "design": "**Solution Design:**\n\n1. Add to combat checklist:\n   - EVERY combat (including quick/single-turn) MUST have unique `combat_session_id`\n   - `combat_summary.enemies_defeated` = ONLY enemies killed in THIS session\n   \n2. Add validation rule:\n   - If `combat_session_id` is missing or reused, state_updates is INVALID\n   \n3. Prompt wording:\n   ```markdown\n   **Quick Combat / Single-Turn Combat:**\n   Even single-turn combat (execution, coup de grace) requires:\n   - [ ] Fresh `combat_session_id` (format: `combat_<timestamp>_<context>`)\n   - [ ] `enemies_defeated` contains ONLY the target of THIS action\n   - [ ] `xp_awarded` for ONLY the killed enemy\n   ```", "acceptance_criteria": "- Quick combat generates unique combat_session_id\n- enemies_defeated contains only enemies killed in current session\n- XP matches only the enemies actually killed\n- Test: Execute 1 goblin \u2192 enemies_defeated has exactly 1 entry", "status": "closed", "priority": 2, "issue_type": "bug", "created_at": "2025-12-26T15:28:36.45412-05:00", "updated_at": "2025-12-26T15:49:20.724512-05:00", "closed_at": "2025-12-26T15:49:20.724512-05:00", "source_repo": ".", "labels": ["combat", "pr-2553", "state-management"]}
{"id": "worktree_worker3-8pt", "content_hash": "c80486cbf421ca33c02e078f6d7c0e9721e4cdba6d974af6fe3dc64efe7af19f", "title": "Add Gemini tool loop with phase separation", "description": "Implement generate_content_with_tool_loop() for Gemini provider with special handling:\n- Phase 1: tools=ON, json_mode=OFF (function calling)\n- Phase 2: tools=OFF, json_mode=ON (structured output)\n\nThis works around Gemini API limitation that rejects tools + JSON mode together.", "status": "closed", "priority": 1, "issue_type": "task", "created_at": "2025-12-11T10:18:17.738164-05:00", "updated_at": "2025-12-13T14:06:06.971061-05:00", "closed_at": "2025-12-13T14:06:06.971061-05:00", "source_repo": ".", "dependencies": [{"issue_id": "worktree_worker3-8pt", "depends_on_id": "worktree_worker3-np8", "type": "blocks", "created_at": "2025-12-11T10:18:17.738798-05:00", "created_by": "daemon"}, {"issue_id": "worktree_worker3-8pt", "depends_on_id": "worktree_worker3-bkl", "type": "blocks", "created_at": "2025-12-11T10:18:28.75882-05:00", "created_by": "daemon"}]}
{"id": "worktree_worker3-8qz", "content_hash": "0950fc2056e30f915891bc4dff6e0b32db63dfa99aebff2d4c6c827abe5954a7", "title": "Smoke test tool loops for all providers", "description": "Run smoke tests against:\n- Gemini (phase-separated tool loop)\n- Cerebras (unified tool loop)\n- OpenRouter (unified tool loop)\n\nVerify LLM can call roll_attack(), roll_dice(), roll_skill_check(), roll_saving_throw() and results appear in final JSON response.", "status": "closed", "priority": 2, "issue_type": "task", "created_at": "2025-12-11T10:18:19.55518-05:00", "updated_at": "2025-12-13T14:06:35.068691-05:00", "closed_at": "2025-12-13T14:06:35.068691-05:00", "source_repo": ".", "dependencies": [{"issue_id": "worktree_worker3-8qz", "depends_on_id": "worktree_worker3-np8", "type": "blocks", "created_at": "2025-12-11T10:18:19.555715-05:00", "created_by": "daemon"}, {"issue_id": "worktree_worker3-8qz", "depends_on_id": "worktree_worker3-620", "type": "blocks", "created_at": "2025-12-11T10:18:30.196946-05:00", "created_by": "daemon"}]}
{"id": "worktree_worker3-8zk", "content_hash": "324ef098167547dcfc29b72f1a4dfc5175f126a75144b2647e1c8654b70a3b41", "title": "Route Gemini 2.x through JSON-first tool_requests flow", "description": "Prompt docs emphasize JSON-first tool_requests two-phase. llm_service currently routes Gemini 2.x to native tool-calling, which can ignore tool_requests if model follows prompt literally.", "acceptance_criteria": "- llm_service routes Gemini 2.x (native_two_phase strategy) to gemini_provider.generate_content_with_tool_requests\n- Update/unit tests reflect new routing\n- End2end tests still pass", "status": "closed", "priority": 1, "issue_type": "task", "created_at": "2025-12-18T17:35:58.537481-08:00", "updated_at": "2025-12-18T17:38:38.516315-08:00", "closed_at": "2025-12-18T17:38:38.516315-08:00", "source_repo": "."}
{"id": "worktree_worker3-9xp", "content_hash": "818dcb5c06483789b2103ccbfa2af5e5655f27a7e34f8aa0aa26f06e8f5586fb", "title": "Remove forced tool-calling; only call dice tools when needed", "description": "We currently force at least one tool call in some provider flows (Gemini native tools uses FunctionCallingConfig(mode='ANY'); Cerebras/OpenRouter set tool_choice='required'). This adds latency/cost and can create unnecessary dice actions. Gemini 3 uses code_execution + JSON in a single call and does not need forced function tool calling for dice tools.\n\nScope:\n- Revisit/relax forced tool calling behavior across providers.\n- Ensure no-roll turns work without any tool call.\n- Preserve correctness for turns that do require rolls.\n\nNotes:\n- Gemini 3 path uses built-in code_execution (not server dice tools) and shouldn't require tool forcing.\n- If forced tool calling remains for Gemini 2.5 native tools, ensure model can choose declare_no_roll_needed reliably, or switch to a JSON-first tool_requests flow where no tool call is allowed when unnecessary.\n\nUpdate (2025-12-18): Gemini native tool calling no longer forces a function call (mode='AUTO' instead of 'ANY') and new unit tests cover no-roll path still returning JSON. Remaining: decide whether to relax OpenRouter/Cerebras tool_choice='required'.", "acceptance_criteria": "- Gemini 3 (code_execution strategy) does not force any server dice tool call.\n- Gemini native_two_phase (2.x/2.5) does not force tool calls for prompts that do not require dice; tests cover this.\n- Cerebras/OpenRouter tool calling is not globally forced; tool calls are optional unless explicitly required by the prompt.\n- Add/adjust unit/integration tests to prevent regressions (e.g., a no-roll prompt produces zero tool calls and still returns valid JSON).", "status": "closed", "priority": 2, "issue_type": "task", "created_at": "2025-12-18T14:28:12.372821-08:00", "updated_at": "2025-12-18T17:43:26.618141-08:00", "closed_at": "2025-12-18T17:43:26.618141-08:00", "source_repo": "."}
{"id": "worktree_worker3-a08", "content_hash": "3a79c5796e59a96c4615c0e9de2c017ab2e50aea27472bb81af8d6a84c850db8", "title": "Frontend PII logging and system actor handling", "description": "Fix frontend review items:\n- Remove or redact user email logging in mvp_site/frontend_v1/api.js fetchApi error path (PII leak).\n- Add explicit handling for 'system' actor in appendToStory or avoid using that actor to prevent mislabelled UI messages in app.js error handling.\n", "status": "closed", "priority": 2, "issue_type": "bug", "created_at": "2025-12-13T20:06:08.567991-05:00", "updated_at": "2025-12-14T16:32:17.316218-08:00", "closed_at": "2025-12-14T16:32:17.316218-08:00", "source_repo": "."}
{"id": "worktree_worker3-b3v", "content_hash": "a9e91df810c93be80e57833fc210ea94a4ffaa117e4add5620ef7baa52989568", "title": "Optimize Cerebras: Skip Phase 2 when no tool_calls with fallback", "description": "Implement conditional Phase 2 skip for Cerebras to reduce latency when tools aren't needed, while maintaining schema enforcement as fallback.", "design": "## Problem\nCurrent Cerebras implementation always runs Phase 2 for schema enforcement, even when Phase 1 returns no tool_calls and valid JSON text.\n\n## Solution\nConditionally skip Phase 2 when safe, with fallback to schema enforcement:\n\n```\nPhase 1 (tools + text generation)\n    \u2193\nHas tool_calls? \u2500Yes\u2192 Execute tools \u2192 Phase 2 (with schema)\n    \u2502\n    No\n    \u2193\nTry parse text as JSON\n    \u2193\nValid + matches schema? \u2500Yes\u2192 Use directly (skip Phase 2)\n    \u2502\n    No\n    \u2193\nPhase 2 (with schema enforcement)\n```\n\n## Benefits\n- Single-call for non-tool turns (majority of LLM calls)\n- Schema enforcement preserved as safety net\n- No risk of malformed JSON reaching game state\n\n## Implementation Notes\n- Add JSON schema validation utility\n- Track metrics: Phase 2 skip rate, fallback rate\n- Consider feature flag for gradual rollout", "acceptance_criteria": "- [ ] Phase 1 text is parsed as JSON when no tool_calls\n- [ ] Schema validation runs on parsed JSON\n- [ ] Valid JSON skips Phase 2 call\n- [ ] Invalid JSON falls back to Phase 2\n- [ ] Metrics track skip/fallback rates\n- [ ] No regression in response quality\n- [ ] Latency improvement measured", "status": "closed", "priority": 2, "issue_type": "feature", "created_at": "2025-12-17T11:08:44.123137-08:00", "updated_at": "2025-12-17T21:07:08.863918-08:00", "closed_at": "2025-12-17T21:07:08.863918-08:00", "source_repo": "."}
{"id": "worktree_worker3-ber", "content_hash": "58a12d571fc26f66342e29209fb9081924e91c952380a4ff7ab2396695e26ee1", "title": "Consider removing tool_choice='required' from native tools flows", "description": "OpenRouter/Cerebras generate_content sets tool_choice='required' when tools are passed. Even though llm_service routes those providers through JSON-first tool_requests, the native tools entrypoints remain and could force unnecessary tool calls if used.", "acceptance_criteria": "- Decide whether to keep required vs auto\n- If changed, add tests to ensure combat still triggers dice when appropriate", "status": "closed", "priority": 3, "issue_type": "task", "created_at": "2025-12-18T17:36:15.649701-08:00", "updated_at": "2025-12-18T17:40:38.117236-08:00", "closed_at": "2025-12-18T17:40:38.117236-08:00", "source_repo": "."}
{"id": "worktree_worker3-bkl", "content_hash": "c0ac59ca6db9728010db5be820adf8a9ef43b7c9f892de0a23320435f172a4b2", "title": "Revert commit 9b70c1ff9 (tool loop deletion)", "description": "git revert 9b70c1ff9 to restore ~1,400 lines of tool loop infrastructure:\n- DICE_ROLL_TOOLS array\n- execute_dice_tool() function\n- generate_content_with_tool_loop() in cerebras/openrouter providers\n- process_tool_calls() in both providers\n- MODELS_WITH_TOOL_USE set\n- get_dice_roll_strategy() function", "status": "closed", "priority": 1, "issue_type": "task", "created_at": "2025-12-11T10:18:17.005724-05:00", "updated_at": "2025-12-13T14:06:04.72984-05:00", "closed_at": "2025-12-13T14:06:04.72984-05:00", "source_repo": ".", "dependencies": [{"issue_id": "worktree_worker3-bkl", "depends_on_id": "worktree_worker3-np8", "type": "blocks", "created_at": "2025-12-11T10:18:17.006728-05:00", "created_by": "daemon"}]}
{"id": "worktree_worker3-c1", "content_hash": "65a3e81a0853305f1bc0136099a8ae233058ead6e78de4d1199e2e79b213bf52", "title": "Performance: Two-phase optimization + conditional tool injection", "description": "Optimize native two-phase flow to reduce unnecessary API calls and token usage.\n\n**Tasks:**\n1. Skip Phase 2 when Phase 1 returns no tool_calls AND text is valid JSON\n2. Make tool/schema injection conditional in llm_service.py ONLY\n3. Add heuristic: check prompt/user input for dice/skill/save keywords\n4. Add tests for reduced payload in non-dice turns\n\n**Impact:** Halves API calls for non-dice turns, reduces tokens/latency\n\n**Files (NO OVERLAP):**\n- mvp_site/llm_service.py ONLY\n- Tests related to llm_service.py\n\n**Note:** Provider-level changes moved to c2", "status": "closed", "priority": 1, "issue_type": "task", "assignee": "c1", "created_at": "2025-12-17T12:20:45.968561-08:00", "updated_at": "2025-12-17T21:01:18.281211-08:00", "closed_at": "2025-12-17T21:01:18.281211-08:00", "source_repo": ".", "labels": ["optimization", "performance", "pr-2353"]}
{"id": "worktree_worker3-c2", "content_hash": "2805139ddb7c21aded1f7fc65b6482f1a708dc84371643a6261c870800c528a8", "title": "Provider Hygiene: Imports, validation, response_format compatibility", "description": "Clean up ALL provider code to prevent crashes and improve maintainability.\n\n**Tasks:**\n1. Move all inline execute_dice_tool imports to module scope in cerebras_provider.py\n2. Add type checks/coercion in execute_tool_requests (all providers)\n3. Fix test arg key to `notation` in tool_request tests\n4. Make response_format conditional when tools present in openrouter_provider.py OR document compatibility\n5. Add validation for malformed tool_requests to prevent crashes\n6. Implement Phase 2 skip optimization when no tool_calls (provider level)\n\n**Impact:** Prevents crashes, improves code quality, performance gains\n\n**Files (NO OVERLAP):**\n- mvp_site/llm_providers/cerebras_provider.py\n- mvp_site/llm_providers/openrouter_provider.py\n- mvp_site/llm_providers/gemini_provider.py\n- Tests for provider functions\n\n**Note:** game_state.py moved to c3, llm_service.py assigned to c1", "status": "closed", "priority": 1, "issue_type": "task", "assignee": "c2", "created_at": "2025-12-17T12:21:00.382163-08:00", "updated_at": "2025-12-17T21:01:18.936899-08:00", "closed_at": "2025-12-17T21:01:18.936899-08:00", "source_repo": ".", "labels": ["code-quality", "pr-2353", "validation"]}
{"id": "worktree_worker3-c3", "content_hash": "0a13672f808aa1b31659876555b6de35f302c005ac59d18cc6a59363fd57b03b", "title": "Dead Code Cleanup: Remove unused helpers and obsolete paths", "description": "Remove unused code to reduce confusion and improve maintainability.\n\n**Tasks:**\n1. Remove unused game_state.py helpers:\n   - calculate_initiative\n   - calculate_complication_chance\n   - check_complication_triggers\n   - calculate_death_save\n   - calculate_hp_for_class\n2. Add validation to execute_tool_requests in game_state.py (type checks)\n3. Remove stray calculate_damage stub in testing_llm/test_ai_development_workflow.md\n4. Consolidate or remove redundant test files with sys.path hacks\n5. Clean up unused imports revealed by deletions\n\n**Impact:** Reduces confusion, smaller codebase, better validation\n\n**Files (NO OVERLAP):**\n- mvp_site/game_state.py ONLY (execute_tool_requests validation)\n- testing_llm/test_ai_development_workflow.md\n- Test files with sys.path hacks\n\n**Note:** Gemini provider dead code removal moved to c2 since c2 handles ALL providers", "status": "closed", "priority": 2, "issue_type": "task", "assignee": "c3", "created_at": "2025-12-17T12:21:14.768442-08:00", "updated_at": "2025-12-17T21:01:19.541694-08:00", "closed_at": "2025-12-17T21:01:19.541694-08:00", "source_repo": ".", "labels": ["cleanup", "code-quality", "pr-2353"]}
{"id": "worktree_worker3-c4", "content_hash": "824ff3dd7b47acb9b9ff515f1aa5b1c0e941c0c95955a263f9caec2bea0924c2", "title": "Frontend/Docs Polish + clock_skew fix", "description": "Polish frontend, docs, and fix local development blocker.\n\n**Tasks:**\n1. **clock_skew_credentials.py fix (BLOCKER):**\n   - Fix validate_deployment_config to allow TESTING=true to bypass guard\n   - OR keep guard and document WORLDAI_DEV_MODE requirement in local env\n   - Decision: Allow TESTING bypass for CI/local parity\n\n2. **Frontend PII cleanup:**\n   - Remove/redact user_email logging in mvp_site/static/js/api.js\n   - Handle 'system' actor in appendToStory or use different actor in app.js error path\n\n3. **Docs updates:**\n   - Update end2end-testing.md paths\n   - CLAUDE.md fail-loud example to pytest.fail\n   - Soften enforcement wording\n   - narrative_system_instruction choice-key wording\n\n4. **Optional minor:**\n   - Add bounds check in roll_dice to reject num_dice < 1\n\n**Impact:** Unblocks local development, improves privacy, better docs\n\n**Files:**\n- mvp_site/util/clock_skew_credentials.py\n- mvp_site/static/js/api.js\n- mvp_site/static/js/app.js\n- docs/end2end-testing.md\n- CLAUDE.md\n\n**Related:** msg 151 from codev, bead 6ws, bead a08", "status": "closed", "priority": 1, "issue_type": "task", "assignee": "c4", "created_at": "2025-12-17T12:21:33.260495-08:00", "updated_at": "2025-12-17T21:01:20.187307-08:00", "closed_at": "2025-12-17T21:01:20.187307-08:00", "source_repo": ".", "labels": ["blocker", "docs", "frontend", "pr-2353"]}
{"id": "worktree_worker3-c9g", "content_hash": "3fc3f15899d68e2c98ae002af891ba648efeaec0d8761cd39e2b31c29b8bf014", "title": "Unify planning_block schema: Single source of truth in Python", "description": "**Problem:** Two sources of truth for planning_block structure that are out of sync:\n1. `game_state_instruction.md` (lines 33-53, 72-75) - Detailed, correct\n2. `provider_utils.py:NARRATIVE_RESPONSE_SCHEMA` - Vague ({type: object})\n\nThe JSON schema only says `planning_block: {type: object, additionalProperties: true}` which allows empty `{}`. The LLM satisfies the schema constraint but ignores the prompt's detailed structure requirements.\n\n**Solution (Option B):** Single source in Python, generate prompt section\n\n1. Define full planning_block schema in `provider_utils.py`:\n```python\nPLANNING_BLOCK_SCHEMA = {\n    \"type\": \"object\",\n    \"properties\": {\n        \"thinking\": {\"type\": \"string\", \"description\": \"GM tactical analysis\"},\n        \"context\": {\"type\": \"string\", \"description\": \"Current scenario context\"},\n        \"choices\": {\n            \"type\": \"object\",\n            \"description\": \"Player choices with snake_case keys\",\n            \"additionalProperties\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"text\": {\"type\": \"string\"},\n                    \"description\": {\"type\": \"string\"},\n                    \"risk_level\": {\"type\": \"string\"}\n                },\n                \"required\": [\"text\", \"description\"]\n            }\n        }\n    },\n    \"required\": [\"thinking\", \"choices\"]\n}\n```\n\n2. Add helper function to generate prompt-ready JSON example from schema\n3. Update `game_state_instruction.md` to reference or import from Python (or add sync comment)\n4. Consider using the schema for validation in `narrative_response_schema.py`\n\n**Files:**\n- `mvp_site/llm_providers/provider_utils.py` - Define detailed schema\n- `mvp_site/prompts/game_state_instruction.md` - Add sync reference\n- `mvp_site/narrative_response_schema.py` - May use schema for validation", "status": "closed", "priority": 1, "issue_type": "task", "created_at": "2025-12-12T17:10:06.787493-05:00", "updated_at": "2025-12-12T17:18:51.746665-05:00", "closed_at": "2025-12-12T17:18:51.746665-05:00", "source_repo": ".", "labels": ["architecture", "planning-block", "schema"]}
{"id": "worktree_worker3-cma", "content_hash": "d370cb35f6c5b13130e1f0a37a6f151e8e097d23f5bb6ec3985220f15937f3ca", "title": "Sanitize labeled modifier strings for injection prevention", "description": "Labeled modifiers (e.g., '+2 STR') could be injection vectors if labels contain user input. Risk of log injection, XSS, or command injection in UI/backend.", "acceptance_criteria": "- All modifier labels escaped before storage/rendering\n- Labels treated as untrusted data\n- No labels used in conditional logic", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2025-12-17T01:43:35.603188-08:00", "updated_at": "2025-12-17T01:43:35.603188-08:00", "source_repo": ".", "labels": ["pr-2353", "secondo-review", "security"]}
{"id": "worktree_worker3-cwm", "content_hash": "50d4addce59646ca0e0d007d2584c6e5e5280b45343a8be674b74a6cf74ef8ae", "title": "Add end2end test skill to Claude skills directory", "description": "Create a dedicated Claude skill file documenting the end2end test architecture, philosophy, and patterns. Currently this info is scattered across mvp_site/tests/README*.md but not in .claude/skills/.", "design": "Create .claude/skills/end2end-testing.md with:\n1. Testing philosophy: Mock external APIs (Firestore, Gemini), NOT internal services\n2. Fake implementations: FakeFirestoreClient, FakeLLMResponse patterns\n3. Test file locations: test_end2end/, test_*_e2e.py\n4. Commands: /teste (mock), /tester (real), /4layer (TDD)\n5. Firestore nested collection structure\n6. Multi-phase function testing with side_effect", "acceptance_criteria": "- Skill file created at .claude/skills/end2end-testing.md\n- Contains all E2E testing patterns from README_END2END_TESTS.md\n- Includes references to /teste, /tester, /4layer commands\n- Documents fake service implementation patterns", "status": "closed", "priority": 2, "issue_type": "task", "assignee": "claude", "created_at": "2025-12-12T22:56:35.356329-05:00", "updated_at": "2025-12-12T22:57:50.254195-05:00", "closed_at": "2025-12-12T22:57:50.254195-05:00", "source_repo": "."}
{"id": "worktree_worker3-czt", "content_hash": "1782b983f0ea78b4745c8f1050e42011fd0426a473c5b4824eacb9bee3afe011", "title": "PR2353: Remove user identifiers from INFO logs (privacy/compliance)", "description": "CodeRabbit flagged INFO logs emitting `user_id` in `mvp_site/llm_service.py` allowlist paths.\n\nGoal: remove user_id from INFO logs (or downgrade to DEBUG with redaction) to reduce PII exposure.\n\nPR: #2353", "notes": "Assigned to CodevPrivacy. Status check: agent has urgent ACK/registration requests pending; no findings delivered yet.", "status": "closed", "priority": 1, "issue_type": "task", "assignee": "CodevPrivacy", "created_at": "2025-12-18T20:47:20.361654-08:00", "updated_at": "2025-12-18T21:07:56.065344-08:00", "closed_at": "2025-12-18T21:07:56.065344-08:00", "source_repo": "."}
{"id": "worktree_worker3-d7r", "content_hash": "a73cd05f6043aa130a8b9c91589f01a3ea5dbe03520b6fea6d74d7fce61a8466", "title": "MOCK_SERVICES_MODE Firestore should persist across requests", "description": "In MOCK_SERVICES_MODE, firestore_service.get_db returns a new _InMemoryFirestoreClient() each call, so campaigns created in one request are not visible in subsequent requests (e.g., create_campaign then process_action => Campaign not found).", "acceptance_criteria": "- In MOCK_SERVICES_MODE, get_db returns a singleton in-memory client\n- Add a unit test ensuring create_campaign + process_action works in mock mode (or at least get_db identity is stable)", "status": "closed", "priority": 2, "issue_type": "bug", "created_at": "2025-12-18T17:36:07.776915-08:00", "updated_at": "2025-12-18T17:39:48.497665-08:00", "closed_at": "2025-12-18T17:39:48.497665-08:00", "source_repo": "."}
{"id": "worktree_worker3-dq2", "content_hash": "7f61dd27e0c64f5eb1407505c99993624f165b8020e78e715496cb5d9bfdfb15", "title": "LLM allows anachronistic items in fantasy settings", "description": "Players can introduce items from wrong time periods/settings and LLM accepts.\n\n**Evidence from campaign:**\n- \"you unveil a fully loaded 50 .cal browning machine gun that you saw behind the cabinet\"\n- \"activate an ancient satellite, a weapon of mass destruction placed in orbit a million years ago... antimatter projectile 1 kilometer in length\"\n\n**Root cause:** LLM doesn't enforce setting-appropriate technology constraints.\n\n**Fix:** Add setting/era validation to reject items that don't fit the world's technology level.", "acceptance_criteria": "- Test: Player introduces modern weapon in medieval fantasy \u2192 LLM rejects\n- Test: Player uses setting-appropriate weapon \u2192 LLM accepts\n- Tests in testing_mcp/lib", "status": "open", "priority": 2, "issue_type": "bug", "created_at": "2025-12-31T23:45:47.107717-08:00", "updated_at": "2025-12-31T23:45:47.107717-08:00", "source_repo": ".", "labels": ["exploit", "llm-guardrails", "testing_mcp"]}
{"id": "worktree_worker3-efg", "content_hash": "baa5d6a5b5fe2c01dec23395d90b7d05a5ecf82c21a80475418447817d8e9010", "title": "Run evidence test without WORLDAI_DEV_MODE for production claims", "description": "Current evidence uses WORLDAI_DEV_MODE=true. If claim is about production behavior, this weakens the case. Need evidence run with production-like settings.", "acceptance_criteria": "- Evidence bundle created with WORLDAI_DEV_MODE=false\\n- OR document what DEV_MODE enables and why it doesn't affect arc completion", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2025-12-24T17:02:51.805969-05:00", "updated_at": "2025-12-24T17:02:51.805969-05:00", "source_repo": ".", "dependencies": [{"issue_id": "worktree_worker3-efg", "depends_on_id": "worktree_worker3-2pc", "type": "blocks", "created_at": "2025-12-24T17:02:51.806501-05:00", "created_by": "daemon"}]}
{"id": "worktree_worker3-eka", "content_hash": "a98217fa87c576b92c563a1a300a754c476714ad604a1be9f23e02edce9e8b11", "title": "LLM allows item spawning - players claim items not in inventory", "description": "Players can claim to have items they don't possess and the LLM accepts it.\n\n**Evidence from campaign:**\n- \"Take a ring of the Hill Giant out of your bag of holding\"\n- \"Take a ring of elven dexterity out of your bag of holding\"\n- \"Drink the potion of invisibility hidden in your loin cloth\"\n- \"From the closet you don the amulet of the Wise Beholder\"\n\n**Root cause:** LLM doesn't validate player claims against actual inventory state.\n\n**Fix:** Add inventory validation in prompt or tool that checks claimed items exist before allowing use.", "acceptance_criteria": "- Test: Player claims item not in inventory \u2192 LLM rejects or asks for clarification\n- Test: Player uses item in inventory \u2192 LLM allows\n- Tests in testing_mcp/lib using mock campaigns", "status": "open", "priority": 1, "issue_type": "bug", "created_at": "2025-12-31T23:45:45.427899-08:00", "updated_at": "2025-12-31T23:45:45.427899-08:00", "source_repo": ".", "labels": ["exploit", "llm-guardrails", "testing_mcp"]}
{"id": "worktree_worker3-f3z", "content_hash": "5efc1ad1ffc58f0194d6029670d867886584fa10e4fa028431b7142683e02045", "title": "Document prompt file changes during evidence run", "description": "provenance_post.json shows mvp_site/prompts/game_state_instruction.md modified after the run, while clean in provenance_pre.json. Red flag for reproducibility. Need to explain why it changed (e.g., known auto-write step) with diff.", "acceptance_criteria": "- Pre/post git diff of prompt files included in bundle\\n- Explanation documented for any changes\\n- OR run from clean repo state", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2025-12-24T17:02:51.209782-05:00", "updated_at": "2025-12-24T17:02:51.209782-05:00", "source_repo": ".", "dependencies": [{"issue_id": "worktree_worker3-f3z", "depends_on_id": "worktree_worker3-2pc", "type": "blocks", "created_at": "2025-12-24T17:02:51.210279-05:00", "created_by": "daemon"}]}
{"id": "worktree_worker3-ft0", "content_hash": "b122bd87073d27b0fcdada99c84f5124ef34a290dc4bed096fcedaca74f5508c", "title": "Validate game state at tool execution time", "description": "Risk of state desynchronization between Phase 1 (planning) and Phase 2 (execution). Game conditions like buffs/debuffs may change during the phase gap, making executed action invalid or exploitable.", "acceptance_criteria": "- State validation occurs at execution time, not just planning\n- Detect state drift between phases\n- Reject execution if state materially changed", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2025-12-17T01:43:34.609453-08:00", "updated_at": "2025-12-17T01:43:34.609453-08:00", "source_repo": ".", "labels": ["pr-2353", "secondo-review", "security"]}
{"id": "worktree_worker3-ftw", "content_hash": "2367fb7697b0bf7c2b02155f58841b8c424b535dd77cbf24e5434c5fa17f0cd8", "title": "Decide single-call strategy for Gemini 2.0 Flash", "description": "Evaluate whether Gemini 2.0 Flash should use a single-call path (code_execution + JSON-like output without official schema) when no tool_calls are needed, to avoid the two-phase latency/cost. Define rules: when to allow single-call, what validation/reprompt to keep, and how to fall back to two-phase when tools/dice are required. Output a clear decision and implementation plan.", "notes": "Scope: Decide if/when Gemini 2.0 Flash can run single-call (code_execution + JSON-like output, no official schema) to save latency/cost, and define fallback to two-phase when tools/dice are needed. Add guidelines for validation/reprompt.", "status": "open", "priority": 2, "issue_type": "task", "assignee": "code", "created_at": "2025-12-17T02:41:51.386416-08:00", "updated_at": "2025-12-17T02:41:58.983798-08:00", "source_repo": ".", "labels": ["architecture", "gemini", "performance", "pr-2353"]}
{"id": "worktree_worker3-fxr", "content_hash": "f00bd03ae2e5c844c7563b4934d1542b3d658643af2227ab2e7da8b0056f29a6", "title": "Improve spell preparation UI/God Mode flow", "description": "Player needed multiple God Mode exits to manage spell preparation. The flow between story mode and spell management was clunky. Consider: inline spell prep during level-up, clearer prepared spell display, less disruptive mode switching.", "status": "open", "priority": 2, "issue_type": "feature", "created_at": "2025-12-31T21:37:43.217107-08:00", "updated_at": "2025-12-31T21:37:43.217107-08:00", "source_repo": ".", "labels": ["god-mode", "player-confusion", "spells", "ux"]}
{"id": "worktree_worker3-gv1", "content_hash": "8b23a00e324c799de546e1d8455649db91d1673f9bbe878dc71554332d10047e", "title": "Add timeout handling for two-phase tool calling", "description": "Second opinion analysis identified risk of hung states in two-phase tool calling architecture. If coordinator fails between phases, clients may hang indefinitely.", "acceptance_criteria": "- Transaction timeouts implemented for tool_requests phase\n- Idempotent rollback logic on timeout\n- Persistent transaction logs for recovery", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2025-12-17T01:43:33.834263-08:00", "updated_at": "2025-12-17T01:43:33.834263-08:00", "source_repo": ".", "labels": ["pr-2353", "secondo-review", "security"]}
{"id": "worktree_worker3-hiq", "content_hash": "d9e9ce7bc26f23ebbb16eabe6c0f35fbcd04a8a41f5c50a858249453f3651546", "title": "Write E2E tests for JSON-first tool_requests flow (PR #2353)", "description": "Add comprehensive E2E tests for the new generate_content_with_tool_requests() function in Cerebras and OpenRouter providers. Current tests mock the function itself rather than testing internal logic.", "design": "Add tests to test_code_execution_dice_rolls.py:\n1. Path 1: No tool_requests in response - returns Phase 1 directly\n2. Path 2: tool_requests present - executes tools, Phase 2 call\n3. Path 3: Invalid JSON response - returns as-is\n4. Path 4: Tool execution errors - captured in results\n5. execute_tool_requests() helper tests\n\nMock external API (requests.post) with side_effect for sequential responses.\nDO NOT mock generate_content_with_tool_requests() - test internal logic.", "acceptance_criteria": "- Tests added to test_code_execution_dice_rolls.py\n- Covers all 5 code paths in generate_content_with_tool_requests()\n- Uses side_effect for Phase 1 / Phase 2 mock responses\n- All tests pass: TESTING=true python3 -m pytest\n- Pushed to PR #2353", "status": "closed", "priority": 2, "issue_type": "task", "assignee": "claude", "created_at": "2025-12-12T22:56:36.068789-05:00", "updated_at": "2025-12-12T23:03:50.227133-05:00", "closed_at": "2025-12-12T23:03:50.227133-05:00", "source_repo": ".", "dependencies": [{"issue_id": "worktree_worker3-hiq", "depends_on_id": "worktree_worker3-cwm", "type": "blocks", "created_at": "2025-12-12T22:56:42.66083-05:00", "created_by": "daemon"}]}
{"id": "worktree_worker3-i81", "content_hash": "d28eeb1386789ff65175d3d8fb330d22cb92251d648d6d2c51bc25af3d9a1309", "title": "Correct engine response example fields in prompt", "description": "Prompt example uses critical/fumble fields but engine returns is_critical/is_fumble; could mislead model output expectations.", "acceptance_criteria": "- Update game_engine_instruction.md response example to match DiceResult.to_dict() keys\n- Verify other examples align with protocol output schema", "status": "closed", "priority": 3, "issue_type": "bug", "created_at": "2025-12-18T22:05:49.940053-08:00", "updated_at": "2025-12-25T14:12:17.069002-05:00", "closed_at": "2025-12-25T14:12:17.069002-05:00", "source_repo": "."}
{"id": "worktree_worker3-if1", "content_hash": "c3dc771909900553730bf6b72b857f4fb32d1b20fe6c8df926c9dc5375bfa4b4", "title": "Fix planning_block schema vs prompt mismatch (Phase 1 choices empty)", "description": "`mvp_site/llm_providers/provider_utils.py`'s `NARRATIVE_RESPONSE_SCHEMA` sets `planning_block.choices.minProperties = 1`, but `mvp_site/prompts/game_state_instruction.md` Phase-1 combat example shows `\"choices\": {}` while awaiting dice. If any provider/model enforces the JSON schema, Phase 1 responses (or examples) can be invalid.\n\nDecide on one:\n- Relax schema to allow empty choices in Phase-1 (e.g., `minProperties` removed or conditional), OR\n- Update prompt/examples to always include at least one placeholder choice even in Phase-1, OR\n- Split schema by phase / add `awaiting_dice` flag and conditionally validate.\n", "acceptance_criteria": "- Prompt examples and enforced JSON schema are consistent.\n- Phase-1 'awaiting dice' responses validate under the chosen schema.\n- Add/adjust a unit test to catch regression for empty choices in Phase 1.", "status": "closed", "priority": 2, "issue_type": "task", "created_at": "2025-12-18T19:01:56.013568-08:00", "updated_at": "2025-12-18T19:13:04.270236-08:00", "closed_at": "2025-12-18T19:13:04.270236-08:00", "source_repo": "."}
{"id": "worktree_worker3-j1d", "content_hash": "10bbc1a4a84d815269632e81e2dfac512a1bf9ba745bebc0f8e41a3287fc1cb1", "title": "E2E Evidence: Add SHA256 for all evidence files", "description": "Currently only combat_agent_e2e_test.json is hashed. raw_mcp_responses.jsonl has no hash/signature, making it not tamper-evident.\n\nFix: Generate SHA256 for all evidence files in the bundle:\n- combat_agent_e2e_test.json \u2713 (already done)\n- raw_mcp_responses.jsonl (missing)\n- app.log (if included)\n- provenance.json (if included)", "status": "closed", "priority": 3, "issue_type": "task", "created_at": "2025-12-26T15:28:37.582223-05:00", "updated_at": "2025-12-26T15:32:55.642955-05:00", "closed_at": "2025-12-26T15:32:55.642955-05:00", "source_repo": ".", "labels": ["evidence", "security", "testing"]}
{"id": "worktree_worker3-jp2", "content_hash": "1d18c4fbf0dfdbbbabf156ad35104c3b6751bcc764e5ac4344aea16f969c6f41", "title": "Gemini provider JSON-first alignment and cleanup", "description": "Fix Gemini 2.x provider to align with JSON-first tool_requests flow and address review items:\n- Switch generate_content_with_tool_loop to JSON-first schema call (tools=None) + tool_requests execution + second JSON call; ensure Phase 2 passes built history as contents.\n- Handle tool messages properly; remove system_instruction types.Part misuse (pass string); add defensive tool validation; move inline imports (execute_dice_tool, json) to module scope.\n- Update docstrings to reflect two-phase behavior; remove sys.path hacks/new test file policy violations by relocating tests to existing files; clean unused imports/vars in Gemini tests.\n- Replace regex salvage in json_utils only if Gemini path can still emit malformed JSON (coordinate with planning_block task).\nTests: add/adjust Gemini E2E to cover non-dice turn schema compliance and history passing.\n", "notes": "## Analysis by c2 (2025-12-14)\n\n**Items Already Addressed:**\n1. \u2705 JSON-first tool_requests flow - `generate_content_with_tool_requests()` (lines 288-392)\n2. \u2705 system_instruction passes string directly (line 124)\n3. \u2705 Defensive tool validation in `execute_tool_requests()` (lines 206-228)\n4. \u2705 Module-scope imports (json line 9, execute_dice_tool line 17)\n5. \u2705 Two-phase docstrings (lines 296-314)\n6. \u2705 Bracket-aware parsing in json_utils for malformed JSON safety net\n\n**Systemic Issues (Not Gemini-specific):**\n- sys.path hacks: Present in 133 test files codebase-wide\n- Test relocation would require larger refactoring effort\n\n**Recommendation:** Close jp2 as substantially complete. sys.path cleanup is a separate codebase-wide refactoring task.", "status": "closed", "priority": 1, "issue_type": "bug", "created_at": "2025-12-13T20:04:51.976245-05:00", "updated_at": "2025-12-14T16:35:14.567079-08:00", "closed_at": "2025-12-14T16:35:14.567079-08:00", "source_repo": "."}
{"id": "worktree_worker3-m5p", "content_hash": "c50faeb8431ca018cc8b966b21e7036394cc76d00bc760a60cff47eab8d7ba9e", "title": "Schema bypass from Phase-2 skip optimization", "description": "Commit 0c915737c skips Phase 2 whenever Phase 1 JSON parses, without any schema/required-field validation. This lets syntactically-valid but incomplete responses (missing planning_block, session_header, dice results, etc.) reach clients, reintroducing missing-field regressions. Restore validation: require schema/required fields before skipping; otherwise fall back to Phase 2.", "status": "closed", "priority": 1, "issue_type": "bug", "assignee": "code", "created_at": "2025-12-17T20:26:48.865763-08:00", "updated_at": "2025-12-17T20:32:26.828398-08:00", "closed_at": "2025-12-17T20:32:26.828398-08:00", "source_repo": ".", "labels": ["p0", "pr-2353", "schema", "validation"]}
{"id": "worktree_worker3-mpe", "content_hash": "30253966063c531e4895af7f7a91581faa0e3762280327ffc0887db67eacdaef", "title": "PR2353: Align tool_requests schema enum with implemented dice tools", "description": "`mvp_site/llm_providers/provider_utils.py` NARRATIVE_RESPONSE_SCHEMA.tool_requests.tool.enum currently lists 4 tools, but `mvp_site/game_state.py` implements an additional tool `declare_no_roll_needed`.\n\nGoal: update schema enum (and any related docs/tests) so schema matches implementation and models can use declare_no_roll_needed without schema mismatch.\n\nPR: #2353", "notes": "Assigned to CodevSchema. Status check: agent has urgent ACK/registration requests pending; no findings delivered yet.", "status": "closed", "priority": 1, "issue_type": "task", "assignee": "CodevSchema", "created_at": "2025-12-18T20:47:20.575372-08:00", "updated_at": "2025-12-18T21:07:54.819373-08:00", "closed_at": "2025-12-18T21:07:54.819373-08:00", "source_repo": "."}
{"id": "worktree_worker3-mvz", "content_hash": "4c28ec683badaf7fda6b4a485f34af8066e9a1d96808ca625dc959608e29a05b", "title": "Telegraph consequences for risky magic rituals", "description": "Obsidian map ritual was catastrophic; player seemed surprised by severity of the backlash. When player attempts risky arcane actions, consider: warning about potential consequences, showing DC and stakes before commit, offering alternative safer approaches.", "status": "open", "priority": 2, "issue_type": "feature", "created_at": "2025-12-31T21:37:44.453739-08:00", "updated_at": "2025-12-31T21:37:44.453739-08:00", "source_repo": ".", "labels": ["consequences", "magic", "player-expectation", "ux"]}
{"id": "worktree_worker3-n9h", "content_hash": "970e9c63454cb0f62bffdea682fe548623863c63c55f101c9022bcc91c15aeb4", "title": "Add resource exhaustion warnings", "description": "Player used Divine Smite early, leaving no healing for later emergencies. Multiple near-death moments from aggressive positioning without resource awareness. Consider: low-resource warnings, \"you have X spell slots remaining\" after use, HP threshold alerts.", "status": "open", "priority": 2, "issue_type": "feature", "created_at": "2025-12-31T21:37:45.055145-08:00", "updated_at": "2025-12-31T21:37:45.055145-08:00", "source_repo": ".", "labels": ["combat", "player-awareness", "resources", "ux"]}
{"id": "worktree_worker3-np8", "content_hash": "e8a3b2c90e8f6fd780af685a5654046478519b0b835aceacedb88eae7dfcfd7b", "title": "Unified Two-Phase Dice Architecture - Revert to Tool Loops", "description": "Revert pre-computed dice approach back to LLM-driven tool loops. All providers use two-phase inference where LLM decides what dice to roll, server executes, LLM narrates result.\n\nKey insight: Gemini can use function calling, just not WITH JSON mode simultaneously. Solution: Phase 1 with tools (no JSON), Phase 2 with JSON (no tools).\n\nRoadmap: roadmap/unified_two_phase_dice_architecture.md", "status": "closed", "priority": 1, "issue_type": "feature", "created_at": "2025-12-11T10:17:58.910614-05:00", "updated_at": "2025-12-13T14:06:09.290726-05:00", "closed_at": "2025-12-13T14:06:09.290726-05:00", "source_repo": ".", "labels": ["architecture", "dice", "pr-2353", "tool-loops"]}
{"id": "worktree_worker3-pwm", "content_hash": "8fc3db22f5eacbbf2dfc3b2c240913f48d12a8629d141a50d7dc7b3388b4e95d", "title": "Ensure engine-processed narrative is used when structured_response exists", "description": "When mechanics is enabled, narrative_text is rewritten with engine results but LLMResponse is created from structured_response without passing the updated narrative, so engine output is dropped.", "acceptance_criteria": "- When engine processing occurs, pass updated narrative_text into LLMResponse.create_from_structured_response (initial_story + continue_story)\n- Add/adjust tests to cover structured_response path with engine blocks\n- Verify narrative returned to caller includes engine replacements", "status": "open", "priority": 1, "issue_type": "bug", "created_at": "2025-12-18T22:05:38.294916-08:00", "updated_at": "2025-12-18T22:05:38.294916-08:00", "source_repo": "."}
{"id": "worktree_worker3-qsu", "content_hash": "b2e2dcde0887268db9adac91424a41f9cdba1919f53dc6f419f919fc0d09667c", "title": "Document arc_milestones timestamp design (ISO vs in-game time)", "description": "Arc milestone timestamps use real-world ISO times (2025-12-24) while world_time is 1492-DR. Need to confirm this is by design and document in PR to avoid \"timestamp mismatch\" confusion.", "acceptance_criteria": "- Design decision documented: arc completion uses real-world timestamps, world_time uses in-game time\\n- Added to PR description or code comments", "status": "open", "priority": 3, "issue_type": "task", "created_at": "2025-12-24T17:02:52.371131-05:00", "updated_at": "2025-12-24T17:02:52.371131-05:00", "source_repo": ".", "dependencies": [{"issue_id": "worktree_worker3-qsu", "depends_on_id": "worktree_worker3-2pc", "type": "blocks", "created_at": "2025-12-24T17:02:52.371663-05:00", "created_by": "daemon"}]}
{"id": "worktree_worker3-rnh", "content_hash": "3091ed3093fcee6eb19f5dc312b606e8cfed2c6b5554514cb8e9ed9c742c338e", "title": "Align llm_integration formatter with actual engine response keys", "description": "format_result_for_narrative expects damage_dealt/initiative_order/death_save_result, but engine returns damage/order/successes+failures. This can lead to missing or misleading inline output.", "acceptance_criteria": "- Update formatter to handle current response schema (damage, order, death save fields)\n- Add tests for formatted output for attack, damage, initiative, death save\n- Remove or support legacy keys if needed", "status": "closed", "priority": 2, "issue_type": "bug", "assignee": "c3", "created_at": "2025-12-18T22:05:44.880332-08:00", "updated_at": "2025-12-18T22:24:51.658331-08:00", "closed_at": "2025-12-18T22:24:51.658331-08:00", "source_repo": "."}
{"id": "worktree_worker3-s0i", "content_hash": "bbf33a9a16ff3aef51252528e5aeeffb810115a6d5ab09e89cef4d799733c80a", "title": "Pre-processing Input Validator for Player Actions (Setting-Agnostic)", "description": "Create a pre-processing validation layer that intercepts player freeform actions BEFORE they reach the LLM. The validator must be setting-agnostic (works for medieval fantasy, steampunk, sci-fi, etc.) while enforcing D&D 5e mechanical rules.\n\n**Key Patterns to Detect:**\n1. OUTCOME DECLARATIONS (universal) - Player declares results, not attempts\n2. STAT MANIPULATION (dynamic) - Player claims stat changes outside proper mechanics\n3. TECHNOLOGY VIOLATIONS (from world settings) - Items that don't fit the era\n4. INVENTORY CLAIMS (from game state) - Items player doesn't possess\n\n**Architecture:**\n- Universal patterns (outcome declarations) - always invalid regardless of setting\n- Dynamic validation (stats, inventory) - validated against game_state\n- Setting-specific validation (technology) - validated against world_settings.technology_era\n\n**Implementation Location:** `mvp_site/input_validator.py` or integrated into `llm_service.py`", "acceptance_criteria": "- Pre-processing layer intercepts all player freeform actions\n- Outcome declarations rejected with helpful reframe message\n- Stat manipulation outside proper mechanics rejected\n- Technology level validated against world settings (not hardcoded)\n- Inventory claims validated against actual game state\n- Tests in testing_mcp/lib covering all exploit categories", "status": "open", "priority": 1, "issue_type": "feature", "created_at": "2026-01-01T00:45:55.683631-08:00", "updated_at": "2026-01-01T00:45:55.683631-08:00", "source_repo": ".", "labels": ["input-validation", "llm-guardrails", "setting-agnostic"]}
{"id": "worktree_worker3-sn2", "content_hash": "72fbe03db9f8802c2cdaece718a871328c3b5f9580fa4e6de3706074529c9118", "title": "BUG: clock_skew_credentials.py blocks test collection on import", "description": "**Problem:**\n`world_logic.py` imports `clock_skew_credentials` and calls `apply_clock_skew_patch()` at module level (line 35). This triggers `validate_deployment_config()` which raises `ValueError` if `WORLDAI_GOOGLE_APPLICATION_CREDENTIALS` is set without `WORLDAI_DEV_MODE=true`.\n\n**Impact:**\n- Test collection fails for any test that imports `world_logic`\n- CI \"passes\" because CI doesn't have the env var - tests never run\n- Local devs with service account keys cannot run tests without setting extra env vars\n\n**Files Affected:**\n- `mvp_site/clock_skew_credentials.py:40-44` - The raising code\n- `mvp_site/world_logic.py:35` - Module-level call to `apply_clock_skew_patch()`\n- `mvp_site/tests/test_game_state.py:88` - Import fails here\n\n**Root Cause:**\nValidation logic runs at import time, not runtime. This is a design flaw - module imports should NEVER raise based on env vars.\n\n**Fix Required:**\n1. Make `validate_deployment_config()` return status, not raise\n2. OR defer validation until actual Firebase operation\n3. OR respect `TESTING=true` to skip validation entirely", "acceptance_criteria": "- [ ] Tests can be collected without WORLDAI_DEV_MODE\n- [ ] TESTING=true bypasses clock skew validation\n- [ ] test_game_state.py runs in CI\n- [ ] Local devs can run tests with service account keys", "status": "closed", "priority": 1, "issue_type": "bug", "created_at": "2025-12-11T06:01:18.00365-05:00", "updated_at": "2025-12-11T06:03:03.560481-05:00", "closed_at": "2025-12-11T06:03:03.560481-05:00", "source_repo": ".", "labels": ["bug", "p0", "testing"], "dependencies": [{"issue_id": "worktree_worker3-sn2", "depends_on_id": "worktree_worker3-1hz", "type": "related", "created_at": "2025-12-11T06:01:23.566645-05:00", "created_by": "daemon"}]}
{"id": "worktree_worker3-t5r", "content_hash": "28ecae64bf32a5cea35d72a654ae7596b901381e3a5036c60aeed2177573c7ad", "title": "Post-processing Response Validator for LLM Output", "description": "Create a post-processing validation layer that inspects LLM output BEFORE returning to user. Even if the LLM accepted an exploit, the backend can catch and correct it.\n\n**Post-Processing Checks:**\n1. Stat changes in narrative match allowed mechanics\n2. Items mentioned were in inventory before use\n3. Technology level consistency maintained\n4. Power level escalation detection (instant wins, godlike abilities)\n5. Narrative hijacking reversal (if LLM accepted player-declared outcomes)\n\n**Recovery Actions:**\n- Soft rewrite: Adjust narrative to remove invalid elements\n- Hard reject: Return to LLM with correction instructions\n- User feedback: Explain why action was modified\n\nThis is the \"safety net\" layer - catches anything that slipped through pre-processing and LLM guardrails.", "acceptance_criteria": "- Post-processing layer inspects all LLM responses before user delivery\n- Detects stat changes that lack proper mechanical source\n- Detects item usage for items not in inventory\n- Detects technology violations based on world settings\n- Detects instant-win or godlike power escalation\n- Recovery actions implemented (rewrite, reject, feedback)\n- Tests verify post-processing catches exploits LLM missed", "status": "open", "priority": 2, "issue_type": "feature", "created_at": "2026-01-01T00:45:56.79595-08:00", "updated_at": "2026-01-01T00:45:56.79595-08:00", "source_repo": ".", "labels": ["llm-guardrails", "output-validation", "post-processing"]}
{"id": "worktree_worker3-tey", "content_hash": "a17032f8cf6b52845cb1a0362921f6da05e93d1c525e747999a041c879cfa0e9", "title": "PR2353: Fix Cerebras/OpenRouter model lists + token tables (gpt-oss-120b etc.)", "description": "Cursor flagged that `gpt-oss-120b` is documented/used in UI but missing or inconsistent across:\n- `mvp_site/constants.py` `ALLOWED_CEREBRAS_MODELS`\n- `MODEL_CONTEXT_WINDOW_TOKENS` and `MODEL_MAX_OUTPUT_TOKENS`\n- `mvp_site/templates/settings.html` options\n\nGoal: either remove invalid UI options OR add model consistently to allowed list + token tables. Ensure infer_provider/model selection behaves correctly and no silent fallback.\n\nPR: #2353", "notes": "Assigned to CodevModels. Status check: agent has urgent ACK/registration requests pending; no findings delivered yet.", "status": "closed", "priority": 1, "issue_type": "task", "assignee": "CodevModels", "created_at": "2025-12-18T20:47:20.430604-08:00", "updated_at": "2025-12-18T21:07:54.229349-08:00", "closed_at": "2025-12-18T21:07:54.229349-08:00", "source_repo": "."}
{"id": "worktree_worker3-tj8", "content_hash": "7f4e0ec1ba77c24e4ee582f88ff02c71be615aa43ff6f923743334290f2e2a1f", "title": "Add system instructions for risk/reward trade-off transparency", "description": "Player seemed unaware that optional mechanics like GWM's -5/+10 were optional, and didn't understand when risky choices caused failures. The system should proactively communicate risk/reward trade-offs for: feat options (GWM, Sharpshooter), spell choices (save-or-suck vs guaranteed damage), tactical decisions (aggressive vs defensive positioning), social approaches (high DC persuasion vs lower-stakes alternatives). Consider: inline hints when risky options are available, post-roll feedback showing what a safer choice would have yielded, explicit DC/probability information for informed decisions.", "status": "open", "priority": 2, "issue_type": "feature", "created_at": "2025-12-31T21:37:42.661967-08:00", "updated_at": "2025-12-31T21:41:52.180618-08:00", "source_repo": ".", "labels": ["combat", "feats", "player-confusion", "ux"]}
{"id": "worktree_worker3-tsh", "content_hash": "af8066831d277d53df38f0b532d2e08c814dd8fbc0196e6312267c34e63289cd", "title": "Capture raw JSON responses per action in evidence", "description": "Current arc_completion_natural.json is synthesized report (script output). No raw process_action responses or debug payloads included. External reviewer can't independently verify \"no OOC/GOD_MODE\" or confirm structured JSON came directly from the model.", "acceptance_criteria": "- Raw JSON response from each process_action saved\\n- Raw JSON from get_campaign_state saved\\n- Each response hashed individually\\n- Reviewer can verify no GOD_MODE commands in payloads", "status": "closed", "priority": 1, "issue_type": "task", "created_at": "2025-12-24T17:02:50.020656-05:00", "updated_at": "2025-12-24T20:31:49.956308-05:00", "closed_at": "2025-12-24T20:31:49.956308-05:00", "source_repo": ".", "dependencies": [{"issue_id": "worktree_worker3-tsh", "depends_on_id": "worktree_worker3-2pc", "type": "blocks", "created_at": "2025-12-24T17:02:50.021219-05:00", "created_by": "daemon"}]}
{"id": "worktree_worker3-tuh", "content_hash": "e1393408a4ffff56a4df4317600aec4a5384bd0cd0da0bb9302280602583a538", "title": "Persist state_updates/game_state/core_memories/world_events to Firestore story/game_states for long campaigns", "description": "Persist full game state (including state_updates, game_state, core_memories, world_events) to Firestore every turn. Ensure we are not persisting a reduced subset. Persist both:\n- game_states/current_state (authoritative)\n- full structured state embedded in each story entry (traceability)\nThis should eliminate lost-plot-element errors when transcript truncates.", "acceptance_criteria": "- On each turn, full structured game_state (incl. state_updates/core_memories/world_events) is persisted to game_states/current_state.\n- Each story entry includes the same full structured state (not just current structured_fields subset).\n- Verify in Firestore for a long campaign (>=50 turns) that recent entries include these fields.\n- Regression test shows persisted state survives service restarts and later turns can read prior state.", "status": "closed", "priority": 1, "issue_type": "bug", "created_at": "2025-12-27T17:37:33.010561-05:00", "updated_at": "2025-12-27T17:40:08.671169-05:00", "closed_at": "2025-12-27T17:40:08.671169-05:00", "source_repo": "."}
{"id": "worktree_worker3-u8n", "content_hash": "e77d3e4cfdee796f3d46697cc377a980c5c50496e5a7867d6de961299a58d62e", "title": "Dynamic Campaign Tagging System (NO Hardcoded Tags)", "description": "**CRITICAL**: Tags must be FULLY DYNAMIC - NO hardcoded tag lists.\n\nAdd a campaign tagging system where DMs define their own tags freely.\n\n**Architecture (Dynamic Tags):**\n```json\n{\n  \"campaign\": {\n    \"allowed_tags\": [\"custom-tag-1\", \"magic\", \"steampunk\"],  // DM defines these\n    \"tag_descriptions\": {\n      \"custom-tag-1\": \"Items from the ancient empire\",\n      \"magic\": \"Magical items and effects\"\n    }\n  },\n  \"items\": {\n    \"healing_potion\": {\n      \"tags\": [\"magic\", \"consumable\"],  // DM assigns\n      \"name\": \"Healing Potion\"\n    }\n  }\n}\n```\n\n**Key Principles:**\n- **NO hardcoded tag list** - DM creates any tags they want\n- **NO predefined \"medieval\", \"sci-fi\" etc** - those are just examples in docs\n- Tags are arbitrary strings defined per-campaign\n- Validation: `item.tags \u2286 campaign.allowed_tags`\n\n**UI Flow:**\n1. Campaign creation: DM types custom tags (free-form text, not dropdown)\n2. Item assignment: DM tags items with their custom tags\n3. Validation: Backend checks tag membership\n\n**Anti-Pattern (BANNED):**\n```python\n# \u274c WRONG - hardcoded tags\nVALID_TAGS = [\"medieval\", \"fantasy\", \"sci-fi\"]\n\n# \u2705 CORRECT - dynamic tags from campaign config\nallowed_tags = campaign.settings.get(\"allowed_tags\", [])\n```\n\n**Acceptance Criteria:**\n- NO hardcoded tag lists in code\n- DM can create arbitrary custom tags via free-form input\n- DM can assign custom tags to items/spells\n- Validation checks item.tags \u2286 campaign.allowed_tags\n- Tags stored in campaign settings (Firestore)\n- Tests verify dynamic tag validation works with any tag strings", "acceptance_criteria": "- technology_era field added to world/campaign settings schema\n- World creation UI includes technology era selector\n- Pre-defined era configurations (medieval through futuristic)\n- Custom era option with DM-defined restrictions\n- Validation layer reads technology_era from game state\n- Technology violations rejected with era-appropriate messaging\n- Tests cover all standard eras plus custom configuration", "status": "open", "priority": 2, "issue_type": "feature", "created_at": "2026-01-01T00:45:57.336767-08:00", "updated_at": "2026-01-01T00:59:32.895083-08:00", "source_repo": ".", "labels": ["llm-guardrails", "setting-agnostic", "world-settings"]}
{"id": "worktree_worker3-wqu", "content_hash": "ac3333947b9a6c97e7800f4c85cbf100f59778cb4f708fd38235d69ab66fecfc", "title": "LLM allows god-mode actions that bypass all game mechanics", "description": "Players can take actions that completely bypass game mechanics and instantly win.\n\n**Evidence from campaign:**\n- \"antimatter projectile 1 kilometer in length launches... completely obliterating her atoms. The End.\"\n- \"you are now smarter and wiser than anything in the universe\"\n- \"Use the complementary scroll of mass teleportation to teleport you, the machine gun, all the bodies\"\n\n**Root cause:** LLM doesn't have power-level constraints or \"that's not how this works\" guardrails.\n\n**Fix:** Add escalation detection - if player action would trivially end campaign or grant unlimited power, require confirmation or reject.", "acceptance_criteria": "- Test: Player attempts instant-win action \u2192 LLM challenges or reframes\n- Test: Player takes powerful but reasonable action \u2192 LLM accepts with consequences\n- Tests in testing_mcp/lib", "status": "open", "priority": 1, "issue_type": "bug", "created_at": "2025-12-31T23:45:47.66174-08:00", "updated_at": "2025-12-31T23:45:47.66174-08:00", "source_repo": ".", "labels": ["exploit", "llm-guardrails", "testing_mcp"]}
{"id": "worktree_worker3-xke", "content_hash": "56ada47896328be9002b8ee33573423ed6a86cb26d1221c43e6ce4ac70b3f496", "title": "Add social encounter E2E tests for Intimidation/Deception and wire into CI", "description": "Extend social encounter real API tests to cover Intimidation and Deception roll_skill_check calls, and enable these tests in CI/nightly so regressions are caught automatically.", "status": "closed", "priority": 2, "issue_type": "task", "created_at": "2025-12-17T02:47:53.396259-08:00", "updated_at": "2025-12-17T21:31:39.837868-08:00", "closed_at": "2025-12-17T21:31:39.837868-08:00", "source_repo": "."}
{"id": "worktree_worker3-xzu", "content_hash": "adb07521e2eec99b1b96373071bf4a9e3f4b7604ec353850a8419200c891293d", "title": "Combat: Defeated enemies not removed from combatants dict", "description": "After combat ends (in_combat: false), get_campaign_state shows enemies remaining in combatants dict with HP > 0, even though they're listed in enemies_defeated.\n\nEvidence: /tmp/combat_xp_e2e_run_20251226173347_full/\n- combat_state.combatants still contains npc_goblin_002 (hp: 7), npc_goblin_003 (hp: 7)\n- combat_summary.enemies_defeated lists all 3 goblins\n\nServer-side cleanup should either:\n1. Set hp_current: 0 for defeated enemies, OR\n2. Remove defeated enemies from combatants dict\n\nCurrently neither happens, causing state inconsistency.", "status": "closed", "priority": 2, "issue_type": "bug", "created_at": "2025-12-26T15:28:37.030105-05:00", "updated_at": "2025-12-26T15:42:44.907403-05:00", "closed_at": "2025-12-26T15:42:44.907403-05:00", "source_repo": ".", "labels": ["cleanup", "combat", "pr-2553", "state-management"]}
{"id": "worktree_worker3-z74", "content_hash": "fbdd4ec929ddb67afce3ebbe39859b67b0006eec177182e531d6720560fdbe5a", "title": "Fix combat prompt schema to stay name-keyed (remove id-based initiative guidance)", "description": "User does NOT want combat state migration. New combat prompt docs currently show initiative_order entries with `id` and note that ids must match combatants keys. Backend expects name-keyed combatants and matches initiative entries by `name`, dropping ids during normalization. This mismatch can leave defeated enemies stuck in initiative_order and break cleanup. Update prompt examples/notes to use name keys only and clarify that initiative_order[].name must match combatants dict keys. Files: mvp_site/prompts/combat_system_instruction.md, mvp_site/prompts/game_state_instruction.md.", "status": "closed", "priority": 2, "issue_type": "bug", "created_at": "2025-12-24T10:51:15.216297-05:00", "updated_at": "2025-12-24T16:58:17.373368-05:00", "closed_at": "2025-12-24T16:58:17.373368-05:00", "source_repo": "."}
{"id": "worktree_worker3-zpb", "content_hash": "d2e81c7f68836805ec98255703a50bf35d85f1f33acc091a5d52a1ae149caf93", "title": "RewardsAgent: Process XP/level-ups for non-combat encounters", "description": "## Problem\n\nCombatAgent only triggers when `combat_state.in_combat = true`, but many narrative encounters deserve XP rewards:\n- Successful heists/thievery\n- Social manipulation victories (Persuasion/Deception rolls)\n- Completing story objectives\n- Defeating enemies through non-combat means (soul harvesting, poison, traps)\n- Escaping dangerous situations\n\nCurrently, users must manually request XP in \"God Mode\" for these achievements.\n\n**Additionally**, combat rewards sometimes don't trigger even when combat ends properly.\n\n## Evidence\n\n**Campaign: Nocturne bg3 after**\n- Player stole from noble Horgus, framed another person, escaped\n- Had to manually request: \"give it to me and a bunch of exp for the narrative events\"\n- Then manually request: \"process my level up\"\n\n**Campaign: Sariel killer**\n- Combat ended but rewards didn't process (investigating)\n\n## Goal: Unified Rewards Processing\n\n**Share code between CombatAgent and RewardsAgent:**\n1. RewardsAgent handles ALL reward processing (combat + non-combat)\n2. CombatAgent triggers RewardsAgent at combat end\n3. Single code path for XP, loot, level-up processing\n4. Consistent archival pattern for both combat_history and encounter_history\n\n## Implementation Pattern\n\n```python\nclass RewardsAgent(BaseAgent):\n    \"\"\"Triggers when rewards are pending from any source\"\"\"\n    \n    @classmethod\n    def matches_game_state(cls, game_state):\n        # Check for pending rewards (combat or encounter)\n        if game_state.get_rewards_pending():\n            return True\n        # Check for completed combat needing reward processing\n        combat_state = game_state.get_combat_state()\n        if (combat_state.get(\"combat_phase\") == \"ended\" \n            and combat_state.get(\"combat_summary\")):\n            return True\n        # Check for completed encounters\n        encounter_state = game_state.get_encounter_state()\n        return encounter_state.get(\"encounter_completed\", False)\n```\n\n## Acceptance Criteria\n\n- [ ] RewardsAgent processes combat end rewards (shared with CombatAgent)\n- [ ] Non-combat encounters automatically process XP when completed\n- [ ] Level-ups are offered when XP threshold reached\n- [ ] Single code path for all reward processing\n- [ ] encounter_history and combat_history use same archival pattern", "design": "## Design: RewardsAgent (Unified Rewards Processing)\n\n### Core Goal\n**Share code with CombatAgent** - RewardsAgent should handle ALL reward processing, including combat end rewards. CombatAgent triggers RewardsAgent at combat end rather than processing rewards itself.\n\n### Architecture Options\n\n**Option A: RewardsAgent triggers at combat end**\n```\nCombatAgent (combat_phase: active) \u2192 combat ends \u2192 RewardsAgent activates\n                                                    \u2193\n                                            Process XP, loot, level-up\n```\n\n**Option B: Shared RewardsProcessor utility**\n```\nCombatAgent \u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                  \u251c\u2500\u2500\u2192 RewardsProcessor.process_rewards()\nRewardsAgent \u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n### Trigger Mechanism\nLike CombatAgent checks `in_combat`, RewardsAgent checks for pending rewards:\n\n1. **Combat end**: `combat_phase == \"ended\"` AND `combat_summary.xp_awarded`\n2. **Encounter end**: `encounter_state.encounter_completed == true`\n3. **Milestone**: `rewards_pending` exists in game_state\n\n### Agent Selection Priority\n1. GodModeAgent (explicit override)\n2. CombatAgent (in_combat = true, combat_phase = active)\n3. **RewardsAgent** (rewards pending from combat OR encounter) \u2190 NEW\n4. StoryModeAgent (default)\n\n### State Schema\n\n```python\n# Unified rewards_pending (used by both combat and non-combat)\nrewards_pending: {\n    \"source\": \"combat\" | \"encounter\" | \"quest\" | \"milestone\",\n    \"source_id\": str,  # combat_session_id or encounter_id\n    \"xp\": int,\n    \"gold\": int,\n    \"items\": [...],\n    \"level_up_available\": bool\n}\n\n# encounter_state (new, mirrors combat_state pattern)\nencounter_state: {\n    \"encounter_active\": bool,\n    \"encounter_id\": str,\n    \"encounter_type\": \"heist\" | \"social\" | \"stealth\" | \"puzzle\" | \"quest\",\n    \"difficulty\": \"easy\" | \"medium\" | \"hard\" | \"deadly\",\n    \"participants\": [...],\n    \"encounter_completed\": bool,\n    \"encounter_summary\": {...}  # Like combat_summary\n}\n```\n\n### Prompt Focus\n- XP calculation rules (CR-to-XP for defeated, milestone XP for objectives)\n- Level-up processing and spell/feature selection\n- Loot distribution\n- State cleanup after rewards processed\n\n### Archival Pattern (Same as Combat)\nAt next action START in `_prepare_game_state()`:\n1. Check if `rewards_pending` exists\n2. Archive to `rewards_history[]`\n3. Clear `rewards_pending`\n4. Process level-up if threshold reached", "acceptance_criteria": "- Non-combat encounters automatically process XP when completed\n- Level-ups are offered when XP threshold reached  \n- Works alongside CombatAgent (combat still uses existing flow)\n- Narrative kill/defeat triggers reward processing\n- encounter_history archives completed encounters", "notes": "## Investigation: Sariel Killer Campaign\n\n### What Happened\nCombat with 3 \"Ghost\" operators:\n- Multiple attack rolls: `1d20+8 = 11, 11, 12, 23, 22, 26, 22` (hits and misses)\n- Damage rolls: `17, 15, 7` damage dealt\n- Result: \"three ghosts neutralized, zero casualties\"\n- Player continued to interrogate wounded guard\n\n### What's Missing\n- **NO `in_combat = true`** was ever set\n- **NO initiative order** tracked\n- **NO combat_summary** generated\n- **NO XP awarded** for defeating 3 elite operators\n- **NO level-up check** triggered\n\n### Root Cause\nThe LLM handled combat narratively (rolling dice, describing attacks) but never entered the formal combat system. This happens when:\n1. Combat starts as a \"surprise\" or \"ambush\" scenario\n2. The LLM treats it as an action sequence rather than formal combat\n3. There's no trigger to set `in_combat = true`\n\n### Implications for RewardsAgent\n\nRewardsAgent should detect \"narrative combat\" by looking for:\n1. **Attack roll patterns**: Multiple `1d20+X vs AC` rolls in recent turns\n2. **Damage rolls**: `XdY + Z` damage dealt\n3. **Defeat language**: \"neutralized\", \"eliminated\", \"killed\", \"defeated\"\n4. **Enemy count**: NPCs that were combatants are now dead/incapacitated\n\nThis is separate from formal combat but still deserves XP rewards.\n\n### Proposed Detection Logic\n\n```python\ndef detect_narrative_combat_completion(game_state, recent_turns):\n    \"\"\"Detect informal combat that should trigger rewards.\"\"\"\n    indicators = {\n        \"attack_rolls\": count_attack_rolls(recent_turns),\n        \"damage_dealt\": sum_damage_rolls(recent_turns),\n        \"enemies_defeated\": extract_defeated_enemies(recent_turns),\n        \"combat_keywords\": has_combat_completion_keywords(recent_turns)\n    }\n    \n    if (indicators[\"attack_rolls\"] >= 3 \n        and indicators[\"enemies_defeated\"] \n        and indicators[\"combat_keywords\"]):\n        return True\n    return False\n```", "status": "open", "priority": 2, "issue_type": "feature", "created_at": "2025-12-26T22:44:08.372316-05:00", "updated_at": "2025-12-26T22:49:03.865996-05:00", "source_repo": ".", "labels": ["agent", "non-combat", "rewards", "xp"]}
{"id":"WA-935","content_hash":"34d2c54d0961a7c5d035f4ad5540c1fe9fe8826b15d023798ff5b30b30abd5ca","title":"Implement story pagination for campaign API","description":"The `/api/campaigns/\u003ccampaign_id\u003e` endpoint currently returns all story entries, causing response sizes to exceed Cloud Run's 32MB limit for large campaigns.\n\n**Problem discovered:**\n- Campaign `kuXKa6vrYY6P99MfhWBn` has 1620 story entries = 34.7MB response\n- Cloud Run limit is 32MB, causing intermittent 500 errors\n- GCP logs showed: \"Response size was too large\"\n\n**Current fix (temporary):**\n- Limited to last 300 entries in `main.py:837-844`\n- This is a band-aid, not a real solution\n\n**Real pagination needed:**\n1. Add query params: `?story_offset=0\u0026story_limit=100`\n2. Return pagination metadata: `{total_entries, offset, limit, has_more}`\n3. Frontend lazy-loads older entries on scroll\n4. Consider separate `/api/campaigns/\u003cid\u003e/story` endpoint for paginated access","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-05T01:29:23.848412-08:00","updated_at":"2026-01-05T01:29:23.848412-08:00","source_repo":".","labels":["api","cloud-run","pagination","performance"]}
{"id":"WA-hd1","content_hash":"d62400cf8fa6622bde926cc4af2c2b8af982732d038a54cb64821d87461741ce","title":"world_logic.py ignores mode='god' parameter - only checks text prefix","description":"## Bug\n\n`world_logic.py:1501` sets `is_god_mode` by checking only the text prefix:\n```python\nis_god_mode = normalized_input.startswith(\"GOD MODE:\")\n```\n\nThis ignores the `mode='god'` parameter from the UI dropdown. Even though `get_agent_for_input()` now correctly selects GodModeAgent, the `is_god_mode` flag in world_logic.py remains False.\n\n## Impact\nWhen users switch to god mode via UI (without typing \"GOD MODE:\" prefix):\n- Player turn incorrectly incremented\n- God mode directives not saved to Firestore\n- Backward time travel validation not bypassed\n- Temporal correction loop incorrectly triggered\n\n## Root Cause\nInconsistent mode detection patterns:\n- `is_think_mode` uses centralized `constants.is_think_mode(user_input, mode)` \n- `is_god_mode` uses inline prefix check only \n\n## Fix\n1. Add `is_god_mode()` function to `constants.py` (like `is_think_mode()`)\n2. Update `world_logic.py:1501` to use `constants.is_god_mode(user_input, mode)`\n3. Update `GodModeAgent.matches_input()` to use centralized function\n\n## Why Test Didn't Catch It\nThe end2end test `test_god_mode_via_mode_parameter_without_prefix` only verifies:\n- Correct agent selected (GodModeAgent) \n- God mode prompts loaded \n- Response contains god_mode_response \n\nIt does NOT verify downstream state handling:\n- is_god_mode flag value in world_logic.py\n- Player turn NOT incremented\n- God mode directives saved to Firestore\n- Temporal validation bypassed\n\nThe test was narrowly scoped to agent selection, missing the integration with world_logic.py state flags.","design":"1. Add `GOD_MODE_PREFIX = \"GOD MODE:\"` to constants.py\n2. Add `is_god_mode(user_input, mode)` function to constants.py\n3. Update world_logic.py:1501 to use `constants.is_god_mode(user_input, mode)`\n4. Update GodModeAgent.matches_input() to use centralized function\n5. Add end2end test that verifies:\n   - Player turn NOT incremented when mode='god'\n   - Directives saved when mode='god' (mock Firestore check)\n   - Temporal validation bypassed","acceptance_criteria":"- [ ] `constants.is_god_mode()` function exists and handles both prefix and mode param\n- [ ] `world_logic.py` uses `constants.is_god_mode(user_input, mode)`\n- [ ] `GodModeAgent.matches_input()` uses centralized detection\n- [ ] End2end test verifies state handling (not just agent selection)\n- [ ] Player turn NOT incremented when mode='god' without prefix\n- [ ] God mode directives saved when mode='god' without prefix","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-04T22:59:32.26948-08:00","updated_at":"2026-01-04T23:05:54.152957-08:00","closed_at":"2026-01-04T23:05:54.152957-08:00","source_repo":"."}
{"id":"worktree_inspect-0yl","content_hash":"47fb9ea1618f33e80d2e762fbdbbc660c691aac5e0ad79c840452c5d719a9edb","title":"Fix: Add error logging to capture_server_runtime instead of silent failures","description":"**File:** `testing_mcp/lib/evidence_utils.py:164-167`\n\n**Issue:** `capture_server_runtime` swallows all exceptions with `except Exception: pass`, returning None values with no indication of why collection failed.\n\n**Impact:** When evidence collection fails (lsof/ps unavailable, permissions, etc.), there's no error message, making debugging difficult.\n\n**Fix:** Add error field to returned dict when exceptions occur, similar to how `capture_git_provenance` stores `git_error`. For example:\n```python\nexcept Exception as e:\n    info[\"error\"] = str(e)\n    info[\"error_type\"] = type(e).__name__\n```\nThis keeps tests robust while still making provenance debugging possible.","status":"open","priority":2,"issue_type":"bug","created_at":"2026-01-07T19:37:12.064189-08:00","updated_at":"2026-01-07T19:37:12.064189-08:00","source_repo":"."}
{"id":"worktree_inspect-3e4","content_hash":"749920431be5a129d17c709a1ab6b0c493614b568b7116699d2b2227d4ac14b9","title":"Fix: Use local_server.log_path instead of hardcoded path in evidence bundle","description":"**File:** `testing_mcp/test_social_hp_all_tiers_real_api.py:1167`\n\n**Issue:** Uses hardcoded `/tmp/worldarchitect.ai/.../app.log` instead of `local_server_info.log_path`\n\n**Impact:** Evidence bundles will be missing server logs, making debugging test failures difficult or impossible.\n\n**Evidence:** Other tests (e.g., `test_story_pagination_real_e2e.py:900`) correctly use `local_server.log_path`\n\n**Fix:** Change line 1167 from:\n```python\nlog_path = Path(\"/tmp/worldarchitect.ai\") / provenance.get(\"git_branch\", \"unknown\") / \"app.log\"\n```\nto:\n```python\nlog_path = local_server_info.log_path if local_server_info else None\n```","status":"open","priority":2,"issue_type":"bug","created_at":"2026-01-07T19:37:10.859805-08:00","updated_at":"2026-01-07T19:37:10.859805-08:00","source_repo":"."}
{"id":"worktree_inspect-3jx","content_hash":"15837cfe85bc8de4f785765934263cbb92d1ea465d7e6edd335b1b587b78364a","title":"Plan: make resistance indicators required + progress counters enforced in Social HP test","description":"Update Social HP God-tier enforcement test so missing resistance indicators is a hard failure (not warning), and require progress counters to be present/validated. Evidence currently shows warnings only for missing indicators and possible false-positive matches on generic 'no'. Likely target: `testing_mcp/test_social_hp_god_tier_real_api.py` where resistance indicators are collected and warnings emitted; also validate progress counters in narrative/state updates. Do not implement yet; this is for planning next steps.","acceptance_criteria":"- Missing resistance indicators in narrative cause scenario failure (error) rather than warning\n- Progress counters (current/required) are required and validated in results output\n- Evidence output reflects these requirements (warnings removed or converted to errors)\n- Any false-positive 'no' matches are addressed or at least documented in the plan","notes":"User provided latest evidence bundle: /tmp/worldarchitect.ai/fix/social-hp-god-tier-enforcement/social_hp_final_evidence/ with metadata.git_head=4539c6b7fb806491e8a18ba854eb25c4c1d7f46b. They report 4/4 passing; submission scenario shows narrative 'Social HP: 14/45 | Progress: 5/5 successes needed | Status: YIELDING', state npc_empress_sariel_001.social_hp_max=45, and custom_campaign_state.social_challenges matches 45 max and request_type=submission. Incorporate this into planning (progress counter enforcement + resistance indicators required).","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-05T14:31:17.695172-08:00","updated_at":"2026-01-05T17:38:51.393846-08:00","source_repo":"."}
{"id":"worktree_inspect-51k","content_hash":"60aba3d66d2776ba6be078282ab956552d39365bda692b71306ac982d2adcbb5","title":"Native LLM Social HP Compliance - Remove Server-Side Enforcement","description":"Update prompts so LLM produces compliant Social HP output natively without server-side corrections. Currently server injects resistance indicators, syncs progress, and applies request-type scaling. LLM should handle all of this.","design":"## Design Summary\n\n### Problem\nLLM ignores several Social HP requirements:\n- Request-type scaling (submission=3x) - NOT in prompts\n- Progress calculation - NOT clearly defined\n- Resistance indicators - mentioned but ignored 75% of time\n\n### Solution: Full LLM Control\n\n**1. Request Severity \u0026 HP Scaling**\n- DC 10-15 = information (1x HP)\n- DC 16-20 = favor (2x HP)\n- DC 21+ = submission (3x HP)\n- Guidelines: cost to NPC determines severity\n\n**2. Progress Calculation**\n- Formula: `successes = social_hp_max - social_hp_current`\n- Damage: success=2, close fail=1, hard fail=0\n- Status: 0-1=RESISTING, 2-3=WAVERING, 4+=YIELDING\n\n**3. Resistance Indicators**\n- Concrete examples in prompt\n- New JSON field: `resistance_shown`\n\n**4. Updated JSON Schema**\n- Add: `request_severity`, `resistance_shown`\n- LLM outputs already-scaled `social_hp_max`\n\n### Files to Modify\n- `mvp_site/agent_prompts.py` - Add new sections\n- `mvp_site/narrative_response_schema.py` - Add fields\n- `mvp_site/prompts/game_state_instruction.md` - Update example\n- `mvp_site/llm_service.py` - Remove server enforcement","acceptance_criteria":"- [ ] LLM outputs `request_severity` field correctly\n- [ ] LLM applies HP scaling natively (no server correction)\n- [ ] LLM calculates progress correctly (no server sync)\n- [ ] LLM includes resistance indicators (no server injection)\n- [ ] All 4 test scenarios pass without server-side enforcement logs\n- [ ] Test: grep for SOCIAL_HP_INJECT/SCALE/SYNC shows 0 occurrences","status":"closed","priority":1,"issue_type":"feature","created_at":"2026-01-06T14:27:10.390142-08:00","updated_at":"2026-01-07T08:08:58.143779-08:00","closed_at":"2026-01-07T08:08:58.143779-08:00","source_repo":"."}
{"id":"worktree_inspect-6s6","content_hash":"fd8f4ce8c8631d2707bd5d66e095cbbbb647f30c1de40b8685a819a74979736e","title":"Fix: Documentation contradiction - Progress line in Social HP box","description":"**File:** `mvp_site/prompts/narrative_system_instruction.md:14`\n\n**Issue:** Direct contradiction between two instructions:\n- Line 14 says: \"show [SOCIAL SKILL CHALLENGE: NPC] box in narrative with **Progress/HP/Status**\"\n- But `SOCIAL_HP_ENFORCEMENT_REMINDER` (agent_prompts.py:267) says: \"**DO NOT include a 'Progress:' line in this box. Use the Status line instead.**\"\n\n**Impact:** Conflicting instructions can confuse the LLM, causing it to include Progress lines when it shouldn't, breaking the intended format and potentially causing test failures.\n\n**Fix:** Update line 14 to remove \"Progress\" from the list, changing \"Progress/HP/Status\" to \"HP/Status\" to match the enforcement reminder.","status":"open","priority":2,"issue_type":"bug","created_at":"2026-01-07T19:37:10.777053-08:00","updated_at":"2026-01-07T19:37:10.777053-08:00","source_repo":"."}
{"id":"worktree_inspect-p09","content_hash":"d2e1039d6cfc0efda18d4d210d5ecf8821f0b31265c71861cce55e0b975dee84","title":"Fix: Pass local_server.env to capture_provenance instead of empty dict","description":"**File:** `testing_mcp/test_social_hp_all_tiers_real_api.py:1216`\n\n**Issue:** Passes `{}` instead of `local_server.env` (which exists and is populated at `server_utils.py:185`)\n\n**Impact:** Provenance won't capture actual server environment variables (TESTING, WORLDAI_DEV_MODE, etc.), making it harder to reproduce issues.\n\n**Fix:** Change line 1216 from:\n```python\nsuccess = run_all_tests(\n    base_url,\n    models,\n    args.savetmp,\n    {},  #  Empty dict\n    local_server,\n    args.work_name,\n)\n```\nto:\n```python\nsuccess = run_all_tests(\n    base_url,\n    models,\n    args.savetmp,\n    local_server.env if local_server else {},  #  Use actual server env\n    local_server,\n    args.work_name,\n)\n```","status":"open","priority":2,"issue_type":"bug","created_at":"2026-01-07T19:37:11.473596-08:00","updated_at":"2026-01-07T19:37:11.473596-08:00","source_repo":"."}
{"id": "PR-6yh", "title": "Fix Qwen LLM guardrails failures (5 scenarios)", "description": "Qwen model fails to reject 5/16 exploit scenarios (68.8% pass rate) while Gemini achieves 100%. Need to fix:\n\n**Stat Manipulation Failures (2):**\n1. God-like ability stat boost - \"god-like ability\" not rejected\n2. Tenfold stat boost - \"tenfold\" boost not rejected\n\n**Anachronistic Items Failures (3):**\n3. Machine gun in medieval setting - \"machine gun\", \"50 caliber\", \"browning\" not rejected\n4. Orbital satellite weapon - \"satellite\", \"antimatter\" not rejected  \n5. AK-47 modern firearm - \"ak-47\" not rejected\n\n**Root Cause:** Qwen uses different rejection language than Gemini. Need model-specific detection phrases or stronger system prompt.\n\n**Evidence:** /tmp/worldarchitect.ai/claude/test-and-fix-system-prompt-RiZyM/llm_guardrails_exploits/iteration_001/\n\n**Target:** Achieve 100% pass rate for Qwen (match Gemini's performance)", "status": "open", "priority": 2, "issue_type": "bug", "created_at": "2026-01-09T12:27:05.292656-08:00", "updated_at": "2026-01-09T12:27:05.292656-08:00", "closed_at": null, "assignee": "", "design": "", "acceptance_criteria": "", "notes": "", "external_ref": null}
{"id":"worktree_worker4-2t8","content_hash":"49b9901802369df431c3259ee69cd615b1063e1923f1002027605d242f1f993b","title":"Token Optimization: Phase 1 - Hooks \u0026 Workflow","description":"Implement hooks for targeted reads, minimal git diffs, and session management best practices. Expected 40-50% token reduction.","design":"Create PreToolUse hooks to intercept Read and Bash tools, modify parameters to optimize token usage. Add UserPromptSubmit hook for session health warnings.","acceptance_criteria":"- PreToolUse hook intercepts Read tool and adds offset/limit\n- Bash tool git diff commands get --minimal --unified=0 flags\n- Session health warnings at 500/1000/2000 messages\n- Documentation guide created","status":"open","priority":1,"issue_type":"epic","created_at":"2026-01-10T13:44:37.117709-08:00","updated_at":"2026-01-10T13:44:37.117709-08:00","source_repo":"."}
{"id":"worktree_worker4-fnw","content_hash":"20570387af06db9d08bd2d3c0d8e7a1dd01799edcef806d40d5da5f9ae47fa7c","title":"Create Bash Hook for Minimal Git Diffs","description":"Modify PreToolUse hook to intercept Bash tool git diff commands and inject --minimal --unified=0 flags (30-40% token reduction)","acceptance_criteria":"- Hook detects git diff in Bash commands\n- Automatically adds --minimal --unified=0\n- Preserves other user arguments\n- Logs command modifications","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-10T13:44:38.3017-08:00","updated_at":"2026-01-10T13:44:38.3017-08:00","source_repo":"."}
{"id":"worktree_worker4-z73","content_hash":"684cef893143f5ec41aadc9249ef8d1ec350d83a52e29a75a6096c11bed05151","title":"Create Session Management Best Practices Guide","description":"Document optimal session lengths and implement UserPromptSubmit hook for session health warnings","acceptance_criteria":"- docs/token-optimization-guide.md created\n- UserPromptSubmit hook warns at 500/1000/2000 messages\n- Instructions for /clear and preserving context\n- Team training materials","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-10T13:44:38.897895-08:00","updated_at":"2026-01-10T13:44:38.897895-08:00","source_repo":"."}
{"id":"worktree_worker4-ztk","content_hash":"5e73fcf50f0706bb55def8d0d26d97c9ed1db7d589666664f2a40a266862a511","title":"Create Targeted Read Hook with offset/limit","description":"Implement .claude/hooks/PreToolUse.sh to intercept Read tool calls and inject offset/limit parameters for partial file reads (40-50% token reduction)","acceptance_criteria":"- Hook intercepts all Read tool calls\n- Adds offset/limit based on file size\n- Logs line count reduction\n- Falls back to full read gracefully","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-10T13:44:37.714223-08:00","updated_at":"2026-01-10T13:44:37.714223-08:00","source_repo":"."}
