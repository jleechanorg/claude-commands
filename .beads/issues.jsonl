{"id":"worktree_worker4-2ar","content_hash":"da4e136148b96debf310172545d30b50823e5aea7e0db097704ec3d0e1f2382b","title":"Time monotonicity validation uses mutated reference, fails to detect backward time","description":"Observed in new validation flow added to process_action_unified, GOD_MODE_SET, and GOD_MODE_UPDATE_STATE. Code captures `original_world_time` as a reference to `current_game_state.to_dict()['world_data']['world_time']` then passes the same dict into `update_state_with_changes`, which mutates it in place. As a result `original_world_time` is mutated to the new time before `validate_game_state_updates` runs, so comparisons see identical values and backward time regressions are never flagged. This leaves the temporal regression defect unfixed despite added validation.\n\nRisk: High — timeline regressions still silently persist; user-facing stories can move time backwards without warning. Affects all API paths updated in this PR.\n\nSuggested fix:\n- Deep copy world_time (or full world_data) before merging changes so `original_world_time` remains the pre-update snapshot.\n- Add regression test that simulates world_time moving backwards and asserts a warning/flag is produced.\n\nFiles/lines: mvp_site/world_logic.py:896-912, 1801-1820, 1872-1892.","status":"open","priority":1,"issue_type":"bug","created_at":"2025-12-16T20:39:06.795703-08:00","updated_at":"2025-12-16T20:39:06.795703-08:00","source_repo":"."}
{"id":"worktree_worker4-6on","content_hash":"9bac54d641549a53e9892cfb33d802d376a6bd8e85498afa6431c3716ea76c29","title":"Create compressible entity summaries at multiple detail levels","description":"Generate entity summaries at 3 compression levels during campaign creation:\n- Full: Complete backstory, relationships, speech patterns (500 tokens)\n- Medium: Key traits, current goal, player relationship (200 tokens)\n- Minimal: Name, role, one-liner (50 tokens)\n\nSelect level based on available token budget and entity importance score.\n\nRequires changes to entity data model and entity_preloader.py.","status":"open","priority":3,"issue_type":"feature","created_at":"2025-12-07T23:13:16.396242-05:00","updated_at":"2025-12-07T23:13:16.396242-05:00","source_repo":".","labels":["architecture","context-budget","entity-tracking"],"dependencies":[{"issue_id":"worktree_worker4-6on","depends_on_id":"worktree_worker4-a76","type":"blocks","created_at":"2025-12-07T23:13:27.51776-05:00","created_by":"daemon"}]}
{"id":"worktree_worker4-78a","content_hash":"baf96f41f2c49d813ad8a79c2075eeb3cbcbccefb6663ba47c2dbd94abd72bb1","title":"Test auth bypass (X-Test-Bypass-Auth) removed breaks CI","description":"Removed X-Test-Bypass-Auth in mvp_site/main.py Lines 334-335, 331-382 breaks test suite. CI/CD cannot run tests.","status":"open","priority":1,"issue_type":"bug","created_at":"2025-12-01T00:21:45.843348-08:00","updated_at":"2025-12-01T00:21:45.843348-08:00","source_repo":".","labels":["P0","blocks-testing","pr-2082"]}
{"id":"worktree_worker4-79n","content_hash":"d8e3064fe38da61f2a5ca6f7506144b3c6fe9c05a5b86c2d8908a977d9a4d9df","title":"Unify user settings defaults in one place","description":"main.py and world_logic.py both set default LLM provider/model values. Create a single source (e.g., world_logic.get_user_settings_unified) and have main.py delegate to avoid drift.","status":"closed","priority":3,"issue_type":"chore","assignee":"Cerebras","created_at":"2025-11-30T22:32:52.81325-08:00","updated_at":"2025-12-01T00:21:50.006342-08:00","closed_at":"2025-12-01T00:21:50.006342-08:00","source_repo":"."}
{"id":"worktree_worker4-7wz","content_hash":"c0a2938106955b30fe68330be98491f7ce016719426aefad29da8689011b8476","title":"Rate limiter IP spoofing vulnerability - uses load balancer IP","description":"mvp_site/main.py Lines 235-236, 246-253 uses load balancer IP instead of client IP. All users share one rate limit bucket causing global DoS. Fix: Use X-Forwarded-For with ProxyFix.","status":"open","priority":1,"issue_type":"bug","created_at":"2025-12-01T00:21:45.844193-08:00","updated_at":"2025-12-01T00:21:45.844193-08:00","source_repo":".","labels":["P0","pr-2082","security"]}
{"id":"worktree_worker4-7y4","content_hash":"872bc7a73ca6d6142cec00467235c0be0093ec51aca2b41b023f6ec76245b04e","title":"Refactor duplicate MCP HTTP handlers into single handler","description":"mvp_site/mcp_api.py defines both DualMCPHandler and MCPHandler with overlapping /health and /mcp logic. Consolidate into one handler class to reduce maintenance risk.","status":"closed","priority":3,"issue_type":"chore","assignee":"c1","created_at":"2025-11-30T22:32:48.55523-08:00","updated_at":"2025-12-01T00:21:45.850224-08:00","closed_at":"2025-12-01T00:21:45.850224-08:00","source_repo":"."}
{"id":"worktree_worker4-8k9","content_hash":"d20e526e3efa12f718099764f2e45f99ce5d2f80cf82b9809dbed62f342838ad","title":"Flask-Limiter dependency missing from requirements.txt","description":"flask_limiter imported in mvp_site/main.py Line 79 but not in requirements.txt. Deployment will fail with ImportError.","status":"open","priority":1,"issue_type":"bug","created_at":"2025-12-01T00:21:45.844663-08:00","updated_at":"2025-12-01T00:21:45.844663-08:00","source_repo":".","labels":["P0","blocks-deployment","pr-2082"]}
{"id":"worktree_worker4-9u7","content_hash":"458c8a856c72c924d062f5ae0c77b09d2a3e667e13ecd4e843c7fb95b14eae03","title":"Multiple validation error types support (V2 feature)","description":"mvp_site/validation_recovery.py Lines 105-126 only extracts ONE HP error type. Current design intentional - handles one error type per response. Future enhancement to support multiple different error types.","status":"closed","priority":3,"issue_type":"feature","created_at":"2025-12-01T00:21:45.845173-08:00","updated_at":"2025-12-01T00:21:45.845173-08:00","closed_at":"2025-11-23T15:59:09.608643-08:00","source_repo":".","labels":["P3","future","pr-2082"]}
{"id":"worktree_worker4-a2c","content_hash":"fe9ed8e999400536d002a6567eaf47232070c3af0ad9d9bc1765d4f02f239d6f","title":"S1 outage \u0026 PR #2327 merge readiness","description":"Track S1 preview 404 outage and merge readiness for PR #2327. Steps: restore S1 availability, rerun mature campaign VqqJLpABua9bvAG4ArTg with the fix; capture narrative and token logs; if S1 stays down, document local proof and risk for merge decision.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-08T23:26:44.363042-05:00","updated_at":"2025-12-08T23:29:58.912143-05:00","closed_at":"2025-12-08T23:29:58.912143-05:00","source_repo":".","labels":["context-budget","infra","release"]}
{"id":"worktree_worker4-a76","content_hash":"af04726d4974e39aa3037cacbacbddede1861562c46a7498088c075fcf5b4578","title":"Add entity_tracking token measurement logging","description":"Add logging to measure actual entity_tracking_data token count before API call. This is needed to validate the hypothesis that entity_tracking exceeds its 10,500 token reserve.\n\nAdd after line 3342 in llm_service.py:\n```python\nentity_tracking_tokens = estimate_tokens(json.dumps(entity_tracking_data))\nlogging_util.info(f\"ENTITY_TRACKING_SIZE: {entity_tracking_tokens}tk (reserve: {ENTITY_TRACKING_TOKEN_RESERVE}tk)\")\n```\n\nThis is a prerequisite for all other entity truncation work.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-07T23:13:15.268259-05:00","updated_at":"2025-12-08T23:41:10.171336-05:00","closed_at":"2025-12-08T23:41:10.171336-05:00","source_repo":".","labels":["context-budget","logging","quick-win"]}
{"id":"worktree_worker4-cho","content_hash":"47fb45242cea0c8895e3ddccff93938f526a199c4be9eb01568c5cedf29b0236","title":"Optimize dual-pass entity generation for cost efficiency","description":"The dual-pass entity generation system triggers 2 extra LLM API calls (~118k tokens, ~11 seconds) for marginal benefit (recovering 1 entity). Pass 1 often produces worse results than the original response. Need to either: raise the trigger threshold, skip Pass 1, use original response as base, or remove the feature entirely.","design":"Options:\nA) Skip Pass 1 entirely - go direct to entity injection\nB) Raise trigger threshold from 66% to 50%\nC) Use original response as base instead of regenerating\nD) Remove dual-pass feature entirely\n\nFiles: mvp_site/dual_pass_generator.py, mvp_site/llm_service.py (lines 2530-2560), mvp_site/entity_validator.py\n\nPrompt file: ~/Downloads/fix-dual-pass-efficiency.md","acceptance_criteria":"1. Reduce unnecessary API calls when entity coverage \u003e60%\n2. Pass 1 should not produce worse results than original\n3. Add metrics logging for dual-pass effectiveness\n4. Unit tests for threshold changes","status":"open","priority":2,"issue_type":"task","created_at":"2025-11-30T19:14:36.361775-08:00","updated_at":"2025-11-30T19:14:36.361775-08:00","source_repo":".","labels":["cost-reduction","llm","optimization"]}
{"id":"worktree_worker4-clg","content_hash":"13a32a19e2b6f00f6d092f2c15d47ff6d22ea6fd617db4be3a34aafa140a1895","title":"Remove dead full_prompt code in continue_story","description":"The `full_prompt` variable built at lines 3319-3327 in llm_service.py is never used. The actual API call uses LLMRequest instead.\n\nThis dead code:\n1. Wastes CPU cycles building unused string\n2. Confuses maintainers about what's actually sent\n3. Includes timeline_log which caused the wrong hypothesis\n\nDelete lines 3319-3327 and any related dead code.","status":"closed","priority":2,"issue_type":"chore","created_at":"2025-12-07T23:13:17.262877-05:00","updated_at":"2025-12-08T23:41:09.682402-05:00","closed_at":"2025-12-08T23:41:09.682402-05:00","source_repo":".","labels":["cleanup","tech-debt"]}
{"id":"worktree_worker4-fsr","content_hash":"13bd91906ae1bc04156e494033562c9f527fb73a50737560f15f81fe7571f43b","title":"Add response_json_schema to Gemini provider for structured output enforcement","description":"Gemini provider currently only uses response_mime_type: \"application/json\" which guarantees valid JSON syntax but does NOT enforce schema structure. Add response_json_schema parameter to enforce NarrativeResponse schema like we did for Cerebras in PR #2377.","design":"File: mvp_site/llm_providers/gemini_provider.py\n\nCurrent (line 62-67):\n```python\ngeneration_config_params = {\n    \"max_output_tokens\": json_mode_max_output_tokens,\n    \"temperature\": temperature,\n    \"safety_settings\": safety_settings,\n    \"response_mime_type\": \"application/json\",\n}\n```\n\nTarget:\n```python\ngeneration_config_params = {\n    \"max_output_tokens\": json_mode_max_output_tokens,\n    \"temperature\": temperature,\n    \"safety_settings\": safety_settings,\n    \"response_mime_type\": \"application/json\",\n    \"response_json_schema\": NARRATIVE_RESPONSE_SCHEMA,  # Add schema\n}\n```\n\nReference: https://ai.google.dev/gemini-api/docs/structured-output","acceptance_criteria":"- [ ] Add NARRATIVE_RESPONSE_SCHEMA constant matching Cerebras schema\n- [ ] Add response_json_schema to generation_config_params\n- [ ] Write TDD tests for schema enforcement\n- [ ] Verify Gemini still works with schema (no API errors)\n- [ ] Monitor for reduced planning_block failures","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-10T01:51:33.747212-05:00","updated_at":"2025-12-10T02:11:39.468712-05:00","closed_at":"2025-12-10T02:11:39.468712-05:00","source_repo":".","labels":["gemini","json-schema","llm-provider"]}
{"id":"worktree_worker4-ii5","content_hash":"215c1d2cae128fd8da7a52817036a963303a5eaa58282d8612583a3b473baa50","title":"Update RCA/docs to reflect story_history metadata as root cause","description":"Revise investigation docs (context_overflow* and timeline_log_claims) to correct the root cause: story_history metadata bloat, not entity tracking or timeline_log. Remove/replace the 4x entity reserve claim, summarize real measurements (story_history ~70K -\u003e ~26K; entity_tracking ~47), and note current mitigation (ESSENTIAL_STORY_FIELDS stripping, npc_data excluded).","status":"closed","priority":2,"issue_type":"chore","created_at":"2025-12-08T23:27:51.916027-05:00","updated_at":"2025-12-08T23:35:14.564125-05:00","closed_at":"2025-12-08T23:35:14.564125-05:00","source_repo":".","labels":["context-budget","docs","rca"]}
{"id":"worktree_worker4-jqy","content_hash":"4390a39d73be649752981a54c255c2b984c9dd9c64ea7ab3c7a5865982b40372","title":"Add XSS security warning to god mode documentation","description":"Example code in docs/god_mode_validation_recovery.md Lines 58-74 and docs/god_mode_implementation_complete.md Lines 173-189 uses innerHTML without sanitization. Add disclaimer about using textContent/DOMPurify in production.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-01T00:21:45.845625-08:00","updated_at":"2025-12-01T00:21:45.845625-08:00","source_repo":".","labels":["P2","documentation","pr-2082"]}
{"id":"worktree_worker4-kln","content_hash":"ecc6e5dfff0899cf893e5af1f95d3ef629a004b755ec792d4645cf62258abcc5","title":"Inline re import violation in validation_recovery.py","description":"import re inside method at mvp_site/validation_recovery.py Line 69-70 violates CLAUDE.md standards. Must move to module level.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-01T00:21:45.846045-08:00","updated_at":"2025-12-01T00:21:45.846045-08:00","closed_at":"2025-11-23T15:59:06.173342-08:00","source_repo":".","labels":["P1","pr-2082","standards"]}
{"id":"worktree_worker4-ms2","content_hash":"927bccbd07c23cb84f7488357dfd9b07e18a81fd0fbb22a94f2d8fd782861f6e","title":"Document rate limiter memory storage limitation","description":"memory:// storage at mvp_site/main.py Lines 235-236 not suitable for multi-worker production. Add comment explaining dev-only limitation.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-01T00:21:45.846505-08:00","updated_at":"2025-12-01T00:21:45.846505-08:00","source_repo":".","labels":["P2","documentation","pr-2082"]}
{"id":"worktree_worker4-od8","content_hash":"ca19735c308129187d30efeed5097356bea43fdd7df7d88e79626bfdfcf5f947","title":"Implement tiered entity importance system","description":"Create a scoring system to prioritize entities by relevance:\n- +10 if mentioned in player's current input\n- +5 if appeared in last 3 turns  \n- +3 if in current location\n- +1 if in active quest\n\nOnly include top N entities in entity_tracking_data based on score.\n\nThis is a medium-sized refactor affecting entity_preloader.py and llm_service.py.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-07T23:13:15.870699-05:00","updated_at":"2025-12-07T23:13:15.870699-05:00","source_repo":".","labels":["architecture","context-budget","entity-tracking"],"dependencies":[{"issue_id":"worktree_worker4-od8","depends_on_id":"worktree_worker4-a76","type":"blocks","created_at":"2025-12-07T23:13:26.924903-05:00","created_by":"daemon"}]}
{"id":"worktree_worker4-rys","content_hash":"0970327054deaee612b5e730debe8824ed6726426049eecd0299eca5dbebd07b","title":"Evaluate PR #2384 and cherry-pick decision","description":"Review PR https://github.com/jleechanorg/worldarchitect.ai/pull/2384 (schema enforcement, provider fixes) and decide whether to cherry-pick onto fix/cerebras-json-schema. Summarize benefits/risks and action taken.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T03:23:01.195448-05:00","updated_at":"2025-12-10T03:24:28.701628-05:00","closed_at":"2025-12-10T03:24:28.701628-05:00","source_repo":".","labels":["decision","pr-2384","structured-output"]}
{"id":"worktree_worker4-thg","content_hash":"774950eb3f021eed94654080309e5592d62161f43334909a4c8145c91b3c46a6","title":"Investigate Cerebras empty narrative / {\"type\":\"object\"} responses","description":"Reproduce and debug the Cerebras (zai-glm-4.6) empty narrative issue where raw response is {\"type\":\"object\"}. Determine if parsing, provider bug, or prompt change with stripped story_history. Try provider swap (Gemini) for comparison, capture raw response bodies, and propose mitigation (fallback provider or response validation).","notes":"Partial finding: Empty `{\"type\":\"object\"}` responses are TRANSIENT.\n\nEvidence:\n- Same campaign (VqqJL) tested twice on S1\n- First test (02:37 UTC): narrative_len=0, raw_response=`{\"type\":\"object\"}`\n- Second test (04:28 UTC): narrative_len=1876 ✅\n\nThis is NOT a code bug - it's intermittent Cerebras API behavior. Consider:\n1. Adding retry logic on empty/malformed responses\n2. Response validation before accepting\n3. Fallback to Gemini if response is garbage\n\nKeep open to implement mitigation.","status":"open","priority":2,"issue_type":"bug","created_at":"2025-12-08T23:28:00.495572-05:00","updated_at":"2025-12-08T23:29:59.875629-05:00","source_repo":".","labels":["cerebras","llm-response","regression"]}
{"id":"worktree_worker4-vdz","content_hash":"f01a584de551e46355d79e6b117358cf73fb41488c05468fc499b09e8f5186ed","title":"Unsafe type conversion in validation_recovery.py crashes recovery","description":"Direct int() casts without try/except at mvp_site/validation_recovery.py Lines 116-156 will crash on invalid types. Add try/except for defensive conversion.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-01T00:21:45.846924-08:00","updated_at":"2025-12-01T00:21:45.846924-08:00","closed_at":"2025-11-23T15:59:07.890132-08:00","source_repo":".","labels":["P1","crashes","pr-2082"]}
{"id":"worktree_worker4-z5h","content_hash":"fb268bc69b8f7deb89048e44b851b0909673b9e75f1c717b1f92e642326d20e4","title":"Verify context fix \u0026 narrative on VqqJL campaign (dev vs s1)","description":"Reproduce the mature campaign VqqJLpABua9bvAG4ArTg turn on both dev and s1 with the latest context-stripping code. Capture actual request payload token breakdowns (story_history, entity_tracking, game_state, total) and provider raw responses. Confirm non-empty narrative/choices with the same provider. Clarify whether npc_data is excluded in the request or re-added later. Confirm dev deploy is the same commit as s1.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-08T23:26:39.762707-05:00","updated_at":"2025-12-08T23:29:59.403891-05:00","closed_at":"2025-12-08T23:29:59.403891-05:00","source_repo":".","labels":["context-budget","entity-tracking","regression"]}
{"id":"worktree_worker4-zca","content_hash":"928e8f023cae49fa1b29b50e01181d66a272671ded7c2dde83e8c6ee87213b6f","title":"Instrument and capture request payloads for budget checks","description":"Add or run instrumentation to persist per-run token breakdowns and serialized LLMRequest payloads for targeted campaigns (including VqqJL) across dev and s1. Goal: attach actual request bodies and token counts (story_history, entity_tracking, game_state, total) to beads, not just log excerpts. Provide a repeatable script/command to gather these snapshots.","notes":"**COMPLETED: S1 payload captured and documented**\n\n**Artifact:** `/tmp/worldarchitect.ai/continue_camp5/s1_payload_capture.json`\n\n**Content summary:**\n```json\n{\n  \"success\": true,\n  \"narrative_len\": 1531,\n  \"sequence_id\": 138,\n  \"planning_choices\": [\"depart_immediately\", \"examine_equipment_closer\", ...]\n}\n```\n\n**Repeatable command:**\n```bash\ncurl -s -X POST https://mvp-site-app-s1-754683067800.us-central1.run.app/mcp \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"tools/call\",\"params\":{\"name\":\"process_action\",\"arguments\":{\"campaign_id\":\"VqqJLpABua9bvAG4ArTg\",\"user_id\":\"vnLp2G3m21PJL6kxcuAqmWSOtm73\",\"user_input\":\"What do I see?\"}}}'\n```\n\n**Token breakdown from logs:**\n```\nENTITY_TRACKING_SIZE: 47tk (reserve was 10500tk)\nGAME_STATE_BREAKDOWN: npc_data=162tk (EXCLUDED), world_data=77tk, player_data=109tk\nLLMREQUEST_PAYLOAD: story_history=26684tk, total_payload=30776tk\n```","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-08T23:27:56.214509-05:00","updated_at":"2025-12-09T09:50:18.473082-05:00","closed_at":"2025-12-08T23:35:14.062806-05:00","source_repo":".","labels":["context-budget","instrumentation","observability"]}
