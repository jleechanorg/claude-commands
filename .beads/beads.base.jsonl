{"id":"WA-1","content_hash":"535f70bf87d903f6a899075a38786208e6bed7698650f9c079fc6e63c828d46c","title":"Context Budget Allocation: No Auto-Fallback, Add Middle Compaction","description":"Track context budget allocation decisions and prevent regression.\n\n## Architecture Decision: NO AUTO-FALLBACK\nAuto-fallback to larger models was explicitly removed in PR #2311. Reasons:\n1. Cost unpredictability - larger models cost more\n2. Voice inconsistency - different models have different personalities\n3. Latency variance - larger contexts = slower responses\n4. Proper solution is adaptive truncation, not model switching\n\nIf ContextTooLargeError occurs, improve truncation logic instead.\n\n## Current Allocation\n- Model Context (100%)\n  - Safe Budget (90%)\n    - Output Reserve (20%)\n    - Max Input (80%)\n      - Scaffold (~15-20%)\n      - Entity Reserve (10.5K fixed)\n      - Story Budget (~50-60%)\n        - Start (25%)\n        - Middle (DROPPED - needs work)\n        - End (70%)\n        - Marker (5%)\n\n## Missing: Middle Compaction\nCurrently middle turns are completely dropped. Should:\n1. Summarize plot-critical events from middle\n2. Use importance scoring to select what to summarize\n3. Target ~5-10% of story budget for middle summary\n\n## Components Needing % Targets\n- [ ] System instruction: target 5-8K tokens\n- [ ] Game state JSON: target 2-4K tokens\n- [ ] Entity tracking: currently 10.5K fixed, could be dynamic\n- [ ] Story history: start/middle/end percentages","acceptance_criteria":"- [ ] Code documentation in llm_service.py prevents fallback additions\n- [ ] Middle compaction feature designed\n- [ ] All context components have documented % targets\n- [ ] No ContextTooLargeError in production logs","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-04T14:03:49.392479-08:00","updated_at":"2025-12-04T14:03:49.392479-08:00","source_repo":".","labels":["architecture-decision","context-budget","no-fallback"]}
