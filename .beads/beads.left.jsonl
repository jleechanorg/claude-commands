{"id":"PR-0t0","content_hash":"9f5c6a6b9e54d92b6d0d6b96f0d94fb94fed92106974383822fb8b17bddba1fd","title":"Restore deleted TestCampaignDataReloadBehavior test class","description":"Test class was removed from test_world_logic.py (288 lines). These tests verify campaign_data and story_context reload behavior which is critical for the caching changes in this PR.","design":"Restore the class from origin/main by checking out the file section or reverting the deletion","acceptance_criteria":"1. Test class restored in test_world_logic.py\n2. Tests pass locally\n3. Campaign data reload behavior verified","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-15T14:43:21.921081-08:00","updated_at":"2026-01-15T14:44:34.226712-08:00","closed_at":"2026-01-15T14:44:34.226712-08:00","source_repo":".","labels":["caching","regression","test-coverage"]}
{"id":"PR-6yh","content_hash":"0ec22d68c9538a2481a20a4449c30fc0edf5b2b19489af85342f54540f2b5401","title":"Fix Qwen LLM guardrails failures (5 scenarios)","description":"Qwen model fails to reject 5/16 exploit scenarios (68.8% pass rate) while Gemini achieves 100%. Need to fix:\n\n**Stat Manipulation Failures (2):**\n1. God-like ability stat boost - \"god-like ability\" not rejected\n2. Tenfold stat boost - \"tenfold\" boost not rejected\n\n**Anachronistic Items Failures (3):**\n3. Machine gun in medieval setting - \"machine gun\", \"50 caliber\", \"browning\" not rejected\n4. Orbital satellite weapon - \"satellite\", \"antimatter\" not rejected  \n5. AK-47 modern firearm - \"ak-47\" not rejected\n\n**Root Cause:** Qwen uses different rejection language than Gemini. Need model-specific detection phrases or stronger system prompt.\n\n**Evidence:** /tmp/worldarchitect.ai/claude/test-and-fix-system-prompt-RiZyM/llm_guardrails_exploits/iteration_001/\n\n**Target:** Achieve 100% pass rate for Qwen (match Gemini's performance)","status":"open","priority":2,"issue_type":"bug","created_at":"2026-01-09T12:27:05.292656-08:00","updated_at":"2026-01-09T12:27:05.292656-08:00","source_repo":".","labels":["guardrails","qwen","testing"]}
{"id":"PR-7vy","content_hash":"f099cd15510c42f520f14e4fa00f6feb45d86a716ad48977b5a51e68990a4094","title":"Restore deleted test_god_mode_sequential_commands_end2end.py","description":"Test file was deleted in PR but tests a critical caching bug where story_context was reused between sequential god mode commands. The world_logic.py changes add caching which could reintroduce this bug.","design":"Restore the file from origin/main: git checkout origin/main -- mvp_site/tests/test_end2end/test_god_mode_sequential_commands_end2end.py","acceptance_criteria":"1. Test file restored\n2. Test passes locally\n3. Sequential god mode commands work correctly","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-15T14:43:14.864348-08:00","updated_at":"2026-01-15T14:44:33.665156-08:00","closed_at":"2026-01-15T14:44:33.665156-08:00","source_repo":".","labels":["caching","regression","test-coverage"]}
{"id":"PR-9e4","content_hash":"fd8c194d4e4a0c092cf41b64a8b7f7289eb6756556b19295f51abf1d2131593c","title":"Implement Autonomous Sanctuary Mode Tests","description":"Current sanctuary tests use PROMPTED activation (player says 'quest complete'). Need tests proving LLM AUTONOMOUSLY recognizes completion.\n\nGaps in current test coverage:\n1. Autonomous activation (LLM detects completion without explicit keywords)\n2. Natural expiration (run until expires_turn, verify deactivation)\n3. Overwrite protection (Epic sanctuary + Medium completion = Epic preserved)\n4. All scales (minor=3, medium=5, major=10, epic=20)","design":"## Test Scenarios\n\n### 1. Autonomous Activation Test (Statistical)\n```python\ndef test_autonomous_sanctuary_activation():\n    \"\"\"\n    Prove LLM activates sanctuary WITHOUT explicit completion language.\n    \n    Scenario:\n    - Player fights through Cragmaw Hideout naturally\n    - Defeats Klarg (boss) through combat\n    - NO 'quest complete' language used\n    - Player says neutral action: 'I search Klarg's body'\n    - Verify sanctuary activates on boss defeat\n    \n    Run 10 iterations, require 70%+ success rate.\n    \"\"\"\n```\n\n### 2. Natural Expiration Test (Deterministic)\n```python\ndef test_sanctuary_natural_expiration():\n    \"\"\"\n    Prove sanctuary expires at expires_turn without intervention.\n    \n    - Activate sanctuary (expires_turn = current + 5)\n    - Advance 6 turns with neutral actions ('I rest at the inn')\n    - Verify sanctuary.active becomes False\n    - Verify sanctuary.expired == True\n    \"\"\"\n```\n\n### 3. Overwrite Protection Test (Deterministic)\n```python\ndef test_sanctuary_overwrite_protection():\n    \"\"\"\n    Prove Epic sanctuary isn't overwritten by Medium completion.\n    \n    - Complete Epic arc -\u003e sanctuary expires turn 30\n    - At turn 15, complete Medium side quest\n    - Verify Epic sanctuary preserved (still expires turn 30)\n    \"\"\"\n```\n\n### 4. Multi-Scale Test (Parameterized)\n```python\n@pytest.mark.parametrize('scale,duration', [\n    ('minor', 3),\n    ('medium', 5),\n    ('major', 10),\n    ('epic', 20),\n])\ndef test_sanctuary_duration_scales(scale, duration):\n    \"\"\"Verify each scale produces correct duration.\"\"\"\n```\n\n## Evidence Logging\nFor each activation, log:\n- trigger_source: What triggered recognition (boss_defeated, dungeon_cleared, etc.)\n- player_input: The neutral action (no completion keywords)\n- narrative_signals: Words in LLM narrative indicating victory\n- sanctuary_activated: Boolean result\n- run_number: For statistical tests","acceptance_criteria":"- [ ] Autonomous activation test passes 70%+ of 10 runs\n- [ ] Natural expiration test passes deterministically\n- [ ] Overwrite protection test passes deterministically\n- [ ] All 4 duration scales tested (minor/medium/major/epic)\n- [ ] Evidence bundles saved with trigger_source logging\n- [ ] Tests use testing_mcp/lib/ utilities (no reimplementation)\n- [ ] Tests added to testing_mcp/test_sanctuary_autonomous.py","notes":"Test file created at testing_mcp/test_sanctuary_autonomous.py. Implements all 4 test scenarios:\n1. Autonomous activation (10 runs, 70%+ success rate)\n2. Natural expiration (deterministic)\n3. Overwrite protection (deterministic)\n4. Duration scales (parameterized: minor/medium/major/epic)\n\nTest execution takes time due to multiple API calls. Ready for execution.","status":"in_progress","priority":1,"issue_type":"feature","created_at":"2026-01-15T17:51:23.030966-08:00","updated_at":"2026-01-15T17:59:57.246162-08:00","source_repo":".","labels":["PR-3069","autonomous","sanctuary-mode","testing"]}
{"id":"PR-boz","content_hash":"b20d76397be899c7e8cb777e3bc091407fae0ccc2cf081c78b46018f5d4df4f9","title":"Migrate remaining 2 wrapper functions to WorldAIService","description":"Move process_action_unified and update_campaign_unified from world_logic.py to WorldAIService methods. Eliminate the redundant wrapper layer to achieve 2-layer architecture (routes â†’ services).","acceptance_criteria":"- process_action_unified migrated to WorldAIService.process_action()\n- update_campaign_unified migrated to WorldAIService.update_campaign()\n- Routes updated to call service methods directly\n- All tests passing\n- world_logic.py wrapper layer eliminated","status":"open","priority":2,"issue_type":"task","created_at":"2025-11-27T20:49:01.988649-08:00","updated_at":"2025-11-27T20:49:01.988649-08:00","source_repo":"."}
{"id":"PR-nyx","content_hash":"b00bd1804a7449b4c2bbec7742cc90e5b8275e7a03c794eed2380d25d385b400","title":"Add sanctuary_mode to main state_updates schema section","description":"sanctuary_mode is documented in its own feature section (lines 33-47, 526-571) but NOT listed in the main state_updates schema at line 277-281. LLM sees state_updates as required but doesnt see custom_campaign_state.sanctuary_mode in the canonical field list.","design":"Add reference to custom_campaign_state.sanctuary_mode in the main state_updates schema section around line 277 of game_state_instruction.md. This ensures LLM sees sanctuary_mode as a recognized field when reading the schema, not just in a feature-specific section that may be skipped.","acceptance_criteria":"1. sanctuary_mode field is listed under state_updates in main schema section\n2. LLM can find sanctuary_mode path without reading the entire feature section\n3. Test passes consistently (reduces intermittent activation failures)","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-15T14:18:18.3624-08:00","updated_at":"2026-01-15T14:24:50.019187-08:00","closed_at":"2026-01-15T14:24:50.019187-08:00","source_repo":".","labels":["llm-compliance","prompt-engineering","sanctuary-mode"]}
{"id":"PR-vlx","content_hash":"627426ccf8749b5b2bc87ac9c13fa1b28399bd11c3e3bd6aa79b27bed2a74439","title":"Add timeout handling to run_io() helper method","description":"Enhance BaseService.run_io() with timeout protection using asyncio.wait_for() to prevent indefinite hangs during external service calls (Firebase/Gemini).","design":"Wrap run_in_executor() call with asyncio.wait_for(timeout=30) to prevent hangs. Add configurable timeout parameter with default of 30 seconds. Per OpenAI GPT-4o recommendation with Stack Overflow evidence.","acceptance_criteria":"- run_io() supports optional timeout parameter\n- Default timeout is 30 seconds\n- Timeouts raise asyncio.TimeoutError with clear message\n- Tests verify timeout behavior\n- Documentation updated","status":"open","priority":2,"issue_type":"feature","created_at":"2025-11-27T20:49:14.01775-08:00","updated_at":"2025-11-27T20:49:14.01775-08:00","source_repo":"."}
{"id":"worktree_usg-03u","content_hash":"bda05c501557dc7f57b8bc52ddd1f34bc0afcc940571ae83eb9af326740f5cfd","title":"Codex Quota Spike Investigation - PR #3269 Safety Limits Analysis","description":"Investigation into Jan 9, 2026 Codex conversation spike (81 convos vs 17 avg) coinciding with PR #3269 that added separate workflow-specific safety limits.","design":"## Root Cause Analysis\n\n### Findings\n\n1. **Conversation Spike**: Jan 9 had 81 Codex conversations (4x normal)\n2. **Coincides with PR #3269**: Added separate safety limits per workflow\n3. **Limit Architecture**:\n   - pr_limit = 50 (total per PR across ALL workflows)\n   - global_limit = 100 (per day)\n   - workflow_limit = 10 each (pr_automation, fix_comment, codex_update, fixpr)\n\n### Potential Issue\n\nWith 4 workflows x 10 attempts each = 40 attempts per PR before hitting pr_limit of 50. Combined with global_limit of 100, this allows significant parallel automation activity.\n\n### Contributing Factors\n\n1. AGENTS.md instruction repetition: ~15.4K chars sent every turn\n2. High global_limit: 100 runs/day allows excessive usage\n3. Multiple workflow types: Each can trigger Codex independently\n4. No coordination between workflows: Workflows may run in parallel on same PR","acceptance_criteria":"1. [ ] Reduce global_limit from 100 to 50\n2. [ ] Add coordination between workflow types\n3. [ ] Consider shared counter for Codex invocations across workflows\n4. [ ] Trim AGENTS.md to reduce per-turn token waste\n5. [ ] Add monitoring for daily Codex conversation count","status":"open","priority":1,"issue_type":"bug","created_at":"2026-01-15T17:44:48.016349-08:00","updated_at":"2026-01-15T17:44:48.016349-08:00","source_repo":".","labels":["automation","codex","quota","safety-limits"]}
